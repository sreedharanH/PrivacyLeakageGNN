{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GraphSAGE_WhiteBox.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R04d7dBUiO1",
        "colab_type": "text"
      },
      "source": [
        "GraphSAGE\n",
        "- cora: ~0.8330 \n",
        "- citeseer: ~0.7110\n",
        "- pubmed: ~0.7830"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "826eEMOcT_2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install dgl\n",
        "!pip install dgl-cu101"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON8YOzNAKnF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import time\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dgl import DGLGraph\n",
        "from dgl.data import register_data_args, load_data\n",
        "from dgl.nn.pytorch.conv import SAGEConv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WFBfTlDTQqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " dropout=0.5\n",
        " gpu=0\n",
        " lr=1e-2\n",
        " epochs=200\n",
        " n_hidden=16\n",
        " n_layers=1\n",
        " weight_decay=5e-4\n",
        " aggregator_type=\"gcn\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqqWnJdxSwbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self,\n",
        "                 g,\n",
        "                 in_feats,\n",
        "                 n_hidden,\n",
        "                 n_classes,\n",
        "                 n_layers,\n",
        "                 activation,\n",
        "                 dropout,\n",
        "                 aggregator_type):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.g = g\n",
        "\n",
        "        # input layer\n",
        "        self.layers.append(SAGEConv(in_feats, n_hidden, aggregator_type, feat_drop=dropout, activation=activation))\n",
        "        # hidden layers\n",
        "        for i in range(n_layers - 1):\n",
        "            self.layers.append(SAGEConv(n_hidden, n_hidden, aggregator_type, feat_drop=dropout, activation=activation))\n",
        "        # output layer\n",
        "        self.layers.append(SAGEConv(n_hidden, n_classes, aggregator_type, feat_drop=dropout, activation=None)) # activation None\n",
        "\n",
        "    def forward(self, features):\n",
        "        emb=[]\n",
        "        h = features\n",
        "        for layer in self.layers:\n",
        "            h = layer(self.g, h)\n",
        "            emb.append(h)\n",
        "        return h,emb\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8UfQlFeS3eq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parser = argparse.ArgumentParser(description='APPNP')\n",
        "register_data_args(parser)\n",
        "args = parser.parse_args(args=['--dataset', 'cora'])\n",
        "#args = parser.parse_args(args=['--dataset', 'citeseer'])\n",
        "#args = parser.parse_args(args=['--dataset', 'pubmed'])\n",
        "\n",
        "data = load_data(args)\n",
        "features = torch.FloatTensor(data.features)\n",
        "labels = torch.LongTensor(data.labels)\n",
        "if hasattr(torch, 'BoolTensor'):\n",
        "    train_mask = torch.BoolTensor(data.train_mask)\n",
        "    val_mask = torch.BoolTensor(data.val_mask)\n",
        "    test_mask = torch.BoolTensor(data.test_mask)\n",
        "else:\n",
        "    train_mask = torch.ByteTensor(data.train_mask)\n",
        "    val_mask = torch.ByteTensor(data.val_mask)\n",
        "    test_mask = torch.ByteTensor(data.test_mask)\n",
        "in_feats = features.shape[1]\n",
        "n_classes = data.num_labels\n",
        "n_edges = data.graph.number_of_edges()\n",
        "print(\"\"\"----Data statistics------'\n",
        "  #Edges %d\n",
        "  #Classes %d\n",
        "  #Train samples %d\n",
        "  #Val samples %d\n",
        "  #Test samples %d\"\"\" %\n",
        "      (n_edges, n_classes,\n",
        "        train_mask.int().sum().item(),\n",
        "        val_mask.int().sum().item(),\n",
        "        test_mask.int().sum().item()))\n",
        "\n",
        "if gpu < 0:\n",
        "    cuda = False\n",
        "else:\n",
        "    cuda = True\n",
        "    torch.cuda.set_device(gpu)\n",
        "    features = features.cuda()\n",
        "    labels = labels.cuda()\n",
        "    train_mask = train_mask.cuda()\n",
        "    val_mask = val_mask.cuda()\n",
        "    test_mask = test_mask.cuda()\n",
        "    print(\"use cuda:\", gpu)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o3d9xP9Szfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, features, labels, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits,_ = model(features)\n",
        "        logits = logits[mask]\n",
        "        labels = labels[mask]\n",
        "        _, indices = torch.max(logits, dim=1)\n",
        "        correct = torch.sum(indices == labels)\n",
        "        acc =correct.item() * 1.0 / len(labels)\n",
        "        return acc\n",
        "\n",
        "\n",
        "def train(model, n_epochs):\n",
        "    dur = []\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        if epoch >= 3:\n",
        "            t0 = time.time()\n",
        "        # forward\n",
        "        logits,_ = model(features)\n",
        "        loss = loss_fcn(logits[train_mask], labels[train_mask])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch >= 3:\n",
        "            dur.append(time.time() - t0)\n",
        "\n",
        "        acc = evaluate(model, features, labels, val_mask)\n",
        "        print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} |Accuracy {:.4f} |\"\n",
        "              \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur), loss.item(),\n",
        "                                           acc,n_edges / np.mean(dur) / 1000))\n",
        "\n",
        "    print()\n",
        "    trainacc = evaluate(model, features, labels, train_mask)\n",
        "    print(\"Test Accuracy {:.4f}\".format(trainacc))\n",
        "    acc = evaluate(model, features, labels, test_mask)\n",
        "    print(\"Test Accuracy {:.4f}\".format(acc))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLiZelf0S9ah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g = data.graph\n",
        "g.remove_edges_from(nx.selfloop_edges(g))\n",
        "g = DGLGraph(g)\n",
        "n_edges = g.number_of_edges()\n",
        "\n",
        "# create GraphSAGE model\n",
        "model = GraphSAGE(g,\n",
        "                  in_feats,\n",
        "                  n_hidden,\n",
        "                  n_classes,\n",
        "                  n_layers,\n",
        "                  F.relu,\n",
        "                  dropout,\n",
        "                  aggregator_type\n",
        "                  )\n",
        "\n",
        "if cuda:\n",
        "    model.cuda()\n",
        "loss_fcn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# use optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o6w3EJTTUDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(model,200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhu2eJqZ2WB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ExtractEmbedding(model, features, labels, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits, emb = model(features)\n",
        "        embedding1=emb[0][mask]\n",
        "        embedding2=emb[1][mask]\n",
        "        logits = logits[mask]\n",
        "        labels = labels[mask]\n",
        "        return embedding1, embedding2\n",
        "\n",
        "train_emb1,train_emb2=ExtractEmbedding(model, features, labels, train_mask)\n",
        "test_emb1,test_emb2 = ExtractEmbedding(model, features, labels, test_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMp-MF-aTOsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_emb=train_emb1.cpu().numpy()\n",
        "test_emb=test_emb1.cpu().numpy()\n",
        "print(train_emb.shape)\n",
        "print(test_emb.shape)\n",
        "X=np.concatenate((train_emb, test_emb), axis=0)\n",
        "print(X.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCacg2ohRHo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "encoding_dim = 1  \n",
        "\n",
        "input_img = Input(shape=(16,))\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "decoded = Dense(16, activation='sigmoid')(encoded)\n",
        "autoencoder = Model(input_img, decoded)\n",
        "encoder = Model(input_img, encoded)\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.fit(X, X,epochs=1000,batch_size=256,shuffle=True)\n",
        "encoded_imgs = encoder.predict(X)\n",
        "#print(encoded_imgs.shape)\n",
        "#print(encoded_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seHRN5n3b_qH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(encoded_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PkZfGOOlFxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy=[]\n",
        "for i in range(100):\n",
        "  kmeans = KMeans(n_clusters=2, random_state=i).fit(encoded_imgs)\n",
        "  #print(kmeans.labels_)\n",
        "  ylabel=[1]*train_emb.shape[0] + [0]*test_emb.shape[0] \n",
        "  acc = accuracy_score(kmeans.labels_, ylabel)\n",
        "  accuracy.append(acc)\n",
        "print(max(accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}