{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAE_Citeseer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoJstoMsmPS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/DaehanKim/vgae_pytorch\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "import scipy.sparse as sp\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87ADSmnpmy0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Args:\n",
        "  dataset = 'citeseer'\n",
        "  model = 'GAE'\n",
        "\n",
        "  input_dim = 3703 \n",
        "  hidden1_dim = 32\n",
        "  hidden2_dim = 16\n",
        "  use_feature = True\n",
        "\n",
        "  num_epoch = 200\n",
        "  learning_rate = 0.01\n",
        "args=Args()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03DM2VwxmXUs",
        "colab_type": "code",
        "outputId": "a92233d3-07e7-4290-dea6-3e0e12f913ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "****************NOTE*****************\n",
        "CREDITS : Thomas Kipf\n",
        "since datasets are the same as those in kipf's implementation, \n",
        "Their preprocessing source was used as-is.\n",
        "*************************************\n",
        "'''\n",
        "import numpy as np\n",
        "import sys\n",
        "import pickle as pkl\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "colab='Colab Notebooks'\n",
        "path = F\"/content/gdrive/My Drive/{colab}/GraphNN/data/\"\n",
        "\n",
        "def parse_index_file(filename):\n",
        "    index = []\n",
        "    for line in open(filename):\n",
        "        index.append(int(line.strip()))\n",
        "    return index\n",
        "\n",
        "def load_data(dataset):\n",
        "    # load the data: x, tx, allx, graph\n",
        "    names = ['x', 'tx', 'allx', 'graph']\n",
        "    objects = []\n",
        "    for i in range(len(names)):\n",
        "        with open(path+\"ind.{}.{}\".format(dataset, names[i]), 'rb') as f:\n",
        "            if sys.version_info > (3, 0):\n",
        "                objects.append(pkl.load(f, encoding='latin1'))\n",
        "            else:\n",
        "                objects.append(pkl.load(f))\n",
        "    x, tx, allx, graph = tuple(objects)\n",
        "    test_idx_reorder = parse_index_file(path+\"ind.{}.test.index\".format(dataset))\n",
        "    test_idx_range = np.sort(test_idx_reorder)\n",
        "\n",
        "    if dataset == 'citeseer':\n",
        "        # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
        "        # Find isolated nodes, add them as zero-vecs into the right position\n",
        "        test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
        "        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
        "        tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
        "        tx = tx_extended\n",
        "\n",
        "    features = sp.vstack((allx, tx)).tolil()\n",
        "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
        "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
        "\n",
        "    return adj, features"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q60gv7pmdil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "****************NOTE*****************\n",
        "CREDITS : Thomas Kipf\n",
        "since datasets are the same as those in kipf's implementation, \n",
        "Their preprocessing source was used as-is.\n",
        "*************************************\n",
        "'''\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "def sparse_to_tuple(sparse_mx):\n",
        "    if not sp.isspmatrix_coo(sparse_mx):\n",
        "        sparse_mx = sparse_mx.tocoo()\n",
        "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
        "    values = sparse_mx.data\n",
        "    shape = sparse_mx.shape\n",
        "    return coords, values, shape\n",
        "\n",
        "def preprocess_graph(adj):\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    adj_ = adj + sp.eye(adj.shape[0])\n",
        "    rowsum = np.array(adj_.sum(1))\n",
        "    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n",
        "    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n",
        "    return sparse_to_tuple(adj_normalized)\n",
        "\n",
        "def mask_test_edges(adj):\n",
        "    # Function to build test set with 10% positive links\n",
        "    # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n",
        "    # TODO: Clean up.\n",
        "\n",
        "    # Remove diagonal elements\n",
        "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
        "    adj.eliminate_zeros()\n",
        "    # Check that diag is zero:\n",
        "    assert np.diag(adj.todense()).sum() == 0\n",
        "\n",
        "    adj_triu = sp.triu(adj)\n",
        "    adj_tuple = sparse_to_tuple(adj_triu)\n",
        "    edges = adj_tuple[0]\n",
        "    edges_all = sparse_to_tuple(adj)[0]\n",
        "    #num_test = int(np.floor(edges.shape[0] / 60.))\n",
        "    #num_val = int(np.floor(edges.shape[0] / 10.))\n",
        "    num_val=int(edges.shape[0]*0.1)\n",
        "    num_test=int(edges.shape[0]*0.6)\n",
        "    all_edge_idx = list(range(edges.shape[0]))\n",
        "    np.random.shuffle(all_edge_idx)\n",
        "    val_edge_idx = all_edge_idx[:num_val]\n",
        "    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
        "    test_edges = edges[test_edge_idx]\n",
        "    val_edges = edges[val_edge_idx]\n",
        "    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
        "\n",
        "    def ismember(a, b, tol=5):\n",
        "        rows_close = np.all(np.round(a - b[:, None], tol) == 0, axis=-1)\n",
        "        return np.any(rows_close)\n",
        "\n",
        "    test_edges_false = []\n",
        "    while len(test_edges_false) < len(test_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], edges_all):\n",
        "            continue\n",
        "        if test_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(test_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(test_edges_false)):\n",
        "                continue\n",
        "        test_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    val_edges_false = []\n",
        "    while len(val_edges_false) < len(val_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], train_edges):\n",
        "            continue\n",
        "        if ismember([idx_j, idx_i], train_edges):\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], val_edges):\n",
        "            continue\n",
        "        if ismember([idx_j, idx_i], val_edges):\n",
        "            continue\n",
        "        if val_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(val_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(val_edges_false)):\n",
        "                continue\n",
        "        val_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    assert ~ismember(test_edges_false, edges_all)\n",
        "    assert ~ismember(val_edges_false, edges_all)\n",
        "    assert ~ismember(val_edges, train_edges)\n",
        "    assert ~ismember(test_edges, train_edges)\n",
        "    assert ~ismember(val_edges, test_edges)\n",
        "\n",
        "    data = np.ones(train_edges.shape[0])\n",
        "\n",
        "    # Re-build adj matrix\n",
        "    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n",
        "    adj_train = adj_train + adj_train.T\n",
        "\n",
        "    # NOTE: these edge lists only contain single direction of edge!\n",
        "    return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VoHmNaFmkjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "class GraphConvSparse(nn.Module):\n",
        "\tdef __init__(self, input_dim, output_dim, adj, activation = F.relu, **kwargs):\n",
        "\t\tsuper(GraphConvSparse, self).__init__(**kwargs)\n",
        "\t\tself.weight = glorot_init(input_dim, output_dim) \n",
        "\t\tself.adj = adj\n",
        "\t\tself.activation = activation\n",
        "\n",
        "\tdef forward(self, inputs):\n",
        "\t\tx = inputs\n",
        "\t\tx = torch.mm(x,self.weight)\n",
        "\t\tx = torch.mm(self.adj, x)\n",
        "\t\toutputs = self.activation(x)\n",
        "\t\treturn outputs\n",
        "\n",
        "\n",
        "def dot_product_decode(Z):\n",
        "\tA_pred = torch.sigmoid(torch.matmul(Z,Z.t()))\n",
        "\treturn A_pred\n",
        "\n",
        "def glorot_init(input_dim, output_dim):\n",
        "\tinit_range = np.sqrt(6.0/(input_dim + output_dim))\n",
        "\tinitial = torch.rand(input_dim, output_dim)*2*init_range - init_range\n",
        "\treturn nn.Parameter(initial)\n",
        "\n",
        "\n",
        "class GAE(nn.Module):\n",
        "\tdef __init__(self,adj):\n",
        "\t\tsuper(GAE,self).__init__()\n",
        "\t\tself.base_gcn = GraphConvSparse(args.input_dim, args.hidden1_dim, adj)\n",
        "\t\tself.gcn_mean = GraphConvSparse(args.hidden1_dim, args.hidden2_dim, adj, activation=lambda x:x)\n",
        "\n",
        "\tdef encode(self, X):\n",
        "\t\thidden = self.base_gcn(X)\n",
        "\t\tz = self.mean = self.gcn_mean(hidden)\n",
        "\t\treturn z\n",
        "\n",
        "\tdef forward(self, X):\n",
        "\t\tZ = self.encode(X)\n",
        "\t\tA_pred = dot_product_decode(Z)\n",
        "\t\treturn A_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDfaB6uwnFAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
        "\n",
        "adj, features = load_data(args.dataset)\n",
        "\n",
        "# Store original adjacency matrix (without diagonal entries) for later\n",
        "adj_orig = adj\n",
        "adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
        "adj_orig.eliminate_zeros()\n",
        "\n",
        "adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
        "adj = adj_train\n",
        "# Some preprocessing\n",
        "adj_norm = preprocess_graph(adj)\n",
        "\n",
        "\n",
        "num_nodes = adj.shape[0]\n",
        "\n",
        "features = sparse_to_tuple(features.tocoo())\n",
        "num_features = features[2][1]\n",
        "features_nonzero = features[1].shape[0]\n",
        "\n",
        "# Create Model\n",
        "pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
        "norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
        "\n",
        "\n",
        "adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
        "adj_label = sparse_to_tuple(adj_label)\n",
        "\n",
        "\n",
        "adj_norm = torch.sparse.FloatTensor(torch.LongTensor(adj_norm[0].T), torch.FloatTensor(adj_norm[1]), torch.Size(adj_norm[2]))\n",
        "adj_label = torch.sparse.FloatTensor(torch.LongTensor(adj_label[0].T),  torch.FloatTensor(adj_label[1]), torch.Size(adj_label[2]))\n",
        "features = torch.sparse.FloatTensor(torch.LongTensor(features[0].T), torch.FloatTensor(features[1]), torch.Size(features[2]))\n",
        "\n",
        "weight_mask = adj_label.to_dense().view(-1) == 1\n",
        "weight_tensor = torch.ones(weight_mask.size(0)) \n",
        "weight_tensor[weight_mask] = pos_weight\n",
        "\n",
        "# init model and optimizer\n",
        "#model = getattr(model,\"GAE\")(adj_norm)\n",
        "#model=VGAE(adj_norm)\n",
        "model=GAE(adj_norm)\n",
        "optimizer = Adam(model.parameters(), lr=args.learning_rate)\n",
        "\n",
        "\n",
        "def get_scores(edges_pos, edges_neg, adj_rec):\n",
        "\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # Predict on test set of edges\n",
        "    preds = []\n",
        "    pos = []\n",
        "    for e in edges_pos:\n",
        "        # print(e)\n",
        "        # print(adj_rec[e[0], e[1]])\n",
        "        preds.append(sigmoid(adj_rec[e[0], e[1]].item()))\n",
        "        pos.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_neg = []\n",
        "    neg = []\n",
        "    for e in edges_neg:\n",
        "\n",
        "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]].data))\n",
        "        neg.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_all = np.hstack([preds, preds_neg])\n",
        "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
        "    roc_score = roc_auc_score(labels_all, preds_all)\n",
        "    ap_score = average_precision_score(labels_all, preds_all)\n",
        "\n",
        "    return roc_score, ap_score\n",
        "\n",
        "def get_acc(adj_rec, adj_label):\n",
        "    labels_all = adj_label.to_dense().view(-1).long()\n",
        "    preds_all = (adj_rec > 0.5).view(-1).long()\n",
        "    accuracy = (preds_all == labels_all).sum().float() / labels_all.size(0)\n",
        "    return accuracy\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK5JgeJ_NLPT",
        "colab_type": "code",
        "outputId": "1387fc41-1c64-44ce-a251-50a9133743cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train model\n",
        "for epoch in range(1500):\n",
        "    t = time.time()\n",
        "\n",
        "    A_pred = model(features)\n",
        "    optimizer.zero_grad()\n",
        "    loss = log_lik = norm*F.binary_cross_entropy(A_pred.view(-1), adj_label.to_dense().view(-1), weight = weight_tensor)\n",
        "    if args.model == 'VGAE':\n",
        "        kl_divergence = 0.5/ A_pred.size(0) * (1 + 2*model.logstd - model.mean**2 - torch.exp(model.logstd)).sum(1).mean()\n",
        "        loss -= kl_divergence\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_acc = get_acc(A_pred,adj_label)\n",
        "\n",
        "    val_roc, val_ap = get_scores(val_edges, val_edges_false, A_pred)\n",
        "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(loss.item()),\n",
        "          \"train_acc=\", \"{:.5f}\".format(train_acc), \"val_roc=\", \"{:.5f}\".format(val_roc),\n",
        "          \"val_ap=\", \"{:.5f}\".format(val_ap),\n",
        "          \"time=\", \"{:.5f}\".format(time.time() - t))\n",
        "\n",
        "\n",
        "test_roc, test_ap = get_scores(test_edges, test_edges_false, A_pred)\n",
        "print(\"End of training!\", \"test_roc=\", \"{:.5f}\".format(test_roc),\n",
        "      \"test_ap=\", \"{:.5f}\".format(test_ap))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 train_loss= 1.07206 train_acc= 0.14887 val_roc= 0.65351 val_ap= 0.65405 time= 0.57934\n",
            "Epoch: 0002 train_loss= 1.25782 train_acc= 0.00834 val_roc= 0.63391 val_ap= 0.67637 time= 0.40744\n",
            "Epoch: 0003 train_loss= 0.95479 train_acc= 0.00863 val_roc= 0.62112 val_ap= 0.63858 time= 0.40771\n",
            "Epoch: 0004 train_loss= 0.96247 train_acc= 0.00859 val_roc= 0.63357 val_ap= 0.65296 time= 0.42319\n",
            "Epoch: 0005 train_loss= 0.89689 train_acc= 0.01291 val_roc= 0.69818 val_ap= 0.70768 time= 0.40925\n",
            "Epoch: 0006 train_loss= 0.88304 train_acc= 0.03194 val_roc= 0.75527 val_ap= 0.77051 time= 0.41367\n",
            "Epoch: 0007 train_loss= 0.84927 train_acc= 0.05531 val_roc= 0.77341 val_ap= 0.79090 time= 0.40855\n",
            "Epoch: 0008 train_loss= 0.80898 train_acc= 0.08064 val_roc= 0.78355 val_ap= 0.80082 time= 0.42035\n",
            "Epoch: 0009 train_loss= 0.77087 train_acc= 0.13158 val_roc= 0.79869 val_ap= 0.81362 time= 0.40609\n",
            "Epoch: 0010 train_loss= 0.72845 train_acc= 0.21712 val_roc= 0.81103 val_ap= 0.82294 time= 0.41240\n",
            "Epoch: 0011 train_loss= 0.68971 train_acc= 0.30746 val_roc= 0.81511 val_ap= 0.82669 time= 0.41151\n",
            "Epoch: 0012 train_loss= 0.66136 train_acc= 0.37347 val_roc= 0.81802 val_ap= 0.82997 time= 0.40734\n",
            "Epoch: 0013 train_loss= 0.64240 train_acc= 0.41049 val_roc= 0.82041 val_ap= 0.83277 time= 0.41358\n",
            "Epoch: 0014 train_loss= 0.62537 train_acc= 0.43459 val_roc= 0.82496 val_ap= 0.83741 time= 0.41117\n",
            "Epoch: 0015 train_loss= 0.60380 train_acc= 0.45714 val_roc= 0.83355 val_ap= 0.84522 time= 0.41367\n",
            "Epoch: 0016 train_loss= 0.58329 train_acc= 0.47430 val_roc= 0.84300 val_ap= 0.85391 time= 0.41661\n",
            "Epoch: 0017 train_loss= 0.57203 train_acc= 0.48020 val_roc= 0.84918 val_ap= 0.85956 time= 0.42502\n",
            "Epoch: 0018 train_loss= 0.56787 train_acc= 0.47993 val_roc= 0.85221 val_ap= 0.86212 time= 0.43283\n",
            "Epoch: 0019 train_loss= 0.56177 train_acc= 0.48281 val_roc= 0.85377 val_ap= 0.86328 time= 0.40435\n",
            "Epoch: 0020 train_loss= 0.55242 train_acc= 0.49007 val_roc= 0.85594 val_ap= 0.86516 time= 0.41078\n",
            "Epoch: 0021 train_loss= 0.54276 train_acc= 0.49920 val_roc= 0.85672 val_ap= 0.86560 time= 0.42399\n",
            "Epoch: 0022 train_loss= 0.53441 train_acc= 0.50844 val_roc= 0.85727 val_ap= 0.86559 time= 0.40049\n",
            "Epoch: 0023 train_loss= 0.52737 train_acc= 0.51691 val_roc= 0.85804 val_ap= 0.86591 time= 0.41421\n",
            "Epoch: 0024 train_loss= 0.52127 train_acc= 0.52364 val_roc= 0.85811 val_ap= 0.86481 time= 0.43398\n",
            "Epoch: 0025 train_loss= 0.51604 train_acc= 0.52819 val_roc= 0.85811 val_ap= 0.86440 time= 0.43211\n",
            "Epoch: 0026 train_loss= 0.51157 train_acc= 0.53076 val_roc= 0.85912 val_ap= 0.86536 time= 0.40112\n",
            "Epoch: 0027 train_loss= 0.50754 train_acc= 0.53194 val_roc= 0.85974 val_ap= 0.86633 time= 0.41527\n",
            "Epoch: 0028 train_loss= 0.50410 train_acc= 0.53252 val_roc= 0.86005 val_ap= 0.86710 time= 0.41570\n",
            "Epoch: 0029 train_loss= 0.50168 train_acc= 0.53261 val_roc= 0.86003 val_ap= 0.86762 time= 0.42759\n",
            "Epoch: 0030 train_loss= 0.49965 train_acc= 0.53275 val_roc= 0.85977 val_ap= 0.86721 time= 0.42677\n",
            "Epoch: 0031 train_loss= 0.49663 train_acc= 0.53370 val_roc= 0.86058 val_ap= 0.86764 time= 0.40732\n",
            "Epoch: 0032 train_loss= 0.49248 train_acc= 0.53543 val_roc= 0.86207 val_ap= 0.86934 time= 0.42209\n",
            "Epoch: 0033 train_loss= 0.48844 train_acc= 0.53728 val_roc= 0.86379 val_ap= 0.87091 time= 0.40341\n",
            "Epoch: 0034 train_loss= 0.48552 train_acc= 0.53871 val_roc= 0.86511 val_ap= 0.87229 time= 0.40214\n",
            "Epoch: 0035 train_loss= 0.48360 train_acc= 0.53923 val_roc= 0.86638 val_ap= 0.87334 time= 0.41366\n",
            "Epoch: 0036 train_loss= 0.48204 train_acc= 0.53915 val_roc= 0.86724 val_ap= 0.87416 time= 0.40159\n",
            "Epoch: 0037 train_loss= 0.48037 train_acc= 0.53905 val_roc= 0.86806 val_ap= 0.87492 time= 0.41313\n",
            "Epoch: 0038 train_loss= 0.47849 train_acc= 0.53912 val_roc= 0.86864 val_ap= 0.87552 time= 0.40025\n",
            "Epoch: 0039 train_loss= 0.47649 train_acc= 0.53938 val_roc= 0.86885 val_ap= 0.87562 time= 0.41142\n",
            "Epoch: 0040 train_loss= 0.47455 train_acc= 0.54015 val_roc= 0.86910 val_ap= 0.87615 time= 0.42070\n",
            "Epoch: 0041 train_loss= 0.47280 train_acc= 0.54111 val_roc= 0.86942 val_ap= 0.87627 time= 0.43640\n",
            "Epoch: 0042 train_loss= 0.47121 train_acc= 0.54207 val_roc= 0.86904 val_ap= 0.87607 time= 0.43264\n",
            "Epoch: 0043 train_loss= 0.46960 train_acc= 0.54299 val_roc= 0.86890 val_ap= 0.87622 time= 0.41241\n",
            "Epoch: 0044 train_loss= 0.46786 train_acc= 0.54399 val_roc= 0.86874 val_ap= 0.87613 time= 0.40951\n",
            "Epoch: 0045 train_loss= 0.46612 train_acc= 0.54483 val_roc= 0.86888 val_ap= 0.87653 time= 0.41497\n",
            "Epoch: 0046 train_loss= 0.46465 train_acc= 0.54557 val_roc= 0.86881 val_ap= 0.87662 time= 0.40684\n",
            "Epoch: 0047 train_loss= 0.46349 train_acc= 0.54616 val_roc= 0.86900 val_ap= 0.87713 time= 0.41006\n",
            "Epoch: 0048 train_loss= 0.46249 train_acc= 0.54676 val_roc= 0.86889 val_ap= 0.87743 time= 0.40677\n",
            "Epoch: 0049 train_loss= 0.46152 train_acc= 0.54724 val_roc= 0.86874 val_ap= 0.87788 time= 0.40508\n",
            "Epoch: 0050 train_loss= 0.46053 train_acc= 0.54767 val_roc= 0.86869 val_ap= 0.87848 time= 0.41173\n",
            "Epoch: 0051 train_loss= 0.45954 train_acc= 0.54803 val_roc= 0.86881 val_ap= 0.87903 time= 0.41757\n",
            "Epoch: 0052 train_loss= 0.45855 train_acc= 0.54836 val_roc= 0.86932 val_ap= 0.88022 time= 0.42255\n",
            "Epoch: 0053 train_loss= 0.45756 train_acc= 0.54878 val_roc= 0.86947 val_ap= 0.88055 time= 0.42883\n",
            "Epoch: 0054 train_loss= 0.45660 train_acc= 0.54930 val_roc= 0.87018 val_ap= 0.88127 time= 0.42958\n",
            "Epoch: 0055 train_loss= 0.45572 train_acc= 0.54977 val_roc= 0.87053 val_ap= 0.88159 time= 0.43679\n",
            "Epoch: 0056 train_loss= 0.45492 train_acc= 0.55027 val_roc= 0.87143 val_ap= 0.88235 time= 0.42880\n",
            "Epoch: 0057 train_loss= 0.45414 train_acc= 0.55073 val_roc= 0.87244 val_ap= 0.88342 time= 0.41290\n",
            "Epoch: 0058 train_loss= 0.45330 train_acc= 0.55129 val_roc= 0.87313 val_ap= 0.88421 time= 0.40697\n",
            "Epoch: 0059 train_loss= 0.45243 train_acc= 0.55200 val_roc= 0.87367 val_ap= 0.88490 time= 0.41524\n",
            "Epoch: 0060 train_loss= 0.45161 train_acc= 0.55284 val_roc= 0.87425 val_ap= 0.88560 time= 0.40000\n",
            "Epoch: 0061 train_loss= 0.45088 train_acc= 0.55350 val_roc= 0.87463 val_ap= 0.88608 time= 0.40610\n",
            "Epoch: 0062 train_loss= 0.45023 train_acc= 0.55417 val_roc= 0.87516 val_ap= 0.88646 time= 0.41605\n",
            "Epoch: 0063 train_loss= 0.44961 train_acc= 0.55487 val_roc= 0.87535 val_ap= 0.88649 time= 0.40257\n",
            "Epoch: 0064 train_loss= 0.44899 train_acc= 0.55557 val_roc= 0.87545 val_ap= 0.88661 time= 0.40509\n",
            "Epoch: 0065 train_loss= 0.44840 train_acc= 0.55625 val_roc= 0.87566 val_ap= 0.88676 time= 0.40861\n",
            "Epoch: 0066 train_loss= 0.44783 train_acc= 0.55685 val_roc= 0.87598 val_ap= 0.88695 time= 0.40319\n",
            "Epoch: 0067 train_loss= 0.44727 train_acc= 0.55741 val_roc= 0.87657 val_ap= 0.88752 time= 0.42217\n",
            "Epoch: 0068 train_loss= 0.44672 train_acc= 0.55790 val_roc= 0.87698 val_ap= 0.88821 time= 0.42967\n",
            "Epoch: 0069 train_loss= 0.44618 train_acc= 0.55835 val_roc= 0.87761 val_ap= 0.88930 time= 0.42789\n",
            "Epoch: 0070 train_loss= 0.44568 train_acc= 0.55878 val_roc= 0.87819 val_ap= 0.89008 time= 0.40460\n",
            "Epoch: 0071 train_loss= 0.44519 train_acc= 0.55915 val_roc= 0.87869 val_ap= 0.89112 time= 0.40698\n",
            "Epoch: 0072 train_loss= 0.44473 train_acc= 0.55965 val_roc= 0.87895 val_ap= 0.89176 time= 0.45780\n",
            "Epoch: 0073 train_loss= 0.44426 train_acc= 0.56008 val_roc= 0.87926 val_ap= 0.89218 time= 0.42599\n",
            "Epoch: 0074 train_loss= 0.44380 train_acc= 0.56058 val_roc= 0.87957 val_ap= 0.89274 time= 0.42624\n",
            "Epoch: 0075 train_loss= 0.44334 train_acc= 0.56109 val_roc= 0.87975 val_ap= 0.89281 time= 0.43980\n",
            "Epoch: 0076 train_loss= 0.44290 train_acc= 0.56159 val_roc= 0.87990 val_ap= 0.89320 time= 0.42561\n",
            "Epoch: 0077 train_loss= 0.44249 train_acc= 0.56214 val_roc= 0.87985 val_ap= 0.89341 time= 0.41018\n",
            "Epoch: 0078 train_loss= 0.44210 train_acc= 0.56272 val_roc= 0.87981 val_ap= 0.89369 time= 0.40410\n",
            "Epoch: 0079 train_loss= 0.44172 train_acc= 0.56334 val_roc= 0.87964 val_ap= 0.89388 time= 0.41470\n",
            "Epoch: 0080 train_loss= 0.44135 train_acc= 0.56390 val_roc= 0.87958 val_ap= 0.89398 time= 0.40471\n",
            "Epoch: 0081 train_loss= 0.44098 train_acc= 0.56453 val_roc= 0.87958 val_ap= 0.89418 time= 0.40930\n",
            "Epoch: 0082 train_loss= 0.44062 train_acc= 0.56512 val_roc= 0.87948 val_ap= 0.89439 time= 0.40949\n",
            "Epoch: 0083 train_loss= 0.44027 train_acc= 0.56567 val_roc= 0.87954 val_ap= 0.89454 time= 0.40712\n",
            "Epoch: 0084 train_loss= 0.43993 train_acc= 0.56625 val_roc= 0.87969 val_ap= 0.89494 time= 0.41944\n",
            "Epoch: 0085 train_loss= 0.43960 train_acc= 0.56675 val_roc= 0.87964 val_ap= 0.89515 time= 0.40445\n",
            "Epoch: 0086 train_loss= 0.43929 train_acc= 0.56732 val_roc= 0.87943 val_ap= 0.89519 time= 0.41289\n",
            "Epoch: 0087 train_loss= 0.43898 train_acc= 0.56794 val_roc= 0.87934 val_ap= 0.89533 time= 0.40588\n",
            "Epoch: 0088 train_loss= 0.43868 train_acc= 0.56857 val_roc= 0.87918 val_ap= 0.89536 time= 0.40817\n",
            "Epoch: 0089 train_loss= 0.43839 train_acc= 0.56917 val_roc= 0.87901 val_ap= 0.89539 time= 0.40437\n",
            "Epoch: 0090 train_loss= 0.43810 train_acc= 0.56972 val_roc= 0.87874 val_ap= 0.89534 time= 0.42984\n",
            "Epoch: 0091 train_loss= 0.43783 train_acc= 0.57027 val_roc= 0.87852 val_ap= 0.89537 time= 0.41149\n",
            "Epoch: 0092 train_loss= 0.43757 train_acc= 0.57078 val_roc= 0.87811 val_ap= 0.89531 time= 0.40073\n",
            "Epoch: 0093 train_loss= 0.43731 train_acc= 0.57121 val_roc= 0.87789 val_ap= 0.89526 time= 0.41222\n",
            "Epoch: 0094 train_loss= 0.43706 train_acc= 0.57171 val_roc= 0.87772 val_ap= 0.89528 time= 0.40017\n",
            "Epoch: 0095 train_loss= 0.43682 train_acc= 0.57225 val_roc= 0.87746 val_ap= 0.89514 time= 0.40180\n",
            "Epoch: 0096 train_loss= 0.43659 train_acc= 0.57276 val_roc= 0.87730 val_ap= 0.89522 time= 0.41149\n",
            "Epoch: 0097 train_loss= 0.43636 train_acc= 0.57323 val_roc= 0.87715 val_ap= 0.89527 time= 0.42945\n",
            "Epoch: 0098 train_loss= 0.43614 train_acc= 0.57377 val_roc= 0.87701 val_ap= 0.89531 time= 0.42192\n",
            "Epoch: 0099 train_loss= 0.43593 train_acc= 0.57425 val_roc= 0.87671 val_ap= 0.89521 time= 0.43322\n",
            "Epoch: 0100 train_loss= 0.43573 train_acc= 0.57471 val_roc= 0.87643 val_ap= 0.89513 time= 0.42131\n",
            "Epoch: 0101 train_loss= 0.43553 train_acc= 0.57515 val_roc= 0.87621 val_ap= 0.89510 time= 0.42045\n",
            "Epoch: 0102 train_loss= 0.43533 train_acc= 0.57564 val_roc= 0.87616 val_ap= 0.89512 time= 0.40350\n",
            "Epoch: 0103 train_loss= 0.43514 train_acc= 0.57609 val_roc= 0.87595 val_ap= 0.89501 time= 0.41078\n",
            "Epoch: 0104 train_loss= 0.43496 train_acc= 0.57656 val_roc= 0.87579 val_ap= 0.89497 time= 0.41125\n",
            "Epoch: 0105 train_loss= 0.43478 train_acc= 0.57705 val_roc= 0.87563 val_ap= 0.89497 time= 0.40137\n",
            "Epoch: 0106 train_loss= 0.43460 train_acc= 0.57747 val_roc= 0.87540 val_ap= 0.89485 time= 0.41434\n",
            "Epoch: 0107 train_loss= 0.43443 train_acc= 0.57797 val_roc= 0.87528 val_ap= 0.89490 time= 0.40515\n",
            "Epoch: 0108 train_loss= 0.43426 train_acc= 0.57838 val_roc= 0.87526 val_ap= 0.89486 time= 0.41084\n",
            "Epoch: 0109 train_loss= 0.43410 train_acc= 0.57877 val_roc= 0.87515 val_ap= 0.89485 time= 0.41463\n",
            "Epoch: 0110 train_loss= 0.43393 train_acc= 0.57921 val_roc= 0.87502 val_ap= 0.89485 time= 0.42971\n",
            "Epoch: 0111 train_loss= 0.43377 train_acc= 0.57963 val_roc= 0.87484 val_ap= 0.89486 time= 0.43674\n",
            "Epoch: 0112 train_loss= 0.43362 train_acc= 0.58000 val_roc= 0.87468 val_ap= 0.89484 time= 0.44389\n",
            "Epoch: 0113 train_loss= 0.43346 train_acc= 0.58037 val_roc= 0.87447 val_ap= 0.89476 time= 0.44739\n",
            "Epoch: 0114 train_loss= 0.43331 train_acc= 0.58075 val_roc= 0.87422 val_ap= 0.89462 time= 0.42551\n",
            "Epoch: 0115 train_loss= 0.43316 train_acc= 0.58111 val_roc= 0.87403 val_ap= 0.89453 time= 0.43376\n",
            "Epoch: 0116 train_loss= 0.43301 train_acc= 0.58144 val_roc= 0.87381 val_ap= 0.89443 time= 0.41124\n",
            "Epoch: 0117 train_loss= 0.43287 train_acc= 0.58181 val_roc= 0.87369 val_ap= 0.89434 time= 0.41169\n",
            "Epoch: 0118 train_loss= 0.43272 train_acc= 0.58216 val_roc= 0.87349 val_ap= 0.89424 time= 0.42045\n",
            "Epoch: 0119 train_loss= 0.43258 train_acc= 0.58259 val_roc= 0.87331 val_ap= 0.89420 time= 0.40605\n",
            "Epoch: 0120 train_loss= 0.43244 train_acc= 0.58298 val_roc= 0.87328 val_ap= 0.89426 time= 0.41579\n",
            "Epoch: 0121 train_loss= 0.43231 train_acc= 0.58331 val_roc= 0.87310 val_ap= 0.89412 time= 0.41172\n",
            "Epoch: 0122 train_loss= 0.43217 train_acc= 0.58365 val_roc= 0.87312 val_ap= 0.89416 time= 0.42650\n",
            "Epoch: 0123 train_loss= 0.43204 train_acc= 0.58397 val_roc= 0.87292 val_ap= 0.89409 time= 0.41265\n",
            "Epoch: 0124 train_loss= 0.43191 train_acc= 0.58431 val_roc= 0.87277 val_ap= 0.89404 time= 0.41293\n",
            "Epoch: 0125 train_loss= 0.43178 train_acc= 0.58460 val_roc= 0.87272 val_ap= 0.89406 time= 0.41405\n",
            "Epoch: 0126 train_loss= 0.43166 train_acc= 0.58495 val_roc= 0.87249 val_ap= 0.89394 time= 0.41841\n",
            "Epoch: 0127 train_loss= 0.43153 train_acc= 0.58531 val_roc= 0.87234 val_ap= 0.89386 time= 0.42041\n",
            "Epoch: 0128 train_loss= 0.43141 train_acc= 0.58570 val_roc= 0.87217 val_ap= 0.89375 time= 0.43730\n",
            "Epoch: 0129 train_loss= 0.43129 train_acc= 0.58602 val_roc= 0.87183 val_ap= 0.89361 time= 0.41372\n",
            "Epoch: 0130 train_loss= 0.43118 train_acc= 0.58642 val_roc= 0.87169 val_ap= 0.89353 time= 0.40701\n",
            "Epoch: 0131 train_loss= 0.43106 train_acc= 0.58678 val_roc= 0.87164 val_ap= 0.89361 time= 0.40666\n",
            "Epoch: 0132 train_loss= 0.43095 train_acc= 0.58713 val_roc= 0.87147 val_ap= 0.89354 time= 0.41995\n",
            "Epoch: 0133 train_loss= 0.43084 train_acc= 0.58745 val_roc= 0.87140 val_ap= 0.89356 time= 0.40752\n",
            "Epoch: 0134 train_loss= 0.43073 train_acc= 0.58778 val_roc= 0.87124 val_ap= 0.89342 time= 0.40164\n",
            "Epoch: 0135 train_loss= 0.43062 train_acc= 0.58813 val_roc= 0.87111 val_ap= 0.89341 time= 0.41018\n",
            "Epoch: 0136 train_loss= 0.43051 train_acc= 0.58850 val_roc= 0.87099 val_ap= 0.89336 time= 0.42519\n",
            "Epoch: 0137 train_loss= 0.43041 train_acc= 0.58888 val_roc= 0.87097 val_ap= 0.89342 time= 0.44457\n",
            "Epoch: 0138 train_loss= 0.43030 train_acc= 0.58922 val_roc= 0.87094 val_ap= 0.89348 time= 0.42867\n",
            "Epoch: 0139 train_loss= 0.43020 train_acc= 0.58961 val_roc= 0.87078 val_ap= 0.89346 time= 0.43720\n",
            "Epoch: 0140 train_loss= 0.43010 train_acc= 0.58996 val_roc= 0.87067 val_ap= 0.89343 time= 0.43551\n",
            "Epoch: 0141 train_loss= 0.43000 train_acc= 0.59026 val_roc= 0.87069 val_ap= 0.89350 time= 0.40349\n",
            "Epoch: 0142 train_loss= 0.42990 train_acc= 0.59062 val_roc= 0.87068 val_ap= 0.89360 time= 0.41001\n",
            "Epoch: 0143 train_loss= 0.42980 train_acc= 0.59100 val_roc= 0.87067 val_ap= 0.89362 time= 0.42000\n",
            "Epoch: 0144 train_loss= 0.42970 train_acc= 0.59134 val_roc= 0.87053 val_ap= 0.89356 time= 0.44029\n",
            "Epoch: 0145 train_loss= 0.42960 train_acc= 0.59176 val_roc= 0.87049 val_ap= 0.89348 time= 0.40382\n",
            "Epoch: 0146 train_loss= 0.42950 train_acc= 0.59215 val_roc= 0.87044 val_ap= 0.89345 time= 0.44399\n",
            "Epoch: 0147 train_loss= 0.42940 train_acc= 0.59255 val_roc= 0.87044 val_ap= 0.89347 time= 0.44966\n",
            "Epoch: 0148 train_loss= 0.42931 train_acc= 0.59295 val_roc= 0.87045 val_ap= 0.89351 time= 0.40664\n",
            "Epoch: 0149 train_loss= 0.42921 train_acc= 0.59336 val_roc= 0.87035 val_ap= 0.89342 time= 0.41233\n",
            "Epoch: 0150 train_loss= 0.42911 train_acc= 0.59381 val_roc= 0.87037 val_ap= 0.89343 time= 0.41190\n",
            "Epoch: 0151 train_loss= 0.42901 train_acc= 0.59425 val_roc= 0.87050 val_ap= 0.89359 time= 0.43827\n",
            "Epoch: 0152 train_loss= 0.42891 train_acc= 0.59462 val_roc= 0.87053 val_ap= 0.89368 time= 0.41888\n",
            "Epoch: 0153 train_loss= 0.42881 train_acc= 0.59506 val_roc= 0.87064 val_ap= 0.89381 time= 0.40387\n",
            "Epoch: 0154 train_loss= 0.42871 train_acc= 0.59551 val_roc= 0.87075 val_ap= 0.89395 time= 0.41498\n",
            "Epoch: 0155 train_loss= 0.42861 train_acc= 0.59592 val_roc= 0.87083 val_ap= 0.89410 time= 0.41045\n",
            "Epoch: 0156 train_loss= 0.42851 train_acc= 0.59639 val_roc= 0.87080 val_ap= 0.89411 time= 0.41116\n",
            "Epoch: 0157 train_loss= 0.42841 train_acc= 0.59682 val_roc= 0.87086 val_ap= 0.89415 time= 0.40700\n",
            "Epoch: 0158 train_loss= 0.42831 train_acc= 0.59725 val_roc= 0.87087 val_ap= 0.89420 time= 0.40758\n",
            "Epoch: 0159 train_loss= 0.42821 train_acc= 0.59772 val_roc= 0.87090 val_ap= 0.89421 time= 0.41442\n",
            "Epoch: 0160 train_loss= 0.42811 train_acc= 0.59817 val_roc= 0.87103 val_ap= 0.89432 time= 0.40168\n",
            "Epoch: 0161 train_loss= 0.42801 train_acc= 0.59860 val_roc= 0.87115 val_ap= 0.89440 time= 0.40749\n",
            "Epoch: 0162 train_loss= 0.42791 train_acc= 0.59901 val_roc= 0.87117 val_ap= 0.89444 time= 0.40648\n",
            "Epoch: 0163 train_loss= 0.42781 train_acc= 0.59944 val_roc= 0.87123 val_ap= 0.89451 time= 0.40573\n",
            "Epoch: 0164 train_loss= 0.42770 train_acc= 0.59990 val_roc= 0.87123 val_ap= 0.89451 time= 0.41720\n",
            "Epoch: 0165 train_loss= 0.42760 train_acc= 0.60039 val_roc= 0.87130 val_ap= 0.89457 time= 0.40131\n",
            "Epoch: 0166 train_loss= 0.42751 train_acc= 0.60086 val_roc= 0.87130 val_ap= 0.89458 time= 0.41110\n",
            "Epoch: 0167 train_loss= 0.42741 train_acc= 0.60135 val_roc= 0.87137 val_ap= 0.89465 time= 0.42054\n",
            "Epoch: 0168 train_loss= 0.42731 train_acc= 0.60183 val_roc= 0.87151 val_ap= 0.89486 time= 0.41942\n",
            "Epoch: 0169 train_loss= 0.42721 train_acc= 0.60232 val_roc= 0.87167 val_ap= 0.89503 time= 0.41167\n",
            "Epoch: 0170 train_loss= 0.42711 train_acc= 0.60282 val_roc= 0.87176 val_ap= 0.89512 time= 0.40506\n",
            "Epoch: 0171 train_loss= 0.42701 train_acc= 0.60329 val_roc= 0.87185 val_ap= 0.89522 time= 0.41371\n",
            "Epoch: 0172 train_loss= 0.42691 train_acc= 0.60374 val_roc= 0.87195 val_ap= 0.89525 time= 0.40248\n",
            "Epoch: 0173 train_loss= 0.42681 train_acc= 0.60421 val_roc= 0.87210 val_ap= 0.89534 time= 0.41812\n",
            "Epoch: 0174 train_loss= 0.42672 train_acc= 0.60469 val_roc= 0.87219 val_ap= 0.89544 time= 0.41615\n",
            "Epoch: 0175 train_loss= 0.42662 train_acc= 0.60517 val_roc= 0.87204 val_ap= 0.89538 time= 0.40494\n",
            "Epoch: 0176 train_loss= 0.42652 train_acc= 0.60569 val_roc= 0.87201 val_ap= 0.89541 time= 0.41022\n",
            "Epoch: 0177 train_loss= 0.42642 train_acc= 0.60619 val_roc= 0.87212 val_ap= 0.89552 time= 0.41631\n",
            "Epoch: 0178 train_loss= 0.42633 train_acc= 0.60666 val_roc= 0.87212 val_ap= 0.89548 time= 0.40830\n",
            "Epoch: 0179 train_loss= 0.42623 train_acc= 0.60715 val_roc= 0.87226 val_ap= 0.89555 time= 0.40369\n",
            "Epoch: 0180 train_loss= 0.42613 train_acc= 0.60762 val_roc= 0.87235 val_ap= 0.89560 time= 0.43723\n",
            "Epoch: 0181 train_loss= 0.42603 train_acc= 0.60813 val_roc= 0.87232 val_ap= 0.89555 time= 0.44192\n",
            "Epoch: 0182 train_loss= 0.42594 train_acc= 0.60859 val_roc= 0.87228 val_ap= 0.89550 time= 0.43427\n",
            "Epoch: 0183 train_loss= 0.42584 train_acc= 0.60908 val_roc= 0.87222 val_ap= 0.89543 time= 0.43178\n",
            "Epoch: 0184 train_loss= 0.42574 train_acc= 0.60961 val_roc= 0.87220 val_ap= 0.89542 time= 0.39992\n",
            "Epoch: 0185 train_loss= 0.42564 train_acc= 0.61014 val_roc= 0.87215 val_ap= 0.89536 time= 0.40811\n",
            "Epoch: 0186 train_loss= 0.42554 train_acc= 0.61069 val_roc= 0.87215 val_ap= 0.89536 time= 0.41361\n",
            "Epoch: 0187 train_loss= 0.42544 train_acc= 0.61125 val_roc= 0.87200 val_ap= 0.89527 time= 0.40022\n",
            "Epoch: 0188 train_loss= 0.42534 train_acc= 0.61178 val_roc= 0.87196 val_ap= 0.89525 time= 0.40882\n",
            "Epoch: 0189 train_loss= 0.42524 train_acc= 0.61233 val_roc= 0.87200 val_ap= 0.89526 time= 0.41712\n",
            "Epoch: 0190 train_loss= 0.42514 train_acc= 0.61292 val_roc= 0.87201 val_ap= 0.89520 time= 0.41446\n",
            "Epoch: 0191 train_loss= 0.42505 train_acc= 0.61350 val_roc= 0.87201 val_ap= 0.89526 time= 0.40213\n",
            "Epoch: 0192 train_loss= 0.42495 train_acc= 0.61408 val_roc= 0.87190 val_ap= 0.89523 time= 0.40424\n",
            "Epoch: 0193 train_loss= 0.42485 train_acc= 0.61468 val_roc= 0.87181 val_ap= 0.89512 time= 0.40980\n",
            "Epoch: 0194 train_loss= 0.42475 train_acc= 0.61533 val_roc= 0.87183 val_ap= 0.89514 time= 0.40818\n",
            "Epoch: 0195 train_loss= 0.42465 train_acc= 0.61596 val_roc= 0.87187 val_ap= 0.89516 time= 0.41523\n",
            "Epoch: 0196 train_loss= 0.42455 train_acc= 0.61665 val_roc= 0.87185 val_ap= 0.89515 time= 0.40336\n",
            "Epoch: 0197 train_loss= 0.42445 train_acc= 0.61733 val_roc= 0.87190 val_ap= 0.89516 time= 0.41630\n",
            "Epoch: 0198 train_loss= 0.42436 train_acc= 0.61799 val_roc= 0.87175 val_ap= 0.89504 time= 0.43009\n",
            "Epoch: 0199 train_loss= 0.42426 train_acc= 0.61866 val_roc= 0.87159 val_ap= 0.89498 time= 0.40539\n",
            "Epoch: 0200 train_loss= 0.42416 train_acc= 0.61936 val_roc= 0.87146 val_ap= 0.89481 time= 0.41515\n",
            "Epoch: 0201 train_loss= 0.42407 train_acc= 0.62007 val_roc= 0.87144 val_ap= 0.89484 time= 0.40385\n",
            "Epoch: 0202 train_loss= 0.42397 train_acc= 0.62076 val_roc= 0.87127 val_ap= 0.89466 time= 0.40652\n",
            "Epoch: 0203 train_loss= 0.42388 train_acc= 0.62143 val_roc= 0.87117 val_ap= 0.89455 time= 0.41571\n",
            "Epoch: 0204 train_loss= 0.42379 train_acc= 0.62220 val_roc= 0.87101 val_ap= 0.89441 time= 0.43526\n",
            "Epoch: 0205 train_loss= 0.42370 train_acc= 0.62290 val_roc= 0.87089 val_ap= 0.89432 time= 0.44520\n",
            "Epoch: 0206 train_loss= 0.42361 train_acc= 0.62360 val_roc= 0.87084 val_ap= 0.89430 time= 0.41723\n",
            "Epoch: 0207 train_loss= 0.42352 train_acc= 0.62435 val_roc= 0.87073 val_ap= 0.89425 time= 0.44854\n",
            "Epoch: 0208 train_loss= 0.42343 train_acc= 0.62504 val_roc= 0.87052 val_ap= 0.89415 time= 0.41467\n",
            "Epoch: 0209 train_loss= 0.42335 train_acc= 0.62578 val_roc= 0.87030 val_ap= 0.89394 time= 0.41117\n",
            "Epoch: 0210 train_loss= 0.42326 train_acc= 0.62657 val_roc= 0.87014 val_ap= 0.89379 time= 0.41241\n",
            "Epoch: 0211 train_loss= 0.42318 train_acc= 0.62732 val_roc= 0.87001 val_ap= 0.89375 time= 0.43744\n",
            "Epoch: 0212 train_loss= 0.42310 train_acc= 0.62804 val_roc= 0.86994 val_ap= 0.89368 time= 0.42989\n",
            "Epoch: 0213 train_loss= 0.42302 train_acc= 0.62880 val_roc= 0.86977 val_ap= 0.89351 time= 0.44030\n",
            "Epoch: 0214 train_loss= 0.42294 train_acc= 0.62954 val_roc= 0.86967 val_ap= 0.89335 time= 0.43185\n",
            "Epoch: 0215 train_loss= 0.42286 train_acc= 0.63028 val_roc= 0.86949 val_ap= 0.89326 time= 0.42041\n",
            "Epoch: 0216 train_loss= 0.42279 train_acc= 0.63101 val_roc= 0.86928 val_ap= 0.89317 time= 0.40997\n",
            "Epoch: 0217 train_loss= 0.42271 train_acc= 0.63174 val_roc= 0.86910 val_ap= 0.89306 time= 0.41200\n",
            "Epoch: 0218 train_loss= 0.42263 train_acc= 0.63247 val_roc= 0.86894 val_ap= 0.89295 time= 0.43187\n",
            "Epoch: 0219 train_loss= 0.42256 train_acc= 0.63318 val_roc= 0.86870 val_ap= 0.89280 time= 0.40842\n",
            "Epoch: 0220 train_loss= 0.42249 train_acc= 0.63388 val_roc= 0.86855 val_ap= 0.89267 time= 0.40464\n",
            "Epoch: 0221 train_loss= 0.42242 train_acc= 0.63458 val_roc= 0.86836 val_ap= 0.89258 time= 0.40916\n",
            "Epoch: 0222 train_loss= 0.42234 train_acc= 0.63528 val_roc= 0.86811 val_ap= 0.89242 time= 0.41407\n",
            "Epoch: 0223 train_loss= 0.42227 train_acc= 0.63597 val_roc= 0.86800 val_ap= 0.89234 time= 0.40557\n",
            "Epoch: 0224 train_loss= 0.42220 train_acc= 0.63667 val_roc= 0.86774 val_ap= 0.89215 time= 0.41153\n",
            "Epoch: 0225 train_loss= 0.42213 train_acc= 0.63738 val_roc= 0.86760 val_ap= 0.89209 time= 0.41207\n",
            "Epoch: 0226 train_loss= 0.42206 train_acc= 0.63813 val_roc= 0.86753 val_ap= 0.89203 time= 0.41139\n",
            "Epoch: 0227 train_loss= 0.42198 train_acc= 0.63885 val_roc= 0.86741 val_ap= 0.89200 time= 0.41298\n",
            "Epoch: 0228 train_loss= 0.42191 train_acc= 0.63955 val_roc= 0.86723 val_ap= 0.89191 time= 0.40556\n",
            "Epoch: 0229 train_loss= 0.42184 train_acc= 0.64026 val_roc= 0.86718 val_ap= 0.89188 time= 0.41112\n",
            "Epoch: 0230 train_loss= 0.42177 train_acc= 0.64094 val_roc= 0.86704 val_ap= 0.89179 time= 0.41199\n",
            "Epoch: 0231 train_loss= 0.42170 train_acc= 0.64161 val_roc= 0.86693 val_ap= 0.89175 time= 0.40476\n",
            "Epoch: 0232 train_loss= 0.42163 train_acc= 0.64231 val_roc= 0.86678 val_ap= 0.89172 time= 0.41290\n",
            "Epoch: 0233 train_loss= 0.42156 train_acc= 0.64301 val_roc= 0.86673 val_ap= 0.89171 time= 0.40320\n",
            "Epoch: 0234 train_loss= 0.42148 train_acc= 0.64369 val_roc= 0.86653 val_ap= 0.89160 time= 0.41858\n",
            "Epoch: 0235 train_loss= 0.42141 train_acc= 0.64443 val_roc= 0.86644 val_ap= 0.89159 time= 0.42494\n",
            "Epoch: 0236 train_loss= 0.42134 train_acc= 0.64512 val_roc= 0.86629 val_ap= 0.89154 time= 0.41239\n",
            "Epoch: 0237 train_loss= 0.42126 train_acc= 0.64582 val_roc= 0.86610 val_ap= 0.89148 time= 0.42646\n",
            "Epoch: 0238 train_loss= 0.42119 train_acc= 0.64657 val_roc= 0.86594 val_ap= 0.89135 time= 0.43577\n",
            "Epoch: 0239 train_loss= 0.42112 train_acc= 0.64731 val_roc= 0.86591 val_ap= 0.89133 time= 0.41520\n",
            "Epoch: 0240 train_loss= 0.42104 train_acc= 0.64800 val_roc= 0.86579 val_ap= 0.89128 time= 0.40972\n",
            "Epoch: 0241 train_loss= 0.42097 train_acc= 0.64872 val_roc= 0.86572 val_ap= 0.89129 time= 0.41862\n",
            "Epoch: 0242 train_loss= 0.42089 train_acc= 0.64942 val_roc= 0.86561 val_ap= 0.89126 time= 0.43546\n",
            "Epoch: 0243 train_loss= 0.42082 train_acc= 0.65012 val_roc= 0.86542 val_ap= 0.89112 time= 0.44356\n",
            "Epoch: 0244 train_loss= 0.42074 train_acc= 0.65084 val_roc= 0.86518 val_ap= 0.89092 time= 0.41847\n",
            "Epoch: 0245 train_loss= 0.42067 train_acc= 0.65151 val_roc= 0.86507 val_ap= 0.89086 time= 0.42593\n",
            "Epoch: 0246 train_loss= 0.42059 train_acc= 0.65223 val_roc= 0.86494 val_ap= 0.89084 time= 0.43754\n",
            "Epoch: 0247 train_loss= 0.42052 train_acc= 0.65294 val_roc= 0.86476 val_ap= 0.89075 time= 0.42219\n",
            "Epoch: 0248 train_loss= 0.42044 train_acc= 0.65363 val_roc= 0.86459 val_ap= 0.89067 time= 0.40788\n",
            "Epoch: 0249 train_loss= 0.42037 train_acc= 0.65434 val_roc= 0.86446 val_ap= 0.89065 time= 0.40979\n",
            "Epoch: 0250 train_loss= 0.42029 train_acc= 0.65505 val_roc= 0.86437 val_ap= 0.89067 time= 0.41050\n",
            "Epoch: 0251 train_loss= 0.42022 train_acc= 0.65575 val_roc= 0.86420 val_ap= 0.89061 time= 0.40907\n",
            "Epoch: 0252 train_loss= 0.42014 train_acc= 0.65645 val_roc= 0.86402 val_ap= 0.89054 time= 0.40506\n",
            "Epoch: 0253 train_loss= 0.42007 train_acc= 0.65717 val_roc= 0.86398 val_ap= 0.89054 time= 0.40536\n",
            "Epoch: 0254 train_loss= 0.42000 train_acc= 0.65786 val_roc= 0.86368 val_ap= 0.89038 time= 0.42268\n",
            "Epoch: 0255 train_loss= 0.41993 train_acc= 0.65858 val_roc= 0.86348 val_ap= 0.89029 time= 0.40531\n",
            "Epoch: 0256 train_loss= 0.41986 train_acc= 0.65933 val_roc= 0.86337 val_ap= 0.89024 time= 0.41735\n",
            "Epoch: 0257 train_loss= 0.41979 train_acc= 0.66000 val_roc= 0.86312 val_ap= 0.89012 time= 0.40542\n",
            "Epoch: 0258 train_loss= 0.41972 train_acc= 0.66071 val_roc= 0.86283 val_ap= 0.88990 time= 0.41552\n",
            "Epoch: 0259 train_loss= 0.41965 train_acc= 0.66144 val_roc= 0.86269 val_ap= 0.88981 time= 0.40377\n",
            "Epoch: 0260 train_loss= 0.41958 train_acc= 0.66216 val_roc= 0.86247 val_ap= 0.88964 time= 0.40865\n",
            "Epoch: 0261 train_loss= 0.41952 train_acc= 0.66284 val_roc= 0.86225 val_ap= 0.88957 time= 0.41348\n",
            "Epoch: 0262 train_loss= 0.41945 train_acc= 0.66358 val_roc= 0.86201 val_ap= 0.88946 time= 0.40507\n",
            "Epoch: 0263 train_loss= 0.41939 train_acc= 0.66428 val_roc= 0.86178 val_ap= 0.88936 time= 0.41282\n",
            "Epoch: 0264 train_loss= 0.41933 train_acc= 0.66502 val_roc= 0.86143 val_ap= 0.88922 time= 0.40493\n",
            "Epoch: 0265 train_loss= 0.41926 train_acc= 0.66575 val_roc= 0.86123 val_ap= 0.88906 time= 0.41006\n",
            "Epoch: 0266 train_loss= 0.41920 train_acc= 0.66647 val_roc= 0.86105 val_ap= 0.88893 time= 0.43268\n",
            "Epoch: 0267 train_loss= 0.41914 train_acc= 0.66716 val_roc= 0.86102 val_ap= 0.88889 time= 0.44062\n",
            "Epoch: 0268 train_loss= 0.41908 train_acc= 0.66786 val_roc= 0.86079 val_ap= 0.88872 time= 0.40903\n",
            "Epoch: 0269 train_loss= 0.41903 train_acc= 0.66859 val_roc= 0.86069 val_ap= 0.88866 time= 0.40397\n",
            "Epoch: 0270 train_loss= 0.41897 train_acc= 0.66928 val_roc= 0.86043 val_ap= 0.88852 time= 0.40876\n",
            "Epoch: 0271 train_loss= 0.41891 train_acc= 0.67003 val_roc= 0.86026 val_ap= 0.88840 time= 0.41121\n",
            "Epoch: 0272 train_loss= 0.41886 train_acc= 0.67076 val_roc= 0.86001 val_ap= 0.88828 time= 0.41025\n",
            "Epoch: 0273 train_loss= 0.41880 train_acc= 0.67152 val_roc= 0.85975 val_ap= 0.88812 time= 0.41151\n",
            "Epoch: 0274 train_loss= 0.41875 train_acc= 0.67227 val_roc= 0.85954 val_ap= 0.88799 time= 0.41280\n",
            "Epoch: 0275 train_loss= 0.41870 train_acc= 0.67303 val_roc= 0.85935 val_ap= 0.88791 time= 0.41278\n",
            "Epoch: 0276 train_loss= 0.41865 train_acc= 0.67382 val_roc= 0.85904 val_ap= 0.88767 time= 0.43750\n",
            "Epoch: 0277 train_loss= 0.41860 train_acc= 0.67460 val_roc= 0.85869 val_ap= 0.88747 time= 0.42481\n",
            "Epoch: 0278 train_loss= 0.41855 train_acc= 0.67543 val_roc= 0.85851 val_ap= 0.88736 time= 0.44349\n",
            "Epoch: 0279 train_loss= 0.41849 train_acc= 0.67625 val_roc= 0.85836 val_ap= 0.88730 time= 0.43096\n",
            "Epoch: 0280 train_loss= 0.41845 train_acc= 0.67703 val_roc= 0.85808 val_ap= 0.88708 time= 0.41117\n",
            "Epoch: 0281 train_loss= 0.41840 train_acc= 0.67784 val_roc= 0.85796 val_ap= 0.88698 time= 0.43334\n",
            "Epoch: 0282 train_loss= 0.41835 train_acc= 0.67861 val_roc= 0.85785 val_ap= 0.88691 time= 0.43249\n",
            "Epoch: 0283 train_loss= 0.41830 train_acc= 0.67942 val_roc= 0.85769 val_ap= 0.88683 time= 0.41837\n",
            "Epoch: 0284 train_loss= 0.41826 train_acc= 0.68027 val_roc= 0.85758 val_ap= 0.88675 time= 0.41835\n",
            "Epoch: 0285 train_loss= 0.41821 train_acc= 0.68114 val_roc= 0.85731 val_ap= 0.88653 time= 0.41130\n",
            "Epoch: 0286 train_loss= 0.41816 train_acc= 0.68198 val_roc= 0.85711 val_ap= 0.88636 time= 0.40598\n",
            "Epoch: 0287 train_loss= 0.41811 train_acc= 0.68280 val_roc= 0.85687 val_ap= 0.88613 time= 0.41601\n",
            "Epoch: 0288 train_loss= 0.41806 train_acc= 0.68365 val_roc= 0.85677 val_ap= 0.88603 time= 0.40136\n",
            "Epoch: 0289 train_loss= 0.41802 train_acc= 0.68458 val_roc= 0.85658 val_ap= 0.88591 time= 0.42045\n",
            "Epoch: 0290 train_loss= 0.41797 train_acc= 0.68545 val_roc= 0.85634 val_ap= 0.88569 time= 0.42211\n",
            "Epoch: 0291 train_loss= 0.41792 train_acc= 0.68631 val_roc= 0.85622 val_ap= 0.88558 time= 0.41959\n",
            "Epoch: 0292 train_loss= 0.41787 train_acc= 0.68722 val_roc= 0.85604 val_ap= 0.88540 time= 0.40988\n",
            "Epoch: 0293 train_loss= 0.41782 train_acc= 0.68811 val_roc= 0.85561 val_ap= 0.88507 time= 0.40340\n",
            "Epoch: 0294 train_loss= 0.41777 train_acc= 0.68898 val_roc= 0.85542 val_ap= 0.88486 time= 0.40399\n",
            "Epoch: 0295 train_loss= 0.41772 train_acc= 0.68985 val_roc= 0.85522 val_ap= 0.88471 time= 0.41109\n",
            "Epoch: 0296 train_loss= 0.41767 train_acc= 0.69078 val_roc= 0.85509 val_ap= 0.88461 time= 0.40470\n",
            "Epoch: 0297 train_loss= 0.41762 train_acc= 0.69170 val_roc= 0.85493 val_ap= 0.88447 time= 0.43144\n",
            "Epoch: 0298 train_loss= 0.41757 train_acc= 0.69262 val_roc= 0.85470 val_ap= 0.88425 time= 0.42798\n",
            "Epoch: 0299 train_loss= 0.41752 train_acc= 0.69353 val_roc= 0.85459 val_ap= 0.88418 time= 0.42333\n",
            "Epoch: 0300 train_loss= 0.41747 train_acc= 0.69444 val_roc= 0.85444 val_ap= 0.88409 time= 0.44137\n",
            "Epoch: 0301 train_loss= 0.41742 train_acc= 0.69538 val_roc= 0.85423 val_ap= 0.88395 time= 0.42223\n",
            "Epoch: 0302 train_loss= 0.41736 train_acc= 0.69631 val_roc= 0.85405 val_ap= 0.88378 time= 0.43925\n",
            "Epoch: 0303 train_loss= 0.41731 train_acc= 0.69727 val_roc= 0.85388 val_ap= 0.88361 time= 0.42584\n",
            "Epoch: 0304 train_loss= 0.41726 train_acc= 0.69821 val_roc= 0.85372 val_ap= 0.88349 time= 0.40619\n",
            "Epoch: 0305 train_loss= 0.41720 train_acc= 0.69919 val_roc= 0.85344 val_ap= 0.88326 time= 0.40055\n",
            "Epoch: 0306 train_loss= 0.41715 train_acc= 0.70010 val_roc= 0.85325 val_ap= 0.88303 time= 0.43020\n",
            "Epoch: 0307 train_loss= 0.41709 train_acc= 0.70106 val_roc= 0.85309 val_ap= 0.88290 time= 0.43323\n",
            "Epoch: 0308 train_loss= 0.41704 train_acc= 0.70200 val_roc= 0.85293 val_ap= 0.88273 time= 0.40055\n",
            "Epoch: 0309 train_loss= 0.41698 train_acc= 0.70298 val_roc= 0.85266 val_ap= 0.88255 time= 0.41260\n",
            "Epoch: 0310 train_loss= 0.41693 train_acc= 0.70397 val_roc= 0.85242 val_ap= 0.88239 time= 0.43705\n",
            "Epoch: 0311 train_loss= 0.41687 train_acc= 0.70495 val_roc= 0.85228 val_ap= 0.88225 time= 0.40401\n",
            "Epoch: 0312 train_loss= 0.41681 train_acc= 0.70594 val_roc= 0.85213 val_ap= 0.88211 time= 0.40834\n",
            "Epoch: 0313 train_loss= 0.41675 train_acc= 0.70692 val_roc= 0.85193 val_ap= 0.88199 time= 0.40257\n",
            "Epoch: 0314 train_loss= 0.41669 train_acc= 0.70789 val_roc= 0.85172 val_ap= 0.88183 time= 0.40621\n",
            "Epoch: 0315 train_loss= 0.41663 train_acc= 0.70888 val_roc= 0.85143 val_ap= 0.88159 time= 0.40580\n",
            "Epoch: 0316 train_loss= 0.41657 train_acc= 0.70983 val_roc= 0.85125 val_ap= 0.88142 time= 0.41336\n",
            "Epoch: 0317 train_loss= 0.41651 train_acc= 0.71085 val_roc= 0.85117 val_ap= 0.88131 time= 0.41663\n",
            "Epoch: 0318 train_loss= 0.41645 train_acc= 0.71188 val_roc= 0.85094 val_ap= 0.88116 time= 0.40590\n",
            "Epoch: 0319 train_loss= 0.41639 train_acc= 0.71288 val_roc= 0.85058 val_ap= 0.88092 time= 0.42873\n",
            "Epoch: 0320 train_loss= 0.41633 train_acc= 0.71387 val_roc= 0.85037 val_ap= 0.88075 time= 0.40316\n",
            "Epoch: 0321 train_loss= 0.41626 train_acc= 0.71493 val_roc= 0.85000 val_ap= 0.88048 time= 0.40978\n",
            "Epoch: 0322 train_loss= 0.41620 train_acc= 0.71597 val_roc= 0.84989 val_ap= 0.88041 time= 0.41288\n",
            "Epoch: 0323 train_loss= 0.41613 train_acc= 0.71700 val_roc= 0.84967 val_ap= 0.88025 time= 0.40514\n",
            "Epoch: 0324 train_loss= 0.41607 train_acc= 0.71809 val_roc= 0.84938 val_ap= 0.88006 time= 0.41310\n",
            "Epoch: 0325 train_loss= 0.41600 train_acc= 0.71918 val_roc= 0.84922 val_ap= 0.87994 time= 0.40543\n",
            "Epoch: 0326 train_loss= 0.41593 train_acc= 0.72027 val_roc= 0.84909 val_ap= 0.87986 time= 0.41504\n",
            "Epoch: 0327 train_loss= 0.41587 train_acc= 0.72135 val_roc= 0.84893 val_ap= 0.87973 time= 0.40453\n",
            "Epoch: 0328 train_loss= 0.41580 train_acc= 0.72244 val_roc= 0.84878 val_ap= 0.87957 time= 0.40388\n",
            "Epoch: 0329 train_loss= 0.41573 train_acc= 0.72348 val_roc= 0.84850 val_ap= 0.87936 time= 0.41552\n",
            "Epoch: 0330 train_loss= 0.41566 train_acc= 0.72455 val_roc= 0.84811 val_ap= 0.87909 time= 0.40235\n",
            "Epoch: 0331 train_loss= 0.41559 train_acc= 0.72563 val_roc= 0.84784 val_ap= 0.87887 time= 0.40820\n",
            "Epoch: 0332 train_loss= 0.41552 train_acc= 0.72674 val_roc= 0.84755 val_ap= 0.87868 time= 0.41529\n",
            "Epoch: 0333 train_loss= 0.41545 train_acc= 0.72781 val_roc= 0.84736 val_ap= 0.87852 time= 0.40829\n",
            "Epoch: 0334 train_loss= 0.41538 train_acc= 0.72894 val_roc= 0.84708 val_ap= 0.87834 time= 0.41387\n",
            "Epoch: 0335 train_loss= 0.41530 train_acc= 0.73004 val_roc= 0.84687 val_ap= 0.87814 time= 0.40348\n",
            "Epoch: 0336 train_loss= 0.41523 train_acc= 0.73115 val_roc= 0.84691 val_ap= 0.87811 time= 0.41480\n",
            "Epoch: 0337 train_loss= 0.41516 train_acc= 0.73222 val_roc= 0.84676 val_ap= 0.87798 time= 0.40490\n",
            "Epoch: 0338 train_loss= 0.41509 train_acc= 0.73331 val_roc= 0.84664 val_ap= 0.87780 time= 0.40421\n",
            "Epoch: 0339 train_loss= 0.41501 train_acc= 0.73444 val_roc= 0.84658 val_ap= 0.87770 time= 0.41000\n",
            "Epoch: 0340 train_loss= 0.41494 train_acc= 0.73562 val_roc= 0.84638 val_ap= 0.87752 time= 0.41120\n",
            "Epoch: 0341 train_loss= 0.41486 train_acc= 0.73676 val_roc= 0.84624 val_ap= 0.87737 time= 0.40411\n",
            "Epoch: 0342 train_loss= 0.41479 train_acc= 0.73787 val_roc= 0.84606 val_ap= 0.87720 time= 0.40403\n",
            "Epoch: 0343 train_loss= 0.41471 train_acc= 0.73900 val_roc= 0.84591 val_ap= 0.87710 time= 0.40600\n",
            "Epoch: 0344 train_loss= 0.41464 train_acc= 0.74015 val_roc= 0.84576 val_ap= 0.87691 time= 0.40989\n",
            "Epoch: 0345 train_loss= 0.41456 train_acc= 0.74128 val_roc= 0.84564 val_ap= 0.87675 time= 0.40575\n",
            "Epoch: 0346 train_loss= 0.41449 train_acc= 0.74243 val_roc= 0.84559 val_ap= 0.87667 time= 0.42161\n",
            "Epoch: 0347 train_loss= 0.41441 train_acc= 0.74362 val_roc= 0.84540 val_ap= 0.87654 time= 0.43398\n",
            "Epoch: 0348 train_loss= 0.41434 train_acc= 0.74479 val_roc= 0.84521 val_ap= 0.87639 time= 0.43501\n",
            "Epoch: 0349 train_loss= 0.41426 train_acc= 0.74600 val_roc= 0.84508 val_ap= 0.87631 time= 0.43002\n",
            "Epoch: 0350 train_loss= 0.41419 train_acc= 0.74720 val_roc= 0.84486 val_ap= 0.87607 time= 0.40404\n",
            "Epoch: 0351 train_loss= 0.41412 train_acc= 0.74840 val_roc= 0.84478 val_ap= 0.87598 time= 0.40817\n",
            "Epoch: 0352 train_loss= 0.41404 train_acc= 0.74958 val_roc= 0.84460 val_ap= 0.87581 time= 0.40554\n",
            "Epoch: 0353 train_loss= 0.41397 train_acc= 0.75079 val_roc= 0.84448 val_ap= 0.87575 time= 0.40449\n",
            "Epoch: 0354 train_loss= 0.41390 train_acc= 0.75206 val_roc= 0.84428 val_ap= 0.87562 time= 0.41050\n",
            "Epoch: 0355 train_loss= 0.41383 train_acc= 0.75331 val_roc= 0.84415 val_ap= 0.87554 time= 0.40470\n",
            "Epoch: 0356 train_loss= 0.41377 train_acc= 0.75454 val_roc= 0.84396 val_ap= 0.87543 time= 0.41341\n",
            "Epoch: 0357 train_loss= 0.41370 train_acc= 0.75576 val_roc= 0.84361 val_ap= 0.87517 time= 0.39977\n",
            "Epoch: 0358 train_loss= 0.41363 train_acc= 0.75707 val_roc= 0.84342 val_ap= 0.87505 time= 0.40830\n",
            "Epoch: 0359 train_loss= 0.41356 train_acc= 0.75830 val_roc= 0.84320 val_ap= 0.87491 time= 0.41848\n",
            "Epoch: 0360 train_loss= 0.41350 train_acc= 0.75959 val_roc= 0.84286 val_ap= 0.87469 time= 0.40161\n",
            "Epoch: 0361 train_loss= 0.41344 train_acc= 0.76087 val_roc= 0.84271 val_ap= 0.87465 time= 0.42488\n",
            "Epoch: 0362 train_loss= 0.41337 train_acc= 0.76233 val_roc= 0.84244 val_ap= 0.87451 time= 0.42556\n",
            "Epoch: 0363 train_loss= 0.41331 train_acc= 0.76367 val_roc= 0.84212 val_ap= 0.87430 time= 0.43544\n",
            "Epoch: 0364 train_loss= 0.41325 train_acc= 0.76498 val_roc= 0.84194 val_ap= 0.87421 time= 0.41335\n",
            "Epoch: 0365 train_loss= 0.41320 train_acc= 0.76620 val_roc= 0.84167 val_ap= 0.87406 time= 0.43118\n",
            "Epoch: 0366 train_loss= 0.41314 train_acc= 0.76748 val_roc= 0.84129 val_ap= 0.87382 time= 0.42964\n",
            "Epoch: 0367 train_loss= 0.41308 train_acc= 0.76870 val_roc= 0.84102 val_ap= 0.87369 time= 0.40808\n",
            "Epoch: 0368 train_loss= 0.41303 train_acc= 0.76991 val_roc= 0.84079 val_ap= 0.87349 time= 0.40900\n",
            "Epoch: 0369 train_loss= 0.41297 train_acc= 0.77112 val_roc= 0.84064 val_ap= 0.87341 time= 0.40944\n",
            "Epoch: 0370 train_loss= 0.41292 train_acc= 0.77240 val_roc= 0.84038 val_ap= 0.87330 time= 0.40539\n",
            "Epoch: 0371 train_loss= 0.41287 train_acc= 0.77365 val_roc= 0.84006 val_ap= 0.87308 time= 0.43095\n",
            "Epoch: 0372 train_loss= 0.41282 train_acc= 0.77484 val_roc= 0.83987 val_ap= 0.87289 time= 0.43388\n",
            "Epoch: 0373 train_loss= 0.41277 train_acc= 0.77602 val_roc= 0.83962 val_ap= 0.87269 time= 0.43949\n",
            "Epoch: 0374 train_loss= 0.41272 train_acc= 0.77715 val_roc= 0.83945 val_ap= 0.87255 time= 0.41280\n",
            "Epoch: 0375 train_loss= 0.41267 train_acc= 0.77829 val_roc= 0.83916 val_ap= 0.87236 time= 0.43620\n",
            "Epoch: 0376 train_loss= 0.41262 train_acc= 0.77948 val_roc= 0.83872 val_ap= 0.87214 time= 0.41916\n",
            "Epoch: 0377 train_loss= 0.41258 train_acc= 0.78065 val_roc= 0.83834 val_ap= 0.87196 time= 0.40599\n",
            "Epoch: 0378 train_loss= 0.41253 train_acc= 0.78185 val_roc= 0.83805 val_ap= 0.87175 time= 0.41006\n",
            "Epoch: 0379 train_loss= 0.41250 train_acc= 0.78308 val_roc= 0.83772 val_ap= 0.87149 time= 0.40855\n",
            "Epoch: 0380 train_loss= 0.41246 train_acc= 0.78421 val_roc= 0.83728 val_ap= 0.87122 time= 0.41365\n",
            "Epoch: 0381 train_loss= 0.41241 train_acc= 0.78528 val_roc= 0.83698 val_ap= 0.87098 time= 0.40943\n",
            "Epoch: 0382 train_loss= 0.41237 train_acc= 0.78644 val_roc= 0.83657 val_ap= 0.87074 time= 0.40534\n",
            "Epoch: 0383 train_loss= 0.41233 train_acc= 0.78763 val_roc= 0.83630 val_ap= 0.87055 time= 0.41147\n",
            "Epoch: 0384 train_loss= 0.41229 train_acc= 0.78869 val_roc= 0.83584 val_ap= 0.87029 time= 0.40505\n",
            "Epoch: 0385 train_loss= 0.41225 train_acc= 0.78976 val_roc= 0.83529 val_ap= 0.87009 time= 0.41396\n",
            "Epoch: 0386 train_loss= 0.41221 train_acc= 0.79085 val_roc= 0.83486 val_ap= 0.86984 time= 0.40767\n",
            "Epoch: 0387 train_loss= 0.41217 train_acc= 0.79190 val_roc= 0.83445 val_ap= 0.86964 time= 0.40756\n",
            "Epoch: 0388 train_loss= 0.41213 train_acc= 0.79294 val_roc= 0.83395 val_ap= 0.86937 time= 0.42600\n",
            "Epoch: 0389 train_loss= 0.41210 train_acc= 0.79397 val_roc= 0.83352 val_ap= 0.86915 time= 0.41179\n",
            "Epoch: 0390 train_loss= 0.41206 train_acc= 0.79492 val_roc= 0.83306 val_ap= 0.86896 time= 0.41144\n",
            "Epoch: 0391 train_loss= 0.41202 train_acc= 0.79591 val_roc= 0.83252 val_ap= 0.86867 time= 0.40155\n",
            "Epoch: 0392 train_loss= 0.41199 train_acc= 0.79688 val_roc= 0.83197 val_ap= 0.86839 time= 0.40681\n",
            "Epoch: 0393 train_loss= 0.41195 train_acc= 0.79790 val_roc= 0.83146 val_ap= 0.86815 time= 0.41734\n",
            "Epoch: 0394 train_loss= 0.41191 train_acc= 0.79888 val_roc= 0.83087 val_ap= 0.86789 time= 0.40442\n",
            "Epoch: 0395 train_loss= 0.41188 train_acc= 0.79988 val_roc= 0.83039 val_ap= 0.86767 time= 0.41388\n",
            "Epoch: 0396 train_loss= 0.41184 train_acc= 0.80084 val_roc= 0.83005 val_ap= 0.86752 time= 0.40678\n",
            "Epoch: 0397 train_loss= 0.41181 train_acc= 0.80181 val_roc= 0.82966 val_ap= 0.86737 time= 0.41198\n",
            "Epoch: 0398 train_loss= 0.41177 train_acc= 0.80285 val_roc= 0.82922 val_ap= 0.86723 time= 0.41144\n",
            "Epoch: 0399 train_loss= 0.41174 train_acc= 0.80382 val_roc= 0.82887 val_ap= 0.86709 time= 0.40609\n",
            "Epoch: 0400 train_loss= 0.41170 train_acc= 0.80479 val_roc= 0.82853 val_ap= 0.86693 time= 0.41946\n",
            "Epoch: 0401 train_loss= 0.41167 train_acc= 0.80580 val_roc= 0.82820 val_ap= 0.86677 time= 0.41233\n",
            "Epoch: 0402 train_loss= 0.41163 train_acc= 0.80674 val_roc= 0.82794 val_ap= 0.86667 time= 0.41882\n",
            "Epoch: 0403 train_loss= 0.41160 train_acc= 0.80770 val_roc= 0.82762 val_ap= 0.86647 time= 0.43422\n",
            "Epoch: 0404 train_loss= 0.41156 train_acc= 0.80866 val_roc= 0.82738 val_ap= 0.86638 time= 0.43327\n",
            "Epoch: 0405 train_loss= 0.41153 train_acc= 0.80959 val_roc= 0.82711 val_ap= 0.86625 time= 0.41148\n",
            "Epoch: 0406 train_loss= 0.41149 train_acc= 0.81051 val_roc= 0.82696 val_ap= 0.86614 time= 0.41343\n",
            "Epoch: 0407 train_loss= 0.41147 train_acc= 0.81144 val_roc= 0.82668 val_ap= 0.86597 time= 0.41551\n",
            "Epoch: 0408 train_loss= 0.41144 train_acc= 0.81235 val_roc= 0.82643 val_ap= 0.86588 time= 0.40383\n",
            "Epoch: 0409 train_loss= 0.41140 train_acc= 0.81329 val_roc= 0.82623 val_ap= 0.86578 time= 0.40371\n",
            "Epoch: 0410 train_loss= 0.41137 train_acc= 0.81418 val_roc= 0.82586 val_ap= 0.86559 time= 0.41173\n",
            "Epoch: 0411 train_loss= 0.41134 train_acc= 0.81508 val_roc= 0.82572 val_ap= 0.86554 time= 0.40821\n",
            "Epoch: 0412 train_loss= 0.41131 train_acc= 0.81604 val_roc= 0.82546 val_ap= 0.86535 time= 0.41270\n",
            "Epoch: 0413 train_loss= 0.41127 train_acc= 0.81692 val_roc= 0.82509 val_ap= 0.86514 time= 0.43222\n",
            "Epoch: 0414 train_loss= 0.41124 train_acc= 0.81776 val_roc= 0.82496 val_ap= 0.86510 time= 0.44695\n",
            "Epoch: 0415 train_loss= 0.41121 train_acc= 0.81866 val_roc= 0.82464 val_ap= 0.86491 time= 0.44051\n",
            "Epoch: 0416 train_loss= 0.41118 train_acc= 0.81958 val_roc= 0.82439 val_ap= 0.86475 time= 0.42701\n",
            "Epoch: 0417 train_loss= 0.41115 train_acc= 0.82048 val_roc= 0.82413 val_ap= 0.86457 time= 0.41796\n",
            "Epoch: 0418 train_loss= 0.41112 train_acc= 0.82137 val_roc= 0.82387 val_ap= 0.86439 time= 0.43594\n",
            "Epoch: 0419 train_loss= 0.41109 train_acc= 0.82223 val_roc= 0.82368 val_ap= 0.86423 time= 0.41898\n",
            "Epoch: 0420 train_loss= 0.41106 train_acc= 0.82307 val_roc= 0.82347 val_ap= 0.86410 time= 0.40398\n",
            "Epoch: 0421 train_loss= 0.41103 train_acc= 0.82391 val_roc= 0.82316 val_ap= 0.86389 time= 0.40422\n",
            "Epoch: 0422 train_loss= 0.41100 train_acc= 0.82476 val_roc= 0.82279 val_ap= 0.86358 time= 0.41040\n",
            "Epoch: 0423 train_loss= 0.41097 train_acc= 0.82558 val_roc= 0.82244 val_ap= 0.86335 time= 0.40566\n",
            "Epoch: 0424 train_loss= 0.41094 train_acc= 0.82646 val_roc= 0.82223 val_ap= 0.86321 time= 0.41836\n",
            "Epoch: 0425 train_loss= 0.41091 train_acc= 0.82729 val_roc= 0.82203 val_ap= 0.86308 time= 0.43957\n",
            "Epoch: 0426 train_loss= 0.41088 train_acc= 0.82811 val_roc= 0.82172 val_ap= 0.86289 time= 0.42988\n",
            "Epoch: 0427 train_loss= 0.41085 train_acc= 0.82895 val_roc= 0.82145 val_ap= 0.86273 time= 0.44117\n",
            "Epoch: 0428 train_loss= 0.41083 train_acc= 0.82982 val_roc= 0.82109 val_ap= 0.86246 time= 0.42747\n",
            "Epoch: 0429 train_loss= 0.41080 train_acc= 0.83070 val_roc= 0.82084 val_ap= 0.86231 time= 0.41875\n",
            "Epoch: 0430 train_loss= 0.41077 train_acc= 0.83158 val_roc= 0.82063 val_ap= 0.86221 time= 0.45019\n",
            "Epoch: 0431 train_loss= 0.41074 train_acc= 0.83243 val_roc= 0.82036 val_ap= 0.86206 time= 0.43068\n",
            "Epoch: 0432 train_loss= 0.41071 train_acc= 0.83326 val_roc= 0.82015 val_ap= 0.86197 time= 0.42467\n",
            "Epoch: 0433 train_loss= 0.41068 train_acc= 0.83408 val_roc= 0.81985 val_ap= 0.86177 time= 0.40564\n",
            "Epoch: 0434 train_loss= 0.41066 train_acc= 0.83492 val_roc= 0.81963 val_ap= 0.86165 time= 0.42495\n",
            "Epoch: 0435 train_loss= 0.41063 train_acc= 0.83574 val_roc= 0.81937 val_ap= 0.86146 time= 0.41104\n",
            "Epoch: 0436 train_loss= 0.41060 train_acc= 0.83656 val_roc= 0.81920 val_ap= 0.86140 time= 0.41172\n",
            "Epoch: 0437 train_loss= 0.41057 train_acc= 0.83732 val_roc= 0.81907 val_ap= 0.86129 time= 0.43795\n",
            "Epoch: 0438 train_loss= 0.41055 train_acc= 0.83813 val_roc= 0.81879 val_ap= 0.86114 time= 0.41949\n",
            "Epoch: 0439 train_loss= 0.41052 train_acc= 0.83896 val_roc= 0.81850 val_ap= 0.86092 time= 0.43834\n",
            "Epoch: 0440 train_loss= 0.41050 train_acc= 0.83980 val_roc= 0.81841 val_ap= 0.86086 time= 0.42309\n",
            "Epoch: 0441 train_loss= 0.41047 train_acc= 0.84062 val_roc= 0.81828 val_ap= 0.86076 time= 0.41132\n",
            "Epoch: 0442 train_loss= 0.41044 train_acc= 0.84140 val_roc= 0.81808 val_ap= 0.86068 time= 0.40844\n",
            "Epoch: 0443 train_loss= 0.41042 train_acc= 0.84225 val_roc= 0.81789 val_ap= 0.86052 time= 0.41848\n",
            "Epoch: 0444 train_loss= 0.41039 train_acc= 0.84308 val_roc= 0.81767 val_ap= 0.86039 time= 0.43224\n",
            "Epoch: 0445 train_loss= 0.41036 train_acc= 0.84388 val_roc= 0.81733 val_ap= 0.86013 time= 0.41174\n",
            "Epoch: 0446 train_loss= 0.41034 train_acc= 0.84467 val_roc= 0.81718 val_ap= 0.86002 time= 0.41976\n",
            "Epoch: 0447 train_loss= 0.41031 train_acc= 0.84548 val_roc= 0.81692 val_ap= 0.85982 time= 0.40537\n",
            "Epoch: 0448 train_loss= 0.41029 train_acc= 0.84627 val_roc= 0.81664 val_ap= 0.85962 time= 0.41373\n",
            "Epoch: 0449 train_loss= 0.41026 train_acc= 0.84703 val_roc= 0.81635 val_ap= 0.85940 time= 0.40671\n",
            "Epoch: 0450 train_loss= 0.41024 train_acc= 0.84782 val_roc= 0.81617 val_ap= 0.85929 time= 0.41770\n",
            "Epoch: 0451 train_loss= 0.41021 train_acc= 0.84866 val_roc= 0.81604 val_ap= 0.85919 time= 0.43833\n",
            "Epoch: 0452 train_loss= 0.41019 train_acc= 0.84949 val_roc= 0.81569 val_ap= 0.85902 time= 0.41852\n",
            "Epoch: 0453 train_loss= 0.41016 train_acc= 0.85029 val_roc= 0.81547 val_ap= 0.85885 time= 0.40755\n",
            "Epoch: 0454 train_loss= 0.41014 train_acc= 0.85108 val_roc= 0.81539 val_ap= 0.85874 time= 0.40476\n",
            "Epoch: 0455 train_loss= 0.41011 train_acc= 0.85187 val_roc= 0.81513 val_ap= 0.85855 time= 0.40430\n",
            "Epoch: 0456 train_loss= 0.41009 train_acc= 0.85269 val_roc= 0.81483 val_ap= 0.85829 time= 0.41235\n",
            "Epoch: 0457 train_loss= 0.41007 train_acc= 0.85347 val_roc= 0.81471 val_ap= 0.85824 time= 0.41920\n",
            "Epoch: 0458 train_loss= 0.41004 train_acc= 0.85418 val_roc= 0.81431 val_ap= 0.85792 time= 0.41668\n",
            "Epoch: 0459 train_loss= 0.41002 train_acc= 0.85488 val_roc= 0.81407 val_ap= 0.85773 time= 0.40987\n",
            "Epoch: 0460 train_loss= 0.41000 train_acc= 0.85562 val_roc= 0.81397 val_ap= 0.85765 time= 0.40974\n",
            "Epoch: 0461 train_loss= 0.40998 train_acc= 0.85628 val_roc= 0.81370 val_ap= 0.85743 time= 0.44197\n",
            "Epoch: 0462 train_loss= 0.40995 train_acc= 0.85696 val_roc= 0.81326 val_ap= 0.85706 time= 0.43175\n",
            "Epoch: 0463 train_loss= 0.40993 train_acc= 0.85765 val_roc= 0.81306 val_ap= 0.85683 time= 0.44605\n",
            "Epoch: 0464 train_loss= 0.40991 train_acc= 0.85831 val_roc= 0.81270 val_ap= 0.85656 time= 0.41446\n",
            "Epoch: 0465 train_loss= 0.40989 train_acc= 0.85894 val_roc= 0.81252 val_ap= 0.85638 time= 0.41594\n",
            "Epoch: 0466 train_loss= 0.40986 train_acc= 0.85960 val_roc= 0.81220 val_ap= 0.85610 time= 0.41161\n",
            "Epoch: 0467 train_loss= 0.40984 train_acc= 0.86027 val_roc= 0.81184 val_ap= 0.85578 time= 0.41000\n",
            "Epoch: 0468 train_loss= 0.40982 train_acc= 0.86089 val_roc= 0.81156 val_ap= 0.85547 time= 0.40546\n",
            "Epoch: 0469 train_loss= 0.40980 train_acc= 0.86152 val_roc= 0.81120 val_ap= 0.85518 time= 0.40524\n",
            "Epoch: 0470 train_loss= 0.40978 train_acc= 0.86219 val_roc= 0.81096 val_ap= 0.85501 time= 0.41764\n",
            "Epoch: 0471 train_loss= 0.40976 train_acc= 0.86285 val_roc= 0.81049 val_ap= 0.85461 time= 0.40519\n",
            "Epoch: 0472 train_loss= 0.40974 train_acc= 0.86350 val_roc= 0.81020 val_ap= 0.85434 time= 0.40597\n",
            "Epoch: 0473 train_loss= 0.40972 train_acc= 0.86412 val_roc= 0.80986 val_ap= 0.85407 time= 0.40539\n",
            "Epoch: 0474 train_loss= 0.40970 train_acc= 0.86474 val_roc= 0.80951 val_ap= 0.85387 time= 0.42849\n",
            "Epoch: 0475 train_loss= 0.40967 train_acc= 0.86537 val_roc= 0.80914 val_ap= 0.85364 time= 0.43459\n",
            "Epoch: 0476 train_loss= 0.40965 train_acc= 0.86604 val_roc= 0.80892 val_ap= 0.85348 time= 0.40326\n",
            "Epoch: 0477 train_loss= 0.40963 train_acc= 0.86667 val_roc= 0.80855 val_ap= 0.85322 time= 0.41510\n",
            "Epoch: 0478 train_loss= 0.40961 train_acc= 0.86728 val_roc= 0.80828 val_ap= 0.85302 time= 0.41632\n",
            "Epoch: 0479 train_loss= 0.40959 train_acc= 0.86792 val_roc= 0.80800 val_ap= 0.85286 time= 0.40954\n",
            "Epoch: 0480 train_loss= 0.40957 train_acc= 0.86858 val_roc= 0.80771 val_ap= 0.85264 time= 0.41315\n",
            "Epoch: 0481 train_loss= 0.40955 train_acc= 0.86923 val_roc= 0.80753 val_ap= 0.85245 time= 0.41821\n",
            "Epoch: 0482 train_loss= 0.40954 train_acc= 0.86981 val_roc= 0.80741 val_ap= 0.85233 time= 0.43179\n",
            "Epoch: 0483 train_loss= 0.40952 train_acc= 0.87037 val_roc= 0.80716 val_ap= 0.85216 time= 0.40211\n",
            "Epoch: 0484 train_loss= 0.40950 train_acc= 0.87094 val_roc= 0.80695 val_ap= 0.85201 time= 0.42472\n",
            "Epoch: 0485 train_loss= 0.40948 train_acc= 0.87151 val_roc= 0.80682 val_ap= 0.85189 time= 0.43045\n",
            "Epoch: 0486 train_loss= 0.40946 train_acc= 0.87209 val_roc= 0.80664 val_ap= 0.85175 time= 0.40959\n",
            "Epoch: 0487 train_loss= 0.40945 train_acc= 0.87269 val_roc= 0.80655 val_ap= 0.85170 time= 0.41611\n",
            "Epoch: 0488 train_loss= 0.40943 train_acc= 0.87328 val_roc= 0.80645 val_ap= 0.85165 time= 0.42120\n",
            "Epoch: 0489 train_loss= 0.40941 train_acc= 0.87384 val_roc= 0.80640 val_ap= 0.85163 time= 0.43258\n",
            "Epoch: 0490 train_loss= 0.40940 train_acc= 0.87439 val_roc= 0.80630 val_ap= 0.85157 time= 0.43541\n",
            "Epoch: 0491 train_loss= 0.40938 train_acc= 0.87491 val_roc= 0.80615 val_ap= 0.85148 time= 0.43566\n",
            "Epoch: 0492 train_loss= 0.40936 train_acc= 0.87543 val_roc= 0.80589 val_ap= 0.85128 time= 0.43387\n",
            "Epoch: 0493 train_loss= 0.40935 train_acc= 0.87598 val_roc= 0.80583 val_ap= 0.85122 time= 0.40716\n",
            "Epoch: 0494 train_loss= 0.40933 train_acc= 0.87652 val_roc= 0.80554 val_ap= 0.85097 time= 0.41249\n",
            "Epoch: 0495 train_loss= 0.40931 train_acc= 0.87700 val_roc= 0.80543 val_ap= 0.85089 time= 0.40322\n",
            "Epoch: 0496 train_loss= 0.40930 train_acc= 0.87751 val_roc= 0.80525 val_ap= 0.85075 time= 0.41433\n",
            "Epoch: 0497 train_loss= 0.40928 train_acc= 0.87806 val_roc= 0.80505 val_ap= 0.85060 time= 0.40380\n",
            "Epoch: 0498 train_loss= 0.40926 train_acc= 0.87852 val_roc= 0.80493 val_ap= 0.85056 time= 0.41085\n",
            "Epoch: 0499 train_loss= 0.40925 train_acc= 0.87902 val_roc= 0.80488 val_ap= 0.85056 time= 0.41719\n",
            "Epoch: 0500 train_loss= 0.40923 train_acc= 0.87952 val_roc= 0.80480 val_ap= 0.85041 time= 0.41391\n",
            "Epoch: 0501 train_loss= 0.40922 train_acc= 0.88008 val_roc= 0.80457 val_ap= 0.85021 time= 0.41059\n",
            "Epoch: 0502 train_loss= 0.40920 train_acc= 0.88052 val_roc= 0.80442 val_ap= 0.85006 time= 0.40967\n",
            "Epoch: 0503 train_loss= 0.40919 train_acc= 0.88099 val_roc= 0.80426 val_ap= 0.84999 time= 0.40751\n",
            "Epoch: 0504 train_loss= 0.40917 train_acc= 0.88147 val_roc= 0.80404 val_ap= 0.84988 time= 0.41069\n",
            "Epoch: 0505 train_loss= 0.40916 train_acc= 0.88196 val_roc= 0.80365 val_ap= 0.84967 time= 0.40966\n",
            "Epoch: 0506 train_loss= 0.40914 train_acc= 0.88242 val_roc= 0.80345 val_ap= 0.84954 time= 0.42118\n",
            "Epoch: 0507 train_loss= 0.40913 train_acc= 0.88289 val_roc= 0.80324 val_ap= 0.84935 time= 0.40549\n",
            "Epoch: 0508 train_loss= 0.40912 train_acc= 0.88331 val_roc= 0.80313 val_ap= 0.84934 time= 0.40970\n",
            "Epoch: 0509 train_loss= 0.40910 train_acc= 0.88380 val_roc= 0.80289 val_ap= 0.84919 time= 0.41316\n",
            "Epoch: 0510 train_loss= 0.40909 train_acc= 0.88418 val_roc= 0.80278 val_ap= 0.84910 time= 0.40958\n",
            "Epoch: 0511 train_loss= 0.40907 train_acc= 0.88462 val_roc= 0.80262 val_ap= 0.84903 time= 0.40992\n",
            "Epoch: 0512 train_loss= 0.40907 train_acc= 0.88509 val_roc= 0.80245 val_ap= 0.84893 time= 0.40575\n",
            "Epoch: 0513 train_loss= 0.40906 train_acc= 0.88551 val_roc= 0.80208 val_ap= 0.84867 time= 0.42021\n",
            "Epoch: 0514 train_loss= 0.40904 train_acc= 0.88593 val_roc= 0.80187 val_ap= 0.84854 time= 0.40958\n",
            "Epoch: 0515 train_loss= 0.40903 train_acc= 0.88633 val_roc= 0.80164 val_ap= 0.84835 time= 0.41153\n",
            "Epoch: 0516 train_loss= 0.40902 train_acc= 0.88677 val_roc= 0.80128 val_ap= 0.84810 time= 0.41416\n",
            "Epoch: 0517 train_loss= 0.40901 train_acc= 0.88722 val_roc= 0.80114 val_ap= 0.84797 time= 0.41613\n",
            "Epoch: 0518 train_loss= 0.40900 train_acc= 0.88765 val_roc= 0.80092 val_ap= 0.84775 time= 0.43498\n",
            "Epoch: 0519 train_loss= 0.40899 train_acc= 0.88808 val_roc= 0.80057 val_ap= 0.84752 time= 0.41654\n",
            "Epoch: 0520 train_loss= 0.40897 train_acc= 0.88853 val_roc= 0.80050 val_ap= 0.84733 time= 0.40915\n",
            "Epoch: 0521 train_loss= 0.40896 train_acc= 0.88892 val_roc= 0.80013 val_ap= 0.84709 time= 0.41025\n",
            "Epoch: 0522 train_loss= 0.40895 train_acc= 0.88931 val_roc= 0.79994 val_ap= 0.84697 time= 0.40290\n",
            "Epoch: 0523 train_loss= 0.40894 train_acc= 0.88972 val_roc= 0.79967 val_ap= 0.84674 time= 0.43228\n",
            "Epoch: 0524 train_loss= 0.40893 train_acc= 0.89013 val_roc= 0.79949 val_ap= 0.84660 time= 0.40785\n",
            "Epoch: 0525 train_loss= 0.40891 train_acc= 0.89055 val_roc= 0.79927 val_ap= 0.84648 time= 0.40254\n",
            "Epoch: 0526 train_loss= 0.40890 train_acc= 0.89089 val_roc= 0.79909 val_ap= 0.84632 time= 0.41583\n",
            "Epoch: 0527 train_loss= 0.40889 train_acc= 0.89124 val_roc= 0.79891 val_ap= 0.84615 time= 0.40371\n",
            "Epoch: 0528 train_loss= 0.40888 train_acc= 0.89162 val_roc= 0.79864 val_ap= 0.84598 time= 0.42135\n",
            "Epoch: 0529 train_loss= 0.40887 train_acc= 0.89204 val_roc= 0.79829 val_ap= 0.84578 time= 0.40596\n",
            "Epoch: 0530 train_loss= 0.40886 train_acc= 0.89245 val_roc= 0.79797 val_ap= 0.84557 time= 0.40842\n",
            "Epoch: 0531 train_loss= 0.40884 train_acc= 0.89279 val_roc= 0.79753 val_ap= 0.84530 time= 0.41337\n",
            "Epoch: 0532 train_loss= 0.40884 train_acc= 0.89318 val_roc= 0.79724 val_ap= 0.84508 time= 0.40995\n",
            "Epoch: 0533 train_loss= 0.40883 train_acc= 0.89356 val_roc= 0.79685 val_ap= 0.84483 time= 0.42462\n",
            "Epoch: 0534 train_loss= 0.40882 train_acc= 0.89386 val_roc= 0.79650 val_ap= 0.84461 time= 0.41116\n",
            "Epoch: 0535 train_loss= 0.40881 train_acc= 0.89416 val_roc= 0.79631 val_ap= 0.84447 time= 0.43655\n",
            "Epoch: 0536 train_loss= 0.40880 train_acc= 0.89450 val_roc= 0.79618 val_ap= 0.84441 time= 0.42419\n",
            "Epoch: 0537 train_loss= 0.40879 train_acc= 0.89482 val_roc= 0.79598 val_ap= 0.84434 time= 0.40844\n",
            "Epoch: 0538 train_loss= 0.40878 train_acc= 0.89518 val_roc= 0.79568 val_ap= 0.84414 time= 0.40988\n",
            "Epoch: 0539 train_loss= 0.40877 train_acc= 0.89553 val_roc= 0.79545 val_ap= 0.84397 time= 0.40735\n",
            "Epoch: 0540 train_loss= 0.40876 train_acc= 0.89583 val_roc= 0.79515 val_ap= 0.84372 time= 0.41391\n",
            "Epoch: 0541 train_loss= 0.40875 train_acc= 0.89615 val_roc= 0.79500 val_ap= 0.84362 time= 0.41314\n",
            "Epoch: 0542 train_loss= 0.40874 train_acc= 0.89657 val_roc= 0.79470 val_ap= 0.84342 time= 0.40285\n",
            "Epoch: 0543 train_loss= 0.40873 train_acc= 0.89694 val_roc= 0.79445 val_ap= 0.84329 time= 0.41172\n",
            "Epoch: 0544 train_loss= 0.40872 train_acc= 0.89728 val_roc= 0.79427 val_ap= 0.84323 time= 0.41129\n",
            "Epoch: 0545 train_loss= 0.40871 train_acc= 0.89762 val_roc= 0.79414 val_ap= 0.84314 time= 0.40413\n",
            "Epoch: 0546 train_loss= 0.40870 train_acc= 0.89794 val_roc= 0.79396 val_ap= 0.84302 time= 0.41459\n",
            "Epoch: 0547 train_loss= 0.40869 train_acc= 0.89825 val_roc= 0.79374 val_ap= 0.84289 time= 0.40268\n",
            "Epoch: 0548 train_loss= 0.40868 train_acc= 0.89859 val_roc= 0.79345 val_ap= 0.84272 time= 0.41535\n",
            "Epoch: 0549 train_loss= 0.40867 train_acc= 0.89889 val_roc= 0.79325 val_ap= 0.84258 time= 0.42539\n",
            "Epoch: 0550 train_loss= 0.40866 train_acc= 0.89923 val_roc= 0.79292 val_ap= 0.84238 time= 0.42088\n",
            "Epoch: 0551 train_loss= 0.40865 train_acc= 0.89956 val_roc= 0.79270 val_ap= 0.84224 time= 0.40884\n",
            "Epoch: 0552 train_loss= 0.40864 train_acc= 0.89985 val_roc= 0.79253 val_ap= 0.84214 time= 0.40347\n",
            "Epoch: 0553 train_loss= 0.40863 train_acc= 0.90014 val_roc= 0.79231 val_ap= 0.84194 time= 0.41469\n",
            "Epoch: 0554 train_loss= 0.40862 train_acc= 0.90043 val_roc= 0.79196 val_ap= 0.84164 time= 0.40314\n",
            "Epoch: 0555 train_loss= 0.40861 train_acc= 0.90070 val_roc= 0.79173 val_ap= 0.84148 time= 0.40777\n",
            "Epoch: 0556 train_loss= 0.40861 train_acc= 0.90095 val_roc= 0.79142 val_ap= 0.84126 time= 0.41049\n",
            "Epoch: 0557 train_loss= 0.40860 train_acc= 0.90126 val_roc= 0.79130 val_ap= 0.84113 time= 0.40349\n",
            "Epoch: 0558 train_loss= 0.40859 train_acc= 0.90150 val_roc= 0.79098 val_ap= 0.84092 time= 0.41325\n",
            "Epoch: 0559 train_loss= 0.40858 train_acc= 0.90174 val_roc= 0.79083 val_ap= 0.84086 time= 0.40536\n",
            "Epoch: 0560 train_loss= 0.40857 train_acc= 0.90201 val_roc= 0.79062 val_ap= 0.84073 time= 0.41098\n",
            "Epoch: 0561 train_loss= 0.40856 train_acc= 0.90228 val_roc= 0.79043 val_ap= 0.84058 time= 0.40395\n",
            "Epoch: 0562 train_loss= 0.40856 train_acc= 0.90248 val_roc= 0.79034 val_ap= 0.84050 time= 0.40607\n",
            "Epoch: 0563 train_loss= 0.40855 train_acc= 0.90271 val_roc= 0.79016 val_ap= 0.84035 time= 0.42257\n",
            "Epoch: 0564 train_loss= 0.40854 train_acc= 0.90289 val_roc= 0.79005 val_ap= 0.84017 time= 0.40922\n",
            "Epoch: 0565 train_loss= 0.40853 train_acc= 0.90312 val_roc= 0.78984 val_ap= 0.84003 time= 0.41047\n",
            "Epoch: 0566 train_loss= 0.40853 train_acc= 0.90335 val_roc= 0.78970 val_ap= 0.83988 time= 0.41073\n",
            "Epoch: 0567 train_loss= 0.40852 train_acc= 0.90358 val_roc= 0.78961 val_ap= 0.83976 time= 0.40815\n",
            "Epoch: 0568 train_loss= 0.40851 train_acc= 0.90380 val_roc= 0.78944 val_ap= 0.83963 time= 0.41533\n",
            "Epoch: 0569 train_loss= 0.40850 train_acc= 0.90401 val_roc= 0.78932 val_ap= 0.83954 time= 0.40997\n",
            "Epoch: 0570 train_loss= 0.40850 train_acc= 0.90426 val_roc= 0.78916 val_ap= 0.83939 time= 0.41317\n",
            "Epoch: 0571 train_loss= 0.40849 train_acc= 0.90448 val_roc= 0.78898 val_ap= 0.83922 time= 0.40309\n",
            "Epoch: 0572 train_loss= 0.40848 train_acc= 0.90468 val_roc= 0.78886 val_ap= 0.83912 time= 0.40386\n",
            "Epoch: 0573 train_loss= 0.40848 train_acc= 0.90489 val_roc= 0.78872 val_ap= 0.83901 time= 0.41405\n",
            "Epoch: 0574 train_loss= 0.40847 train_acc= 0.90509 val_roc= 0.78861 val_ap= 0.83894 time= 0.41595\n",
            "Epoch: 0575 train_loss= 0.40847 train_acc= 0.90532 val_roc= 0.78849 val_ap= 0.83887 time= 0.42966\n",
            "Epoch: 0576 train_loss= 0.40846 train_acc= 0.90557 val_roc= 0.78834 val_ap= 0.83873 time= 0.41868\n",
            "Epoch: 0577 train_loss= 0.40845 train_acc= 0.90579 val_roc= 0.78820 val_ap= 0.83859 time= 0.41652\n",
            "Epoch: 0578 train_loss= 0.40845 train_acc= 0.90606 val_roc= 0.78803 val_ap= 0.83848 time= 0.40719\n",
            "Epoch: 0579 train_loss= 0.40844 train_acc= 0.90630 val_roc= 0.78790 val_ap= 0.83832 time= 0.41365\n",
            "Epoch: 0580 train_loss= 0.40844 train_acc= 0.90655 val_roc= 0.78774 val_ap= 0.83819 time= 0.41844\n",
            "Epoch: 0581 train_loss= 0.40843 train_acc= 0.90679 val_roc= 0.78751 val_ap= 0.83804 time= 0.41606\n",
            "Epoch: 0582 train_loss= 0.40842 train_acc= 0.90699 val_roc= 0.78726 val_ap= 0.83787 time= 0.41135\n",
            "Epoch: 0583 train_loss= 0.40842 train_acc= 0.90720 val_roc= 0.78723 val_ap= 0.83783 time= 0.40700\n",
            "Epoch: 0584 train_loss= 0.40841 train_acc= 0.90743 val_roc= 0.78708 val_ap= 0.83773 time= 0.40465\n",
            "Epoch: 0585 train_loss= 0.40840 train_acc= 0.90762 val_roc= 0.78702 val_ap= 0.83768 time= 0.40777\n",
            "Epoch: 0586 train_loss= 0.40840 train_acc= 0.90785 val_roc= 0.78679 val_ap= 0.83753 time= 0.40099\n",
            "Epoch: 0587 train_loss= 0.40839 train_acc= 0.90805 val_roc= 0.78663 val_ap= 0.83743 time= 0.40499\n",
            "Epoch: 0588 train_loss= 0.40839 train_acc= 0.90823 val_roc= 0.78642 val_ap= 0.83727 time= 0.40575\n",
            "Epoch: 0589 train_loss= 0.40838 train_acc= 0.90843 val_roc= 0.78623 val_ap= 0.83710 time= 0.40625\n",
            "Epoch: 0590 train_loss= 0.40837 train_acc= 0.90865 val_roc= 0.78616 val_ap= 0.83706 time= 0.43451\n",
            "Epoch: 0591 train_loss= 0.40837 train_acc= 0.90883 val_roc= 0.78607 val_ap= 0.83700 time= 0.43515\n",
            "Epoch: 0592 train_loss= 0.40836 train_acc= 0.90899 val_roc= 0.78585 val_ap= 0.83681 time= 0.42421\n",
            "Epoch: 0593 train_loss= 0.40836 train_acc= 0.90916 val_roc= 0.78562 val_ap= 0.83662 time= 0.42087\n",
            "Epoch: 0594 train_loss= 0.40835 train_acc= 0.90939 val_roc= 0.78541 val_ap= 0.83647 time= 0.41573\n",
            "Epoch: 0595 train_loss= 0.40835 train_acc= 0.90958 val_roc= 0.78531 val_ap= 0.83636 time= 0.41210\n",
            "Epoch: 0596 train_loss= 0.40834 train_acc= 0.90975 val_roc= 0.78515 val_ap= 0.83624 time= 0.40961\n",
            "Epoch: 0597 train_loss= 0.40834 train_acc= 0.90993 val_roc= 0.78505 val_ap= 0.83618 time= 0.41286\n",
            "Epoch: 0598 train_loss= 0.40833 train_acc= 0.91012 val_roc= 0.78469 val_ap= 0.83595 time= 0.40562\n",
            "Epoch: 0599 train_loss= 0.40833 train_acc= 0.91025 val_roc= 0.78455 val_ap= 0.83583 time= 0.41553\n",
            "Epoch: 0600 train_loss= 0.40833 train_acc= 0.91038 val_roc= 0.78438 val_ap= 0.83568 time= 0.40559\n",
            "Epoch: 0601 train_loss= 0.40832 train_acc= 0.91051 val_roc= 0.78411 val_ap= 0.83552 time= 0.42425\n",
            "Epoch: 0602 train_loss= 0.40832 train_acc= 0.91066 val_roc= 0.78390 val_ap= 0.83529 time= 0.41686\n",
            "Epoch: 0603 train_loss= 0.40832 train_acc= 0.91078 val_roc= 0.78359 val_ap= 0.83510 time= 0.41599\n",
            "Epoch: 0604 train_loss= 0.40831 train_acc= 0.91092 val_roc= 0.78340 val_ap= 0.83499 time= 0.41307\n",
            "Epoch: 0605 train_loss= 0.40831 train_acc= 0.91107 val_roc= 0.78321 val_ap= 0.83483 time= 0.41983\n",
            "Epoch: 0606 train_loss= 0.40830 train_acc= 0.91121 val_roc= 0.78302 val_ap= 0.83462 time= 0.40627\n",
            "Epoch: 0607 train_loss= 0.40830 train_acc= 0.91137 val_roc= 0.78277 val_ap= 0.83441 time= 0.44567\n",
            "Epoch: 0608 train_loss= 0.40829 train_acc= 0.91157 val_roc= 0.78259 val_ap= 0.83426 time= 0.42859\n",
            "Epoch: 0609 train_loss= 0.40829 train_acc= 0.91170 val_roc= 0.78229 val_ap= 0.83406 time= 0.41938\n",
            "Epoch: 0610 train_loss= 0.40829 train_acc= 0.91184 val_roc= 0.78201 val_ap= 0.83385 time= 0.40020\n",
            "Epoch: 0611 train_loss= 0.40828 train_acc= 0.91197 val_roc= 0.78163 val_ap= 0.83362 time= 0.40180\n",
            "Epoch: 0612 train_loss= 0.40828 train_acc= 0.91209 val_roc= 0.78143 val_ap= 0.83351 time= 0.44338\n",
            "Epoch: 0613 train_loss= 0.40827 train_acc= 0.91221 val_roc= 0.78109 val_ap= 0.83330 time= 0.43701\n",
            "Epoch: 0614 train_loss= 0.40827 train_acc= 0.91234 val_roc= 0.78092 val_ap= 0.83316 time= 0.44636\n",
            "Epoch: 0615 train_loss= 0.40827 train_acc= 0.91249 val_roc= 0.78078 val_ap= 0.83306 time= 0.43206\n",
            "Epoch: 0616 train_loss= 0.40826 train_acc= 0.91262 val_roc= 0.78064 val_ap= 0.83297 time= 0.42288\n",
            "Epoch: 0617 train_loss= 0.40826 train_acc= 0.91277 val_roc= 0.78052 val_ap= 0.83286 time= 0.40520\n",
            "Epoch: 0618 train_loss= 0.40825 train_acc= 0.91290 val_roc= 0.78036 val_ap= 0.83282 time= 0.40892\n",
            "Epoch: 0619 train_loss= 0.40825 train_acc= 0.91302 val_roc= 0.78014 val_ap= 0.83266 time= 0.41797\n",
            "Epoch: 0620 train_loss= 0.40824 train_acc= 0.91317 val_roc= 0.77994 val_ap= 0.83251 time= 0.40600\n",
            "Epoch: 0621 train_loss= 0.40824 train_acc= 0.91332 val_roc= 0.77978 val_ap= 0.83241 time= 0.41991\n",
            "Epoch: 0622 train_loss= 0.40824 train_acc= 0.91345 val_roc= 0.77962 val_ap= 0.83230 time= 0.40940\n",
            "Epoch: 0623 train_loss= 0.40823 train_acc= 0.91360 val_roc= 0.77943 val_ap= 0.83212 time= 0.41297\n",
            "Epoch: 0624 train_loss= 0.40823 train_acc= 0.91372 val_roc= 0.77927 val_ap= 0.83205 time= 0.41354\n",
            "Epoch: 0625 train_loss= 0.40822 train_acc= 0.91384 val_roc= 0.77906 val_ap= 0.83192 time= 0.40274\n",
            "Epoch: 0626 train_loss= 0.40822 train_acc= 0.91396 val_roc= 0.77891 val_ap= 0.83183 time= 0.43870\n",
            "Epoch: 0627 train_loss= 0.40822 train_acc= 0.91411 val_roc= 0.77873 val_ap= 0.83172 time= 0.40741\n",
            "Epoch: 0628 train_loss= 0.40822 train_acc= 0.91423 val_roc= 0.77857 val_ap= 0.83160 time= 0.42760\n",
            "Epoch: 0629 train_loss= 0.40821 train_acc= 0.91437 val_roc= 0.77839 val_ap= 0.83149 time= 0.43085\n",
            "Epoch: 0630 train_loss= 0.40821 train_acc= 0.91451 val_roc= 0.77829 val_ap= 0.83144 time= 0.42425\n",
            "Epoch: 0631 train_loss= 0.40821 train_acc= 0.91462 val_roc= 0.77814 val_ap= 0.83133 time= 0.44311\n",
            "Epoch: 0632 train_loss= 0.40820 train_acc= 0.91475 val_roc= 0.77793 val_ap= 0.83123 time= 0.42729\n",
            "Epoch: 0633 train_loss= 0.40820 train_acc= 0.91488 val_roc= 0.77772 val_ap= 0.83109 time= 0.44093\n",
            "Epoch: 0634 train_loss= 0.40820 train_acc= 0.91503 val_roc= 0.77741 val_ap= 0.83090 time= 0.42873\n",
            "Epoch: 0635 train_loss= 0.40819 train_acc= 0.91514 val_roc= 0.77717 val_ap= 0.83076 time= 0.42557\n",
            "Epoch: 0636 train_loss= 0.40819 train_acc= 0.91533 val_roc= 0.77696 val_ap= 0.83065 time= 0.40922\n",
            "Epoch: 0637 train_loss= 0.40819 train_acc= 0.91548 val_roc= 0.77681 val_ap= 0.83054 time= 0.40806\n",
            "Epoch: 0638 train_loss= 0.40818 train_acc= 0.91558 val_roc= 0.77652 val_ap= 0.83036 time= 0.44689\n",
            "Epoch: 0639 train_loss= 0.40818 train_acc= 0.91571 val_roc= 0.77626 val_ap= 0.83018 time= 0.43484\n",
            "Epoch: 0640 train_loss= 0.40817 train_acc= 0.91584 val_roc= 0.77604 val_ap= 0.83006 time= 0.40848\n",
            "Epoch: 0641 train_loss= 0.40817 train_acc= 0.91598 val_roc= 0.77572 val_ap= 0.82987 time= 0.43318\n",
            "Epoch: 0642 train_loss= 0.40817 train_acc= 0.91612 val_roc= 0.77561 val_ap= 0.82981 time= 0.42876\n",
            "Epoch: 0643 train_loss= 0.40816 train_acc= 0.91621 val_roc= 0.77538 val_ap= 0.82969 time= 0.44567\n",
            "Epoch: 0644 train_loss= 0.40816 train_acc= 0.91631 val_roc= 0.77518 val_ap= 0.82956 time= 0.41262\n",
            "Epoch: 0645 train_loss= 0.40816 train_acc= 0.91640 val_roc= 0.77488 val_ap= 0.82940 time= 0.42172\n",
            "Epoch: 0646 train_loss= 0.40816 train_acc= 0.91653 val_roc= 0.77468 val_ap= 0.82926 time= 0.43530\n",
            "Epoch: 0647 train_loss= 0.40815 train_acc= 0.91668 val_roc= 0.77442 val_ap= 0.82913 time= 0.44963\n",
            "Epoch: 0648 train_loss= 0.40815 train_acc= 0.91678 val_roc= 0.77420 val_ap= 0.82900 time= 0.43689\n",
            "Epoch: 0649 train_loss= 0.40816 train_acc= 0.91686 val_roc= 0.77393 val_ap= 0.82881 time= 0.41741\n",
            "Epoch: 0650 train_loss= 0.40815 train_acc= 0.91694 val_roc= 0.77367 val_ap= 0.82867 time= 0.45208\n",
            "Epoch: 0651 train_loss= 0.40815 train_acc= 0.91703 val_roc= 0.77347 val_ap= 0.82855 time= 0.42537\n",
            "Epoch: 0652 train_loss= 0.40815 train_acc= 0.91711 val_roc= 0.77324 val_ap= 0.82841 time= 0.44065\n",
            "Epoch: 0653 train_loss= 0.40815 train_acc= 0.91720 val_roc= 0.77306 val_ap= 0.82830 time= 0.41226\n",
            "Epoch: 0654 train_loss= 0.40814 train_acc= 0.91730 val_roc= 0.77282 val_ap= 0.82817 time= 0.44013\n",
            "Epoch: 0655 train_loss= 0.40814 train_acc= 0.91741 val_roc= 0.77259 val_ap= 0.82804 time= 0.44398\n",
            "Epoch: 0656 train_loss= 0.40814 train_acc= 0.91748 val_roc= 0.77228 val_ap= 0.82789 time= 0.39923\n",
            "Epoch: 0657 train_loss= 0.40813 train_acc= 0.91759 val_roc= 0.77198 val_ap= 0.82767 time= 0.41239\n",
            "Epoch: 0658 train_loss= 0.40813 train_acc= 0.91769 val_roc= 0.77180 val_ap= 0.82759 time= 0.41157\n",
            "Epoch: 0659 train_loss= 0.40813 train_acc= 0.91777 val_roc= 0.77154 val_ap= 0.82743 time= 0.40974\n",
            "Epoch: 0660 train_loss= 0.40813 train_acc= 0.91784 val_roc= 0.77131 val_ap= 0.82727 time= 0.40109\n",
            "Epoch: 0661 train_loss= 0.40812 train_acc= 0.91797 val_roc= 0.77100 val_ap= 0.82709 time= 0.42881\n",
            "Epoch: 0662 train_loss= 0.40812 train_acc= 0.91804 val_roc= 0.77071 val_ap= 0.82687 time= 0.44421\n",
            "Epoch: 0663 train_loss= 0.40812 train_acc= 0.91817 val_roc= 0.77045 val_ap= 0.82674 time= 0.42696\n",
            "Epoch: 0664 train_loss= 0.40812 train_acc= 0.91829 val_roc= 0.77012 val_ap= 0.82657 time= 0.44128\n",
            "Epoch: 0665 train_loss= 0.40811 train_acc= 0.91842 val_roc= 0.76987 val_ap= 0.82643 time= 0.42342\n",
            "Epoch: 0666 train_loss= 0.40811 train_acc= 0.91850 val_roc= 0.76949 val_ap= 0.82617 time= 0.42495\n",
            "Epoch: 0667 train_loss= 0.40811 train_acc= 0.91861 val_roc= 0.76919 val_ap= 0.82594 time= 0.40793\n",
            "Epoch: 0668 train_loss= 0.40811 train_acc= 0.91870 val_roc= 0.76897 val_ap= 0.82583 time= 0.40713\n",
            "Epoch: 0669 train_loss= 0.40811 train_acc= 0.91880 val_roc= 0.76873 val_ap= 0.82570 time= 0.42785\n",
            "Epoch: 0670 train_loss= 0.40810 train_acc= 0.91890 val_roc= 0.76835 val_ap= 0.82549 time= 0.40768\n",
            "Epoch: 0671 train_loss= 0.40810 train_acc= 0.91902 val_roc= 0.76807 val_ap= 0.82538 time= 0.44952\n",
            "Epoch: 0672 train_loss= 0.40810 train_acc= 0.91913 val_roc= 0.76786 val_ap= 0.82528 time= 0.41889\n",
            "Epoch: 0673 train_loss= 0.40810 train_acc= 0.91924 val_roc= 0.76765 val_ap= 0.82516 time= 0.45273\n",
            "Epoch: 0674 train_loss= 0.40809 train_acc= 0.91933 val_roc= 0.76745 val_ap= 0.82505 time= 0.43183\n",
            "Epoch: 0675 train_loss= 0.40809 train_acc= 0.91946 val_roc= 0.76731 val_ap= 0.82499 time= 0.41607\n",
            "Epoch: 0676 train_loss= 0.40809 train_acc= 0.91955 val_roc= 0.76705 val_ap= 0.82489 time= 0.44695\n",
            "Epoch: 0677 train_loss= 0.40809 train_acc= 0.91967 val_roc= 0.76681 val_ap= 0.82478 time= 0.43000\n",
            "Epoch: 0678 train_loss= 0.40809 train_acc= 0.91972 val_roc= 0.76656 val_ap= 0.82463 time= 0.45252\n",
            "Epoch: 0679 train_loss= 0.40808 train_acc= 0.91981 val_roc= 0.76635 val_ap= 0.82453 time= 0.42449\n",
            "Epoch: 0680 train_loss= 0.40808 train_acc= 0.91988 val_roc= 0.76613 val_ap= 0.82441 time= 0.40402\n",
            "Epoch: 0681 train_loss= 0.40808 train_acc= 0.91994 val_roc= 0.76597 val_ap= 0.82434 time= 0.42151\n",
            "Epoch: 0682 train_loss= 0.40808 train_acc= 0.92000 val_roc= 0.76566 val_ap= 0.82418 time= 0.41066\n",
            "Epoch: 0683 train_loss= 0.40807 train_acc= 0.92006 val_roc= 0.76543 val_ap= 0.82407 time= 0.41655\n",
            "Epoch: 0684 train_loss= 0.40807 train_acc= 0.92013 val_roc= 0.76534 val_ap= 0.82410 time= 0.41606\n",
            "Epoch: 0685 train_loss= 0.40807 train_acc= 0.92020 val_roc= 0.76517 val_ap= 0.82402 time= 0.41914\n",
            "Epoch: 0686 train_loss= 0.40807 train_acc= 0.92026 val_roc= 0.76497 val_ap= 0.82391 time= 0.40755\n",
            "Epoch: 0687 train_loss= 0.40807 train_acc= 0.92033 val_roc= 0.76470 val_ap= 0.82378 time= 0.44134\n",
            "Epoch: 0688 train_loss= 0.40806 train_acc= 0.92039 val_roc= 0.76462 val_ap= 0.82375 time= 0.44248\n",
            "Epoch: 0689 train_loss= 0.40806 train_acc= 0.92048 val_roc= 0.76447 val_ap= 0.82368 time= 0.41628\n",
            "Epoch: 0690 train_loss= 0.40806 train_acc= 0.92058 val_roc= 0.76428 val_ap= 0.82358 time= 0.41595\n",
            "Epoch: 0691 train_loss= 0.40806 train_acc= 0.92066 val_roc= 0.76420 val_ap= 0.82355 time= 0.42049\n",
            "Epoch: 0692 train_loss= 0.40806 train_acc= 0.92076 val_roc= 0.76395 val_ap= 0.82342 time= 0.40512\n",
            "Epoch: 0693 train_loss= 0.40805 train_acc= 0.92088 val_roc= 0.76375 val_ap= 0.82333 time= 0.41498\n",
            "Epoch: 0694 train_loss= 0.40805 train_acc= 0.92096 val_roc= 0.76356 val_ap= 0.82323 time= 0.40683\n",
            "Epoch: 0695 train_loss= 0.40805 train_acc= 0.92105 val_roc= 0.76338 val_ap= 0.82315 time= 0.41325\n",
            "Epoch: 0696 train_loss= 0.40805 train_acc= 0.92115 val_roc= 0.76314 val_ap= 0.82298 time= 0.40733\n",
            "Epoch: 0697 train_loss= 0.40805 train_acc= 0.92125 val_roc= 0.76296 val_ap= 0.82289 time= 0.41039\n",
            "Epoch: 0698 train_loss= 0.40804 train_acc= 0.92131 val_roc= 0.76277 val_ap= 0.82282 time= 0.41388\n",
            "Epoch: 0699 train_loss= 0.40804 train_acc= 0.92137 val_roc= 0.76268 val_ap= 0.82279 time= 0.40729\n",
            "Epoch: 0700 train_loss= 0.40804 train_acc= 0.92142 val_roc= 0.76252 val_ap= 0.82267 time= 0.41005\n",
            "Epoch: 0701 train_loss= 0.40804 train_acc= 0.92149 val_roc= 0.76242 val_ap= 0.82265 time= 0.41989\n",
            "Epoch: 0702 train_loss= 0.40804 train_acc= 0.92154 val_roc= 0.76227 val_ap= 0.82257 time= 0.44399\n",
            "Epoch: 0703 train_loss= 0.40804 train_acc= 0.92160 val_roc= 0.76221 val_ap= 0.82255 time= 0.43107\n",
            "Epoch: 0704 train_loss= 0.40803 train_acc= 0.92166 val_roc= 0.76207 val_ap= 0.82246 time= 0.40639\n",
            "Epoch: 0705 train_loss= 0.40803 train_acc= 0.92172 val_roc= 0.76198 val_ap= 0.82237 time= 0.41681\n",
            "Epoch: 0706 train_loss= 0.40803 train_acc= 0.92178 val_roc= 0.76187 val_ap= 0.82232 time= 0.41131\n",
            "Epoch: 0707 train_loss= 0.40803 train_acc= 0.92184 val_roc= 0.76182 val_ap= 0.82229 time= 0.41491\n",
            "Epoch: 0708 train_loss= 0.40802 train_acc= 0.92189 val_roc= 0.76169 val_ap= 0.82219 time= 0.41624\n",
            "Epoch: 0709 train_loss= 0.40802 train_acc= 0.92196 val_roc= 0.76160 val_ap= 0.82212 time= 0.41267\n",
            "Epoch: 0710 train_loss= 0.40802 train_acc= 0.92202 val_roc= 0.76154 val_ap= 0.82210 time= 0.41168\n",
            "Epoch: 0711 train_loss= 0.40802 train_acc= 0.92207 val_roc= 0.76153 val_ap= 0.82209 time= 0.41729\n",
            "Epoch: 0712 train_loss= 0.40802 train_acc= 0.92211 val_roc= 0.76137 val_ap= 0.82194 time= 0.40832\n",
            "Epoch: 0713 train_loss= 0.40801 train_acc= 0.92220 val_roc= 0.76127 val_ap= 0.82188 time= 0.40952\n",
            "Epoch: 0714 train_loss= 0.40801 train_acc= 0.92225 val_roc= 0.76121 val_ap= 0.82186 time= 0.41113\n",
            "Epoch: 0715 train_loss= 0.40801 train_acc= 0.92230 val_roc= 0.76117 val_ap= 0.82184 time= 0.41169\n",
            "Epoch: 0716 train_loss= 0.40801 train_acc= 0.92238 val_roc= 0.76114 val_ap= 0.82181 time= 0.40657\n",
            "Epoch: 0717 train_loss= 0.40801 train_acc= 0.92263 val_roc= 0.76099 val_ap= 0.82172 time= 0.41322\n",
            "Epoch: 0718 train_loss= 0.40800 train_acc= 0.92268 val_roc= 0.76096 val_ap= 0.82171 time= 0.40905\n",
            "Epoch: 0719 train_loss= 0.40800 train_acc= 0.92273 val_roc= 0.76098 val_ap= 0.82170 time= 0.41640\n",
            "Epoch: 0720 train_loss= 0.40800 train_acc= 0.92279 val_roc= 0.76102 val_ap= 0.82173 time= 0.40707\n",
            "Epoch: 0721 train_loss= 0.40800 train_acc= 0.92289 val_roc= 0.76095 val_ap= 0.82171 time= 0.40785\n",
            "Epoch: 0722 train_loss= 0.40800 train_acc= 0.92296 val_roc= 0.76079 val_ap= 0.82162 time= 0.43836\n",
            "Epoch: 0723 train_loss= 0.40799 train_acc= 0.92301 val_roc= 0.76071 val_ap= 0.82152 time= 0.41201\n",
            "Epoch: 0724 train_loss= 0.40799 train_acc= 0.92309 val_roc= 0.76068 val_ap= 0.82149 time= 0.40888\n",
            "Epoch: 0725 train_loss= 0.40799 train_acc= 0.92314 val_roc= 0.76060 val_ap= 0.82143 time= 0.41185\n",
            "Epoch: 0726 train_loss= 0.40799 train_acc= 0.92321 val_roc= 0.76052 val_ap= 0.82135 time= 0.41342\n",
            "Epoch: 0727 train_loss= 0.40799 train_acc= 0.92325 val_roc= 0.76052 val_ap= 0.82133 time= 0.41640\n",
            "Epoch: 0728 train_loss= 0.40799 train_acc= 0.92330 val_roc= 0.76044 val_ap= 0.82125 time= 0.41997\n",
            "Epoch: 0729 train_loss= 0.40798 train_acc= 0.92334 val_roc= 0.76046 val_ap= 0.82126 time= 0.40981\n",
            "Epoch: 0730 train_loss= 0.40798 train_acc= 0.92338 val_roc= 0.76040 val_ap= 0.82122 time= 0.40749\n",
            "Epoch: 0731 train_loss= 0.40798 train_acc= 0.92342 val_roc= 0.76033 val_ap= 0.82116 time= 0.40712\n",
            "Epoch: 0732 train_loss= 0.40798 train_acc= 0.92346 val_roc= 0.76028 val_ap= 0.82111 time= 0.41576\n",
            "Epoch: 0733 train_loss= 0.40798 train_acc= 0.92351 val_roc= 0.76018 val_ap= 0.82103 time= 0.41097\n",
            "Epoch: 0734 train_loss= 0.40797 train_acc= 0.92359 val_roc= 0.76012 val_ap= 0.82096 time= 0.40791\n",
            "Epoch: 0735 train_loss= 0.40797 train_acc= 0.92364 val_roc= 0.76012 val_ap= 0.82093 time= 0.40841\n",
            "Epoch: 0736 train_loss= 0.40797 train_acc= 0.92373 val_roc= 0.76002 val_ap= 0.82086 time= 0.41197\n",
            "Epoch: 0737 train_loss= 0.40797 train_acc= 0.92376 val_roc= 0.76002 val_ap= 0.82087 time= 0.41244\n",
            "Epoch: 0738 train_loss= 0.40797 train_acc= 0.92383 val_roc= 0.75997 val_ap= 0.82081 time= 0.40856\n",
            "Epoch: 0739 train_loss= 0.40797 train_acc= 0.92389 val_roc= 0.76001 val_ap= 0.82083 time= 0.41250\n",
            "Epoch: 0740 train_loss= 0.40796 train_acc= 0.92395 val_roc= 0.75999 val_ap= 0.82082 time= 0.41065\n",
            "Epoch: 0741 train_loss= 0.40796 train_acc= 0.92398 val_roc= 0.75997 val_ap= 0.82081 time= 0.41043\n",
            "Epoch: 0742 train_loss= 0.40796 train_acc= 0.92402 val_roc= 0.75994 val_ap= 0.82079 time= 0.41241\n",
            "Epoch: 0743 train_loss= 0.40796 train_acc= 0.92406 val_roc= 0.75990 val_ap= 0.82078 time= 0.41068\n",
            "Epoch: 0744 train_loss= 0.40796 train_acc= 0.92410 val_roc= 0.75995 val_ap= 0.82084 time= 0.41944\n",
            "Epoch: 0745 train_loss= 0.40796 train_acc= 0.92415 val_roc= 0.75982 val_ap= 0.82070 time= 0.43712\n",
            "Epoch: 0746 train_loss= 0.40796 train_acc= 0.92418 val_roc= 0.75980 val_ap= 0.82069 time= 0.43358\n",
            "Epoch: 0747 train_loss= 0.40795 train_acc= 0.92421 val_roc= 0.75978 val_ap= 0.82070 time= 0.41286\n",
            "Epoch: 0748 train_loss= 0.40795 train_acc= 0.92424 val_roc= 0.75976 val_ap= 0.82068 time= 0.40797\n",
            "Epoch: 0749 train_loss= 0.40795 train_acc= 0.92427 val_roc= 0.75973 val_ap= 0.82066 time= 0.42447\n",
            "Epoch: 0750 train_loss= 0.40795 train_acc= 0.92431 val_roc= 0.75962 val_ap= 0.82058 time= 0.43744\n",
            "Epoch: 0751 train_loss= 0.40795 train_acc= 0.92438 val_roc= 0.75960 val_ap= 0.82057 time= 0.44200\n",
            "Epoch: 0752 train_loss= 0.40795 train_acc= 0.92441 val_roc= 0.75960 val_ap= 0.82056 time= 0.43176\n",
            "Epoch: 0753 train_loss= 0.40794 train_acc= 0.92445 val_roc= 0.75957 val_ap= 0.82054 time= 0.40569\n",
            "Epoch: 0754 train_loss= 0.40794 train_acc= 0.92448 val_roc= 0.75952 val_ap= 0.82052 time= 0.41763\n",
            "Epoch: 0755 train_loss= 0.40794 train_acc= 0.92451 val_roc= 0.75949 val_ap= 0.82051 time= 0.44356\n",
            "Epoch: 0756 train_loss= 0.40794 train_acc= 0.92455 val_roc= 0.75942 val_ap= 0.82047 time= 0.41254\n",
            "Epoch: 0757 train_loss= 0.40794 train_acc= 0.92459 val_roc= 0.75935 val_ap= 0.82042 time= 0.40693\n",
            "Epoch: 0758 train_loss= 0.40794 train_acc= 0.92463 val_roc= 0.75929 val_ap= 0.82038 time= 0.40824\n",
            "Epoch: 0759 train_loss= 0.40793 train_acc= 0.92467 val_roc= 0.75926 val_ap= 0.82035 time= 0.40535\n",
            "Epoch: 0760 train_loss= 0.40793 train_acc= 0.92475 val_roc= 0.75919 val_ap= 0.82032 time= 0.40332\n",
            "Epoch: 0761 train_loss= 0.40793 train_acc= 0.92479 val_roc= 0.75920 val_ap= 0.82032 time= 0.41453\n",
            "Epoch: 0762 train_loss= 0.40793 train_acc= 0.92483 val_roc= 0.75912 val_ap= 0.82028 time= 0.40524\n",
            "Epoch: 0763 train_loss= 0.40793 train_acc= 0.92487 val_roc= 0.75905 val_ap= 0.82026 time= 0.41086\n",
            "Epoch: 0764 train_loss= 0.40793 train_acc= 0.92492 val_roc= 0.75896 val_ap= 0.82020 time= 0.40509\n",
            "Epoch: 0765 train_loss= 0.40793 train_acc= 0.92497 val_roc= 0.75888 val_ap= 0.82014 time= 0.41470\n",
            "Epoch: 0766 train_loss= 0.40793 train_acc= 0.92501 val_roc= 0.75885 val_ap= 0.82012 time= 0.41286\n",
            "Epoch: 0767 train_loss= 0.40793 train_acc= 0.92504 val_roc= 0.75876 val_ap= 0.82007 time= 0.40194\n",
            "Epoch: 0768 train_loss= 0.40792 train_acc= 0.92508 val_roc= 0.75863 val_ap= 0.81998 time= 0.40734\n",
            "Epoch: 0769 train_loss= 0.40792 train_acc= 0.92515 val_roc= 0.75853 val_ap= 0.81991 time= 0.40562\n",
            "Epoch: 0770 train_loss= 0.40792 train_acc= 0.92522 val_roc= 0.75856 val_ap= 0.81995 time= 0.40516\n",
            "Epoch: 0771 train_loss= 0.40792 train_acc= 0.92531 val_roc= 0.75857 val_ap= 0.81994 time= 0.43056\n",
            "Epoch: 0772 train_loss= 0.40792 train_acc= 0.92533 val_roc= 0.75848 val_ap= 0.81987 time= 0.40728\n",
            "Epoch: 0773 train_loss= 0.40792 train_acc= 0.92538 val_roc= 0.75830 val_ap= 0.81976 time= 0.41913\n",
            "Epoch: 0774 train_loss= 0.40792 train_acc= 0.92542 val_roc= 0.75817 val_ap= 0.81968 time= 0.41252\n",
            "Epoch: 0775 train_loss= 0.40791 train_acc= 0.92545 val_roc= 0.75794 val_ap= 0.81955 time= 0.42540\n",
            "Epoch: 0776 train_loss= 0.40791 train_acc= 0.92552 val_roc= 0.75786 val_ap= 0.81951 time= 0.41612\n",
            "Epoch: 0777 train_loss= 0.40791 train_acc= 0.92558 val_roc= 0.75779 val_ap= 0.81948 time= 0.40731\n",
            "Epoch: 0778 train_loss= 0.40791 train_acc= 0.92560 val_roc= 0.75773 val_ap= 0.81947 time= 0.41098\n",
            "Epoch: 0779 train_loss= 0.40791 train_acc= 0.92562 val_roc= 0.75764 val_ap= 0.81940 time= 0.40644\n",
            "Epoch: 0780 train_loss= 0.40791 train_acc= 0.92568 val_roc= 0.75749 val_ap= 0.81929 time= 0.42120\n",
            "Epoch: 0781 train_loss= 0.40791 train_acc= 0.92573 val_roc= 0.75743 val_ap= 0.81924 time= 0.40883\n",
            "Epoch: 0782 train_loss= 0.40790 train_acc= 0.92576 val_roc= 0.75738 val_ap= 0.81921 time= 0.41361\n",
            "Epoch: 0783 train_loss= 0.40790 train_acc= 0.92580 val_roc= 0.75736 val_ap= 0.81920 time= 0.41785\n",
            "Epoch: 0784 train_loss= 0.40790 train_acc= 0.92585 val_roc= 0.75718 val_ap= 0.81911 time= 0.40624\n",
            "Epoch: 0785 train_loss= 0.40790 train_acc= 0.92590 val_roc= 0.75706 val_ap= 0.81904 time= 0.41762\n",
            "Epoch: 0786 train_loss= 0.40790 train_acc= 0.92596 val_roc= 0.75689 val_ap= 0.81895 time= 0.41137\n",
            "Epoch: 0787 train_loss= 0.40790 train_acc= 0.92600 val_roc= 0.75678 val_ap= 0.81888 time= 0.40959\n",
            "Epoch: 0788 train_loss= 0.40790 train_acc= 0.92604 val_roc= 0.75665 val_ap= 0.81883 time= 0.41729\n",
            "Epoch: 0789 train_loss= 0.40790 train_acc= 0.92609 val_roc= 0.75655 val_ap= 0.81880 time= 0.40850\n",
            "Epoch: 0790 train_loss= 0.40790 train_acc= 0.92612 val_roc= 0.75652 val_ap= 0.81880 time= 0.40991\n",
            "Epoch: 0791 train_loss= 0.40790 train_acc= 0.92617 val_roc= 0.75634 val_ap= 0.81869 time= 0.41386\n",
            "Epoch: 0792 train_loss= 0.40790 train_acc= 0.92619 val_roc= 0.75623 val_ap= 0.81862 time= 0.41568\n",
            "Epoch: 0793 train_loss= 0.40789 train_acc= 0.92623 val_roc= 0.75610 val_ap= 0.81853 time= 0.42452\n",
            "Epoch: 0794 train_loss= 0.40789 train_acc= 0.92626 val_roc= 0.75596 val_ap= 0.81846 time= 0.41797\n",
            "Epoch: 0795 train_loss= 0.40789 train_acc= 0.92629 val_roc= 0.75580 val_ap= 0.81836 time= 0.41699\n",
            "Epoch: 0796 train_loss= 0.40789 train_acc= 0.92634 val_roc= 0.75561 val_ap= 0.81825 time= 0.41449\n",
            "Epoch: 0797 train_loss= 0.40789 train_acc= 0.92636 val_roc= 0.75543 val_ap= 0.81812 time= 0.41566\n",
            "Epoch: 0798 train_loss= 0.40789 train_acc= 0.92641 val_roc= 0.75532 val_ap= 0.81808 time= 0.41178\n",
            "Epoch: 0799 train_loss= 0.40789 train_acc= 0.92642 val_roc= 0.75524 val_ap= 0.81804 time= 0.41541\n",
            "Epoch: 0800 train_loss= 0.40789 train_acc= 0.92644 val_roc= 0.75515 val_ap= 0.81799 time= 0.42313\n",
            "Epoch: 0801 train_loss= 0.40789 train_acc= 0.92645 val_roc= 0.75503 val_ap= 0.81791 time= 0.42329\n",
            "Epoch: 0802 train_loss= 0.40789 train_acc= 0.92648 val_roc= 0.75492 val_ap= 0.81785 time= 0.43067\n",
            "Epoch: 0803 train_loss= 0.40789 train_acc= 0.92649 val_roc= 0.75480 val_ap= 0.81779 time= 0.40729\n",
            "Epoch: 0804 train_loss= 0.40788 train_acc= 0.92650 val_roc= 0.75471 val_ap= 0.81774 time= 0.40758\n",
            "Epoch: 0805 train_loss= 0.40788 train_acc= 0.92651 val_roc= 0.75458 val_ap= 0.81765 time= 0.41875\n",
            "Epoch: 0806 train_loss= 0.40788 train_acc= 0.92652 val_roc= 0.75450 val_ap= 0.81760 time= 0.40733\n",
            "Epoch: 0807 train_loss= 0.40788 train_acc= 0.92654 val_roc= 0.75434 val_ap= 0.81747 time= 0.41367\n",
            "Epoch: 0808 train_loss= 0.40788 train_acc= 0.92653 val_roc= 0.75423 val_ap= 0.81741 time= 0.40655\n",
            "Epoch: 0809 train_loss= 0.40788 train_acc= 0.92655 val_roc= 0.75406 val_ap= 0.81733 time= 0.41055\n",
            "Epoch: 0810 train_loss= 0.40788 train_acc= 0.92656 val_roc= 0.75401 val_ap= 0.81731 time= 0.41897\n",
            "Epoch: 0811 train_loss= 0.40788 train_acc= 0.92660 val_roc= 0.75385 val_ap= 0.81721 time= 0.41009\n",
            "Epoch: 0812 train_loss= 0.40788 train_acc= 0.92663 val_roc= 0.75381 val_ap= 0.81719 time= 0.44880\n",
            "Epoch: 0813 train_loss= 0.40788 train_acc= 0.92664 val_roc= 0.75378 val_ap= 0.81717 time= 0.45225\n",
            "Epoch: 0814 train_loss= 0.40788 train_acc= 0.92667 val_roc= 0.75368 val_ap= 0.81711 time= 0.42039\n",
            "Epoch: 0815 train_loss= 0.40788 train_acc= 0.92671 val_roc= 0.75357 val_ap= 0.81705 time= 0.40905\n",
            "Epoch: 0816 train_loss= 0.40788 train_acc= 0.92674 val_roc= 0.75346 val_ap= 0.81700 time= 0.41426\n",
            "Epoch: 0817 train_loss= 0.40787 train_acc= 0.92675 val_roc= 0.75342 val_ap= 0.81700 time= 0.41593\n",
            "Epoch: 0818 train_loss= 0.40787 train_acc= 0.92677 val_roc= 0.75331 val_ap= 0.81697 time= 0.41401\n",
            "Epoch: 0819 train_loss= 0.40787 train_acc= 0.92678 val_roc= 0.75321 val_ap= 0.81692 time= 0.43247\n",
            "Epoch: 0820 train_loss= 0.40787 train_acc= 0.92679 val_roc= 0.75311 val_ap= 0.81688 time= 0.41003\n",
            "Epoch: 0821 train_loss= 0.40787 train_acc= 0.92681 val_roc= 0.75306 val_ap= 0.81688 time= 0.43053\n",
            "Epoch: 0822 train_loss= 0.40787 train_acc= 0.92684 val_roc= 0.75295 val_ap= 0.81682 time= 0.44778\n",
            "Epoch: 0823 train_loss= 0.40787 train_acc= 0.92685 val_roc= 0.75286 val_ap= 0.81678 time= 0.44028\n",
            "Epoch: 0824 train_loss= 0.40787 train_acc= 0.92686 val_roc= 0.75278 val_ap= 0.81674 time= 0.42325\n",
            "Epoch: 0825 train_loss= 0.40787 train_acc= 0.92687 val_roc= 0.75265 val_ap= 0.81671 time= 0.43445\n",
            "Epoch: 0826 train_loss= 0.40787 train_acc= 0.92691 val_roc= 0.75261 val_ap= 0.81670 time= 0.42673\n",
            "Epoch: 0827 train_loss= 0.40787 train_acc= 0.92692 val_roc= 0.75254 val_ap= 0.81668 time= 0.44578\n",
            "Epoch: 0828 train_loss= 0.40787 train_acc= 0.92695 val_roc= 0.75247 val_ap= 0.81662 time= 0.42571\n",
            "Epoch: 0829 train_loss= 0.40787 train_acc= 0.92696 val_roc= 0.75243 val_ap= 0.81661 time= 0.45072\n",
            "Epoch: 0830 train_loss= 0.40787 train_acc= 0.92697 val_roc= 0.75236 val_ap= 0.81660 time= 0.44833\n",
            "Epoch: 0831 train_loss= 0.40786 train_acc= 0.92699 val_roc= 0.75232 val_ap= 0.81658 time= 0.44400\n",
            "Epoch: 0832 train_loss= 0.40786 train_acc= 0.92701 val_roc= 0.75224 val_ap= 0.81658 time= 0.42116\n",
            "Epoch: 0833 train_loss= 0.40786 train_acc= 0.92702 val_roc= 0.75217 val_ap= 0.81652 time= 0.43294\n",
            "Epoch: 0834 train_loss= 0.40786 train_acc= 0.92703 val_roc= 0.75214 val_ap= 0.81652 time= 0.43130\n",
            "Epoch: 0835 train_loss= 0.40786 train_acc= 0.92705 val_roc= 0.75210 val_ap= 0.81650 time= 0.40572\n",
            "Epoch: 0836 train_loss= 0.40786 train_acc= 0.92706 val_roc= 0.75208 val_ap= 0.81650 time= 0.41674\n",
            "Epoch: 0837 train_loss= 0.40786 train_acc= 0.92707 val_roc= 0.75205 val_ap= 0.81652 time= 0.43697\n",
            "Epoch: 0838 train_loss= 0.40786 train_acc= 0.92711 val_roc= 0.75205 val_ap= 0.81653 time= 0.43440\n",
            "Epoch: 0839 train_loss= 0.40786 train_acc= 0.92712 val_roc= 0.75203 val_ap= 0.81648 time= 0.40927\n",
            "Epoch: 0840 train_loss= 0.40786 train_acc= 0.92713 val_roc= 0.75196 val_ap= 0.81645 time= 0.45175\n",
            "Epoch: 0841 train_loss= 0.40786 train_acc= 0.92712 val_roc= 0.75188 val_ap= 0.81643 time= 0.43556\n",
            "Epoch: 0842 train_loss= 0.40786 train_acc= 0.92715 val_roc= 0.75185 val_ap= 0.81640 time= 0.42108\n",
            "Epoch: 0843 train_loss= 0.40786 train_acc= 0.92717 val_roc= 0.75174 val_ap= 0.81634 time= 0.44755\n",
            "Epoch: 0844 train_loss= 0.40785 train_acc= 0.92718 val_roc= 0.75168 val_ap= 0.81631 time= 0.43950\n",
            "Epoch: 0845 train_loss= 0.40785 train_acc= 0.92722 val_roc= 0.75170 val_ap= 0.81629 time= 0.45099\n",
            "Epoch: 0846 train_loss= 0.40785 train_acc= 0.92726 val_roc= 0.75158 val_ap= 0.81622 time= 0.40991\n",
            "Epoch: 0847 train_loss= 0.40785 train_acc= 0.92729 val_roc= 0.75153 val_ap= 0.81619 time= 0.43172\n",
            "Epoch: 0848 train_loss= 0.40785 train_acc= 0.92731 val_roc= 0.75147 val_ap= 0.81616 time= 0.40910\n",
            "Epoch: 0849 train_loss= 0.40785 train_acc= 0.92735 val_roc= 0.75144 val_ap= 0.81615 time= 0.44608\n",
            "Epoch: 0850 train_loss= 0.40785 train_acc= 0.92738 val_roc= 0.75146 val_ap= 0.81615 time= 0.44106\n",
            "Epoch: 0851 train_loss= 0.40785 train_acc= 0.92740 val_roc= 0.75141 val_ap= 0.81614 time= 0.43408\n",
            "Epoch: 0852 train_loss= 0.40785 train_acc= 0.92743 val_roc= 0.75140 val_ap= 0.81615 time= 0.41253\n",
            "Epoch: 0853 train_loss= 0.40785 train_acc= 0.92745 val_roc= 0.75139 val_ap= 0.81616 time= 0.42692\n",
            "Epoch: 0854 train_loss= 0.40784 train_acc= 0.92749 val_roc= 0.75131 val_ap= 0.81610 time= 0.41281\n",
            "Epoch: 0855 train_loss= 0.40784 train_acc= 0.92754 val_roc= 0.75130 val_ap= 0.81610 time= 0.41454\n",
            "Epoch: 0856 train_loss= 0.40784 train_acc= 0.92756 val_roc= 0.75129 val_ap= 0.81610 time= 0.41084\n",
            "Epoch: 0857 train_loss= 0.40784 train_acc= 0.92758 val_roc= 0.75123 val_ap= 0.81608 time= 0.41555\n",
            "Epoch: 0858 train_loss= 0.40784 train_acc= 0.92761 val_roc= 0.75125 val_ap= 0.81610 time= 0.42944\n",
            "Epoch: 0859 train_loss= 0.40784 train_acc= 0.92765 val_roc= 0.75122 val_ap= 0.81610 time= 0.44779\n",
            "Epoch: 0860 train_loss= 0.40784 train_acc= 0.92767 val_roc= 0.75116 val_ap= 0.81606 time= 0.42570\n",
            "Epoch: 0861 train_loss= 0.40784 train_acc= 0.92769 val_roc= 0.75116 val_ap= 0.81607 time= 0.41268\n",
            "Epoch: 0862 train_loss= 0.40784 train_acc= 0.92771 val_roc= 0.75116 val_ap= 0.81607 time= 0.41584\n",
            "Epoch: 0863 train_loss= 0.40784 train_acc= 0.92775 val_roc= 0.75112 val_ap= 0.81606 time= 0.40820\n",
            "Epoch: 0864 train_loss= 0.40784 train_acc= 0.92783 val_roc= 0.75108 val_ap= 0.81604 time= 0.41557\n",
            "Epoch: 0865 train_loss= 0.40783 train_acc= 0.92786 val_roc= 0.75103 val_ap= 0.81602 time= 0.41648\n",
            "Epoch: 0866 train_loss= 0.40783 train_acc= 0.92790 val_roc= 0.75099 val_ap= 0.81600 time= 0.41233\n",
            "Epoch: 0867 train_loss= 0.40783 train_acc= 0.92820 val_roc= 0.75096 val_ap= 0.81598 time= 0.41772\n",
            "Epoch: 0868 train_loss= 0.40783 train_acc= 0.92825 val_roc= 0.75091 val_ap= 0.81595 time= 0.42142\n",
            "Epoch: 0869 train_loss= 0.40783 train_acc= 0.92829 val_roc= 0.75090 val_ap= 0.81595 time= 0.41637\n",
            "Epoch: 0870 train_loss= 0.40783 train_acc= 0.92830 val_roc= 0.75095 val_ap= 0.81598 time= 0.41995\n",
            "Epoch: 0871 train_loss= 0.40783 train_acc= 0.92832 val_roc= 0.75093 val_ap= 0.81597 time= 0.42609\n",
            "Epoch: 0872 train_loss= 0.40783 train_acc= 0.92834 val_roc= 0.75092 val_ap= 0.81593 time= 0.40768\n",
            "Epoch: 0873 train_loss= 0.40783 train_acc= 0.92837 val_roc= 0.75087 val_ap= 0.81591 time= 0.41833\n",
            "Epoch: 0874 train_loss= 0.40783 train_acc= 0.92838 val_roc= 0.75084 val_ap= 0.81590 time= 0.41680\n",
            "Epoch: 0875 train_loss= 0.40783 train_acc= 0.92840 val_roc= 0.75080 val_ap= 0.81588 time= 0.41003\n",
            "Epoch: 0876 train_loss= 0.40782 train_acc= 0.92844 val_roc= 0.75076 val_ap= 0.81585 time= 0.40866\n",
            "Epoch: 0877 train_loss= 0.40782 train_acc= 0.92847 val_roc= 0.75067 val_ap= 0.81578 time= 0.41055\n",
            "Epoch: 0878 train_loss= 0.40782 train_acc= 0.92849 val_roc= 0.75063 val_ap= 0.81573 time= 0.42881\n",
            "Epoch: 0879 train_loss= 0.40782 train_acc= 0.92850 val_roc= 0.75057 val_ap= 0.81564 time= 0.41650\n",
            "Epoch: 0880 train_loss= 0.40782 train_acc= 0.92855 val_roc= 0.75055 val_ap= 0.81564 time= 0.40798\n",
            "Epoch: 0881 train_loss= 0.40782 train_acc= 0.92858 val_roc= 0.75051 val_ap= 0.81563 time= 0.41246\n",
            "Epoch: 0882 train_loss= 0.40782 train_acc= 0.92864 val_roc= 0.75049 val_ap= 0.81563 time= 0.40769\n",
            "Epoch: 0883 train_loss= 0.40782 train_acc= 0.92867 val_roc= 0.75046 val_ap= 0.81561 time= 0.41031\n",
            "Epoch: 0884 train_loss= 0.40782 train_acc= 0.92870 val_roc= 0.75034 val_ap= 0.81551 time= 0.41960\n",
            "Epoch: 0885 train_loss= 0.40782 train_acc= 0.92872 val_roc= 0.75031 val_ap= 0.81550 time= 0.40518\n",
            "Epoch: 0886 train_loss= 0.40782 train_acc= 0.92877 val_roc= 0.75026 val_ap= 0.81547 time= 0.40781\n",
            "Epoch: 0887 train_loss= 0.40782 train_acc= 0.92882 val_roc= 0.75021 val_ap= 0.81545 time= 0.41050\n",
            "Epoch: 0888 train_loss= 0.40782 train_acc= 0.92883 val_roc= 0.75016 val_ap= 0.81544 time= 0.40820\n",
            "Epoch: 0889 train_loss= 0.40781 train_acc= 0.92885 val_roc= 0.75009 val_ap= 0.81539 time= 0.41612\n",
            "Epoch: 0890 train_loss= 0.40781 train_acc= 0.92887 val_roc= 0.75000 val_ap= 0.81529 time= 0.42391\n",
            "Epoch: 0891 train_loss= 0.40781 train_acc= 0.92889 val_roc= 0.74992 val_ap= 0.81524 time= 0.44438\n",
            "Epoch: 0892 train_loss= 0.40781 train_acc= 0.92891 val_roc= 0.74989 val_ap= 0.81526 time= 0.41098\n",
            "Epoch: 0893 train_loss= 0.40781 train_acc= 0.92895 val_roc= 0.74987 val_ap= 0.81526 time= 0.41639\n",
            "Epoch: 0894 train_loss= 0.40781 train_acc= 0.92898 val_roc= 0.74981 val_ap= 0.81523 time= 0.41772\n",
            "Epoch: 0895 train_loss= 0.40781 train_acc= 0.92902 val_roc= 0.74982 val_ap= 0.81524 time= 0.40813\n",
            "Epoch: 0896 train_loss= 0.40782 train_acc= 0.92905 val_roc= 0.74983 val_ap= 0.81524 time= 0.41456\n",
            "Epoch: 0897 train_loss= 0.40782 train_acc= 0.92930 val_roc= 0.74982 val_ap= 0.81523 time= 0.40489\n",
            "Epoch: 0898 train_loss= 0.40782 train_acc= 0.92938 val_roc= 0.74981 val_ap= 0.81523 time= 0.43976\n",
            "Epoch: 0899 train_loss= 0.40781 train_acc= 0.92939 val_roc= 0.74982 val_ap= 0.81523 time= 0.41585\n",
            "Epoch: 0900 train_loss= 0.40781 train_acc= 0.92943 val_roc= 0.74978 val_ap= 0.81520 time= 0.41732\n",
            "Epoch: 0901 train_loss= 0.40781 train_acc= 0.92944 val_roc= 0.74977 val_ap= 0.81519 time= 0.42685\n",
            "Epoch: 0902 train_loss= 0.40781 train_acc= 0.92945 val_roc= 0.74975 val_ap= 0.81516 time= 0.43745\n",
            "Epoch: 0903 train_loss= 0.40781 train_acc= 0.92947 val_roc= 0.74970 val_ap= 0.81513 time= 0.44639\n",
            "Epoch: 0904 train_loss= 0.40781 train_acc= 0.92955 val_roc= 0.74961 val_ap= 0.81506 time= 0.44243\n",
            "Epoch: 0905 train_loss= 0.40781 train_acc= 0.92956 val_roc= 0.74952 val_ap= 0.81498 time= 0.40888\n",
            "Epoch: 0906 train_loss= 0.40781 train_acc= 0.92957 val_roc= 0.74948 val_ap= 0.81494 time= 0.40772\n",
            "Epoch: 0907 train_loss= 0.40781 train_acc= 0.92958 val_roc= 0.74940 val_ap= 0.81490 time= 0.41200\n",
            "Epoch: 0908 train_loss= 0.40781 train_acc= 0.92961 val_roc= 0.74937 val_ap= 0.81488 time= 0.41947\n",
            "Epoch: 0909 train_loss= 0.40781 train_acc= 0.92960 val_roc= 0.74929 val_ap= 0.81483 time= 0.41026\n",
            "Epoch: 0910 train_loss= 0.40781 train_acc= 0.92961 val_roc= 0.74924 val_ap= 0.81480 time= 0.41159\n",
            "Epoch: 0911 train_loss= 0.40781 train_acc= 0.92961 val_roc= 0.74922 val_ap= 0.81480 time= 0.42658\n",
            "Epoch: 0912 train_loss= 0.40781 train_acc= 0.92964 val_roc= 0.74918 val_ap= 0.81475 time= 0.40803\n",
            "Epoch: 0913 train_loss= 0.40781 train_acc= 0.92964 val_roc= 0.74916 val_ap= 0.81472 time= 0.42622\n",
            "Epoch: 0914 train_loss= 0.40781 train_acc= 0.92964 val_roc= 0.74914 val_ap= 0.81471 time= 0.40706\n",
            "Epoch: 0915 train_loss= 0.40781 train_acc= 0.92965 val_roc= 0.74908 val_ap= 0.81467 time= 0.41202\n",
            "Epoch: 0916 train_loss= 0.40781 train_acc= 0.92966 val_roc= 0.74902 val_ap= 0.81462 time= 0.45037\n",
            "Epoch: 0917 train_loss= 0.40781 train_acc= 0.92966 val_roc= 0.74900 val_ap= 0.81462 time= 0.43423\n",
            "Epoch: 0918 train_loss= 0.40781 train_acc= 0.92967 val_roc= 0.74900 val_ap= 0.81462 time= 0.40899\n",
            "Epoch: 0919 train_loss= 0.40781 train_acc= 0.92970 val_roc= 0.74898 val_ap= 0.81459 time= 0.40477\n",
            "Epoch: 0920 train_loss= 0.40781 train_acc= 0.92971 val_roc= 0.74891 val_ap= 0.81454 time= 0.42935\n",
            "Epoch: 0921 train_loss= 0.40781 train_acc= 0.92974 val_roc= 0.74888 val_ap= 0.81452 time= 0.43730\n",
            "Epoch: 0922 train_loss= 0.40781 train_acc= 0.92975 val_roc= 0.74882 val_ap= 0.81448 time= 0.42432\n",
            "Epoch: 0923 train_loss= 0.40781 train_acc= 0.92976 val_roc= 0.74875 val_ap= 0.81438 time= 0.41161\n",
            "Epoch: 0924 train_loss= 0.40781 train_acc= 0.92979 val_roc= 0.74869 val_ap= 0.81434 time= 0.40541\n",
            "Epoch: 0925 train_loss= 0.40781 train_acc= 0.92980 val_roc= 0.74862 val_ap= 0.81430 time= 0.42533\n",
            "Epoch: 0926 train_loss= 0.40781 train_acc= 0.92983 val_roc= 0.74859 val_ap= 0.81424 time= 0.43440\n",
            "Epoch: 0927 train_loss= 0.40780 train_acc= 0.92984 val_roc= 0.74860 val_ap= 0.81423 time= 0.42632\n",
            "Epoch: 0928 train_loss= 0.40780 train_acc= 0.92987 val_roc= 0.74855 val_ap= 0.81419 time= 0.41173\n",
            "Epoch: 0929 train_loss= 0.40780 train_acc= 0.92988 val_roc= 0.74853 val_ap= 0.81418 time= 0.43748\n",
            "Epoch: 0930 train_loss= 0.40780 train_acc= 0.92989 val_roc= 0.74849 val_ap= 0.81415 time= 0.40437\n",
            "Epoch: 0931 train_loss= 0.40780 train_acc= 0.92990 val_roc= 0.74844 val_ap= 0.81409 time= 0.40759\n",
            "Epoch: 0932 train_loss= 0.40780 train_acc= 0.92991 val_roc= 0.74842 val_ap= 0.81407 time= 0.41280\n",
            "Epoch: 0933 train_loss= 0.40780 train_acc= 0.92991 val_roc= 0.74840 val_ap= 0.81405 time= 0.40695\n",
            "Epoch: 0934 train_loss= 0.40780 train_acc= 0.92992 val_roc= 0.74835 val_ap= 0.81401 time= 0.41170\n",
            "Epoch: 0935 train_loss= 0.40780 train_acc= 0.92992 val_roc= 0.74836 val_ap= 0.81402 time= 0.41868\n",
            "Epoch: 0936 train_loss= 0.40780 train_acc= 0.92993 val_roc= 0.74833 val_ap= 0.81400 time= 0.41935\n",
            "Epoch: 0937 train_loss= 0.40780 train_acc= 0.92994 val_roc= 0.74833 val_ap= 0.81402 time= 0.43339\n",
            "Epoch: 0938 train_loss= 0.40780 train_acc= 0.92994 val_roc= 0.74827 val_ap= 0.81396 time= 0.40837\n",
            "Epoch: 0939 train_loss= 0.40780 train_acc= 0.92994 val_roc= 0.74830 val_ap= 0.81398 time= 0.42017\n",
            "Epoch: 0940 train_loss= 0.40780 train_acc= 0.92995 val_roc= 0.74828 val_ap= 0.81396 time= 0.40989\n",
            "Epoch: 0941 train_loss= 0.40780 train_acc= 0.92996 val_roc= 0.74828 val_ap= 0.81395 time= 0.41427\n",
            "Epoch: 0942 train_loss= 0.40779 train_acc= 0.92997 val_roc= 0.74826 val_ap= 0.81395 time= 0.43522\n",
            "Epoch: 0943 train_loss= 0.40779 train_acc= 0.92998 val_roc= 0.74828 val_ap= 0.81395 time= 0.40872\n",
            "Epoch: 0944 train_loss= 0.40779 train_acc= 0.93001 val_roc= 0.74830 val_ap= 0.81396 time= 0.42792\n",
            "Epoch: 0945 train_loss= 0.40779 train_acc= 0.93003 val_roc= 0.74833 val_ap= 0.81397 time= 0.41479\n",
            "Epoch: 0946 train_loss= 0.40779 train_acc= 0.93003 val_roc= 0.74827 val_ap= 0.81393 time= 0.42191\n",
            "Epoch: 0947 train_loss= 0.40779 train_acc= 0.93004 val_roc= 0.74827 val_ap= 0.81394 time= 0.40789\n",
            "Epoch: 0948 train_loss= 0.40779 train_acc= 0.93004 val_roc= 0.74833 val_ap= 0.81397 time= 0.41603\n",
            "Epoch: 0949 train_loss= 0.40779 train_acc= 0.93005 val_roc= 0.74831 val_ap= 0.81395 time= 0.41459\n",
            "Epoch: 0950 train_loss= 0.40779 train_acc= 0.93006 val_roc= 0.74827 val_ap= 0.81392 time= 0.40296\n",
            "Epoch: 0951 train_loss= 0.40779 train_acc= 0.93007 val_roc= 0.74822 val_ap= 0.81388 time= 0.41288\n",
            "Epoch: 0952 train_loss= 0.40779 train_acc= 0.93010 val_roc= 0.74819 val_ap= 0.81385 time= 0.40975\n",
            "Epoch: 0953 train_loss= 0.40779 train_acc= 0.93011 val_roc= 0.74819 val_ap= 0.81384 time= 0.41699\n",
            "Epoch: 0954 train_loss= 0.40779 train_acc= 0.93011 val_roc= 0.74817 val_ap= 0.81381 time= 0.43426\n",
            "Epoch: 0955 train_loss= 0.40779 train_acc= 0.93012 val_roc= 0.74816 val_ap= 0.81380 time= 0.42935\n",
            "Epoch: 0956 train_loss= 0.40779 train_acc= 0.93013 val_roc= 0.74813 val_ap= 0.81377 time= 0.41591\n",
            "Epoch: 0957 train_loss= 0.40779 train_acc= 0.93014 val_roc= 0.74812 val_ap= 0.81377 time= 0.41931\n",
            "Epoch: 0958 train_loss= 0.40779 train_acc= 0.93015 val_roc= 0.74811 val_ap= 0.81376 time= 0.41710\n",
            "Epoch: 0959 train_loss= 0.40779 train_acc= 0.93016 val_roc= 0.74811 val_ap= 0.81378 time= 0.42580\n",
            "Epoch: 0960 train_loss= 0.40779 train_acc= 0.93017 val_roc= 0.74811 val_ap= 0.81379 time= 0.43279\n",
            "Epoch: 0961 train_loss= 0.40779 train_acc= 0.93017 val_roc= 0.74812 val_ap= 0.81382 time= 0.43802\n",
            "Epoch: 0962 train_loss= 0.40779 train_acc= 0.93017 val_roc= 0.74813 val_ap= 0.81382 time= 0.40569\n",
            "Epoch: 0963 train_loss= 0.40779 train_acc= 0.93018 val_roc= 0.74811 val_ap= 0.81380 time= 0.41340\n",
            "Epoch: 0964 train_loss= 0.40779 train_acc= 0.93019 val_roc= 0.74811 val_ap= 0.81380 time= 0.40636\n",
            "Epoch: 0965 train_loss= 0.40779 train_acc= 0.93022 val_roc= 0.74810 val_ap= 0.81379 time= 0.40318\n",
            "Epoch: 0966 train_loss= 0.40779 train_acc= 0.93025 val_roc= 0.74812 val_ap= 0.81379 time= 0.41134\n",
            "Epoch: 0967 train_loss= 0.40778 train_acc= 0.93026 val_roc= 0.74809 val_ap= 0.81375 time= 0.40284\n",
            "Epoch: 0968 train_loss= 0.40778 train_acc= 0.93026 val_roc= 0.74808 val_ap= 0.81374 time= 0.42160\n",
            "Epoch: 0969 train_loss= 0.40778 train_acc= 0.93027 val_roc= 0.74802 val_ap= 0.81370 time= 0.44053\n",
            "Epoch: 0970 train_loss= 0.40778 train_acc= 0.93027 val_roc= 0.74802 val_ap= 0.81369 time= 0.43730\n",
            "Epoch: 0971 train_loss= 0.40778 train_acc= 0.93028 val_roc= 0.74799 val_ap= 0.81365 time= 0.41367\n",
            "Epoch: 0972 train_loss= 0.40778 train_acc= 0.93030 val_roc= 0.74797 val_ap= 0.81363 time= 0.41122\n",
            "Epoch: 0973 train_loss= 0.40778 train_acc= 0.93030 val_roc= 0.74794 val_ap= 0.81361 time= 0.41452\n",
            "Epoch: 0974 train_loss= 0.40778 train_acc= 0.93031 val_roc= 0.74790 val_ap= 0.81358 time= 0.40793\n",
            "Epoch: 0975 train_loss= 0.40778 train_acc= 0.93031 val_roc= 0.74788 val_ap= 0.81355 time= 0.41677\n",
            "Epoch: 0976 train_loss= 0.40778 train_acc= 0.93032 val_roc= 0.74785 val_ap= 0.81353 time= 0.41317\n",
            "Epoch: 0977 train_loss= 0.40778 train_acc= 0.93033 val_roc= 0.74784 val_ap= 0.81353 time= 0.41195\n",
            "Epoch: 0978 train_loss= 0.40778 train_acc= 0.93034 val_roc= 0.74778 val_ap= 0.81350 time= 0.41422\n",
            "Epoch: 0979 train_loss= 0.40778 train_acc= 0.93035 val_roc= 0.74775 val_ap= 0.81348 time= 0.40647\n",
            "Epoch: 0980 train_loss= 0.40778 train_acc= 0.93037 val_roc= 0.74773 val_ap= 0.81345 time= 0.45099\n",
            "Epoch: 0981 train_loss= 0.40778 train_acc= 0.93040 val_roc= 0.74772 val_ap= 0.81344 time= 0.44008\n",
            "Epoch: 0982 train_loss= 0.40778 train_acc= 0.93041 val_roc= 0.74775 val_ap= 0.81345 time= 0.42173\n",
            "Epoch: 0983 train_loss= 0.40778 train_acc= 0.93042 val_roc= 0.74774 val_ap= 0.81345 time= 0.41295\n",
            "Epoch: 0984 train_loss= 0.40778 train_acc= 0.93042 val_roc= 0.74771 val_ap= 0.81343 time= 0.41034\n",
            "Epoch: 0985 train_loss= 0.40778 train_acc= 0.93043 val_roc= 0.74766 val_ap= 0.81340 time= 0.43852\n",
            "Epoch: 0986 train_loss= 0.40777 train_acc= 0.93044 val_roc= 0.74762 val_ap= 0.81337 time= 0.43152\n",
            "Epoch: 0987 train_loss= 0.40777 train_acc= 0.93045 val_roc= 0.74760 val_ap= 0.81337 time= 0.41499\n",
            "Epoch: 0988 train_loss= 0.40777 train_acc= 0.93049 val_roc= 0.74754 val_ap= 0.81333 time= 0.41044\n",
            "Epoch: 0989 train_loss= 0.40777 train_acc= 0.93049 val_roc= 0.74752 val_ap= 0.81332 time= 0.41259\n",
            "Epoch: 0990 train_loss= 0.40777 train_acc= 0.93048 val_roc= 0.74749 val_ap= 0.81330 time= 0.42137\n",
            "Epoch: 0991 train_loss= 0.40777 train_acc= 0.93049 val_roc= 0.74745 val_ap= 0.81327 time= 0.42237\n",
            "Epoch: 0992 train_loss= 0.40777 train_acc= 0.93050 val_roc= 0.74742 val_ap= 0.81323 time= 0.41365\n",
            "Epoch: 0993 train_loss= 0.40777 train_acc= 0.93051 val_roc= 0.74737 val_ap= 0.81320 time= 0.41269\n",
            "Epoch: 0994 train_loss= 0.40777 train_acc= 0.93052 val_roc= 0.74737 val_ap= 0.81319 time= 0.41371\n",
            "Epoch: 0995 train_loss= 0.40777 train_acc= 0.93054 val_roc= 0.74737 val_ap= 0.81318 time= 0.41925\n",
            "Epoch: 0996 train_loss= 0.40777 train_acc= 0.93055 val_roc= 0.74730 val_ap= 0.81311 time= 0.41134\n",
            "Epoch: 0997 train_loss= 0.40777 train_acc= 0.93056 val_roc= 0.74724 val_ap= 0.81307 time= 0.42183\n",
            "Epoch: 0998 train_loss= 0.40777 train_acc= 0.93058 val_roc= 0.74720 val_ap= 0.81306 time= 0.43657\n",
            "Epoch: 0999 train_loss= 0.40777 train_acc= 0.93062 val_roc= 0.74722 val_ap= 0.81307 time= 0.44362\n",
            "Epoch: 1000 train_loss= 0.40777 train_acc= 0.93063 val_roc= 0.74718 val_ap= 0.81304 time= 0.45042\n",
            "Epoch: 1001 train_loss= 0.40777 train_acc= 0.93062 val_roc= 0.74714 val_ap= 0.81299 time= 0.41066\n",
            "Epoch: 1002 train_loss= 0.40777 train_acc= 0.93063 val_roc= 0.74711 val_ap= 0.81298 time= 0.41899\n",
            "Epoch: 1003 train_loss= 0.40776 train_acc= 0.93065 val_roc= 0.74710 val_ap= 0.81298 time= 0.40482\n",
            "Epoch: 1004 train_loss= 0.40776 train_acc= 0.93065 val_roc= 0.74706 val_ap= 0.81294 time= 0.41146\n",
            "Epoch: 1005 train_loss= 0.40776 train_acc= 0.93066 val_roc= 0.74702 val_ap= 0.81291 time= 0.42165\n",
            "Epoch: 1006 train_loss= 0.40776 train_acc= 0.93067 val_roc= 0.74698 val_ap= 0.81287 time= 0.41891\n",
            "Epoch: 1007 train_loss= 0.40776 train_acc= 0.93068 val_roc= 0.74689 val_ap= 0.81280 time= 0.44468\n",
            "Epoch: 1008 train_loss= 0.40776 train_acc= 0.93067 val_roc= 0.74686 val_ap= 0.81278 time= 0.40502\n",
            "Epoch: 1009 train_loss= 0.40776 train_acc= 0.93067 val_roc= 0.74687 val_ap= 0.81280 time= 0.41333\n",
            "Epoch: 1010 train_loss= 0.40776 train_acc= 0.93068 val_roc= 0.74681 val_ap= 0.81275 time= 0.42441\n",
            "Epoch: 1011 train_loss= 0.40776 train_acc= 0.93069 val_roc= 0.74678 val_ap= 0.81273 time= 0.40684\n",
            "Epoch: 1012 train_loss= 0.40776 train_acc= 0.93070 val_roc= 0.74672 val_ap= 0.81269 time= 0.45776\n",
            "Epoch: 1013 train_loss= 0.40776 train_acc= 0.93071 val_roc= 0.74668 val_ap= 0.81266 time= 0.41339\n",
            "Epoch: 1014 train_loss= 0.40776 train_acc= 0.93072 val_roc= 0.74662 val_ap= 0.81259 time= 0.41947\n",
            "Epoch: 1015 train_loss= 0.40776 train_acc= 0.93074 val_roc= 0.74656 val_ap= 0.81256 time= 0.41194\n",
            "Epoch: 1016 train_loss= 0.40776 train_acc= 0.93075 val_roc= 0.74656 val_ap= 0.81262 time= 0.40963\n",
            "Epoch: 1017 train_loss= 0.40776 train_acc= 0.93077 val_roc= 0.74652 val_ap= 0.81259 time= 0.40593\n",
            "Epoch: 1018 train_loss= 0.40776 train_acc= 0.93078 val_roc= 0.74648 val_ap= 0.81256 time= 0.41933\n",
            "Epoch: 1019 train_loss= 0.40776 train_acc= 0.93079 val_roc= 0.74641 val_ap= 0.81251 time= 0.42742\n",
            "Epoch: 1020 train_loss= 0.40776 train_acc= 0.93080 val_roc= 0.74638 val_ap= 0.81249 time= 0.43647\n",
            "Epoch: 1021 train_loss= 0.40776 train_acc= 0.93081 val_roc= 0.74636 val_ap= 0.81248 time= 0.44654\n",
            "Epoch: 1022 train_loss= 0.40776 train_acc= 0.93082 val_roc= 0.74631 val_ap= 0.81244 time= 0.41753\n",
            "Epoch: 1023 train_loss= 0.40776 train_acc= 0.93083 val_roc= 0.74627 val_ap= 0.81241 time= 0.44949\n",
            "Epoch: 1024 train_loss= 0.40776 train_acc= 0.93087 val_roc= 0.74620 val_ap= 0.81237 time= 0.44247\n",
            "Epoch: 1025 train_loss= 0.40776 train_acc= 0.93088 val_roc= 0.74617 val_ap= 0.81235 time= 0.43857\n",
            "Epoch: 1026 train_loss= 0.40775 train_acc= 0.93088 val_roc= 0.74618 val_ap= 0.81235 time= 0.44074\n",
            "Epoch: 1027 train_loss= 0.40775 train_acc= 0.93089 val_roc= 0.74617 val_ap= 0.81233 time= 0.40788\n",
            "Epoch: 1028 train_loss= 0.40775 train_acc= 0.93090 val_roc= 0.74613 val_ap= 0.81230 time= 0.42028\n",
            "Epoch: 1029 train_loss= 0.40775 train_acc= 0.93091 val_roc= 0.74606 val_ap= 0.81224 time= 0.41834\n",
            "Epoch: 1030 train_loss= 0.40775 train_acc= 0.93092 val_roc= 0.74600 val_ap= 0.81220 time= 0.46217\n",
            "Epoch: 1031 train_loss= 0.40775 train_acc= 0.93093 val_roc= 0.74599 val_ap= 0.81218 time= 0.42917\n",
            "Epoch: 1032 train_loss= 0.40775 train_acc= 0.93094 val_roc= 0.74593 val_ap= 0.81213 time= 0.40553\n",
            "Epoch: 1033 train_loss= 0.40775 train_acc= 0.93096 val_roc= 0.74590 val_ap= 0.81209 time= 0.41756\n",
            "Epoch: 1034 train_loss= 0.40775 train_acc= 0.93098 val_roc= 0.74589 val_ap= 0.81208 time= 0.41034\n",
            "Epoch: 1035 train_loss= 0.40774 train_acc= 0.93100 val_roc= 0.74583 val_ap= 0.81204 time= 0.40983\n",
            "Epoch: 1036 train_loss= 0.40774 train_acc= 0.93102 val_roc= 0.74576 val_ap= 0.81198 time= 0.42437\n",
            "Epoch: 1037 train_loss= 0.40774 train_acc= 0.93102 val_roc= 0.74572 val_ap= 0.81194 time= 0.43461\n",
            "Epoch: 1038 train_loss= 0.40774 train_acc= 0.93103 val_roc= 0.74565 val_ap= 0.81189 time= 0.43518\n",
            "Epoch: 1039 train_loss= 0.40774 train_acc= 0.93104 val_roc= 0.74561 val_ap= 0.81185 time= 0.44041\n",
            "Epoch: 1040 train_loss= 0.40774 train_acc= 0.93104 val_roc= 0.74560 val_ap= 0.81183 time= 0.44231\n",
            "Epoch: 1041 train_loss= 0.40774 train_acc= 0.93106 val_roc= 0.74556 val_ap= 0.81178 time= 0.40894\n",
            "Epoch: 1042 train_loss= 0.40774 train_acc= 0.93106 val_roc= 0.74552 val_ap= 0.81176 time= 0.41140\n",
            "Epoch: 1043 train_loss= 0.40774 train_acc= 0.93107 val_roc= 0.74546 val_ap= 0.81170 time= 0.40904\n",
            "Epoch: 1044 train_loss= 0.40774 train_acc= 0.93108 val_roc= 0.74544 val_ap= 0.81171 time= 0.40798\n",
            "Epoch: 1045 train_loss= 0.40774 train_acc= 0.93108 val_roc= 0.74543 val_ap= 0.81168 time= 0.41451\n",
            "Epoch: 1046 train_loss= 0.40774 train_acc= 0.93109 val_roc= 0.74533 val_ap= 0.81161 time= 0.43205\n",
            "Epoch: 1047 train_loss= 0.40774 train_acc= 0.93109 val_roc= 0.74525 val_ap= 0.81156 time= 0.43344\n",
            "Epoch: 1048 train_loss= 0.40774 train_acc= 0.93110 val_roc= 0.74520 val_ap= 0.81151 time= 0.42692\n",
            "Epoch: 1049 train_loss= 0.40774 train_acc= 0.93111 val_roc= 0.74510 val_ap= 0.81145 time= 0.40517\n",
            "Epoch: 1050 train_loss= 0.40774 train_acc= 0.93111 val_roc= 0.74505 val_ap= 0.81144 time= 0.42508\n",
            "Epoch: 1051 train_loss= 0.40774 train_acc= 0.93112 val_roc= 0.74498 val_ap= 0.81138 time= 0.40332\n",
            "Epoch: 1052 train_loss= 0.40774 train_acc= 0.93113 val_roc= 0.74489 val_ap= 0.81133 time= 0.40705\n",
            "Epoch: 1053 train_loss= 0.40774 train_acc= 0.93116 val_roc= 0.74483 val_ap= 0.81129 time= 0.41158\n",
            "Epoch: 1054 train_loss= 0.40774 train_acc= 0.93116 val_roc= 0.74478 val_ap= 0.81126 time= 0.41218\n",
            "Epoch: 1055 train_loss= 0.40774 train_acc= 0.93117 val_roc= 0.74475 val_ap= 0.81124 time= 0.42359\n",
            "Epoch: 1056 train_loss= 0.40774 train_acc= 0.93118 val_roc= 0.74475 val_ap= 0.81123 time= 0.44487\n",
            "Epoch: 1057 train_loss= 0.40774 train_acc= 0.93119 val_roc= 0.74471 val_ap= 0.81120 time= 0.44112\n",
            "Epoch: 1058 train_loss= 0.40774 train_acc= 0.93122 val_roc= 0.74465 val_ap= 0.81115 time= 0.43400\n",
            "Epoch: 1059 train_loss= 0.40774 train_acc= 0.93123 val_roc= 0.74459 val_ap= 0.81112 time= 0.44567\n",
            "Epoch: 1060 train_loss= 0.40774 train_acc= 0.93123 val_roc= 0.74449 val_ap= 0.81106 time= 0.42282\n",
            "Epoch: 1061 train_loss= 0.40774 train_acc= 0.93124 val_roc= 0.74444 val_ap= 0.81103 time= 0.44424\n",
            "Epoch: 1062 train_loss= 0.40774 train_acc= 0.93124 val_roc= 0.74440 val_ap= 0.81102 time= 0.42037\n",
            "Epoch: 1063 train_loss= 0.40774 train_acc= 0.93125 val_roc= 0.74436 val_ap= 0.81100 time= 0.41496\n",
            "Epoch: 1064 train_loss= 0.40773 train_acc= 0.93126 val_roc= 0.74430 val_ap= 0.81097 time= 0.44096\n",
            "Epoch: 1065 train_loss= 0.40773 train_acc= 0.93126 val_roc= 0.74424 val_ap= 0.81093 time= 0.43203\n",
            "Epoch: 1066 train_loss= 0.40773 train_acc= 0.93127 val_roc= 0.74410 val_ap= 0.81085 time= 0.43712\n",
            "Epoch: 1067 train_loss= 0.40773 train_acc= 0.93127 val_roc= 0.74406 val_ap= 0.81082 time= 0.41050\n",
            "Epoch: 1068 train_loss= 0.40773 train_acc= 0.93128 val_roc= 0.74397 val_ap= 0.81076 time= 0.40508\n",
            "Epoch: 1069 train_loss= 0.40773 train_acc= 0.93129 val_roc= 0.74391 val_ap= 0.81072 time= 0.42413\n",
            "Epoch: 1070 train_loss= 0.40773 train_acc= 0.93130 val_roc= 0.74385 val_ap= 0.81069 time= 0.43728\n",
            "Epoch: 1071 train_loss= 0.40773 train_acc= 0.93130 val_roc= 0.74386 val_ap= 0.81070 time= 0.44662\n",
            "Epoch: 1072 train_loss= 0.40773 train_acc= 0.93131 val_roc= 0.74378 val_ap= 0.81065 time= 0.43691\n",
            "Epoch: 1073 train_loss= 0.40773 train_acc= 0.93132 val_roc= 0.74374 val_ap= 0.81062 time= 0.43521\n",
            "Epoch: 1074 train_loss= 0.40773 train_acc= 0.93132 val_roc= 0.74371 val_ap= 0.81061 time= 0.42173\n",
            "Epoch: 1075 train_loss= 0.40773 train_acc= 0.93133 val_roc= 0.74363 val_ap= 0.81057 time= 0.42371\n",
            "Epoch: 1076 train_loss= 0.40773 train_acc= 0.93133 val_roc= 0.74360 val_ap= 0.81055 time= 0.43039\n",
            "Epoch: 1077 train_loss= 0.40773 train_acc= 0.93134 val_roc= 0.74357 val_ap= 0.81053 time= 0.43822\n",
            "Epoch: 1078 train_loss= 0.40773 train_acc= 0.93135 val_roc= 0.74351 val_ap= 0.81051 time= 0.43733\n",
            "Epoch: 1079 train_loss= 0.40773 train_acc= 0.93136 val_roc= 0.74342 val_ap= 0.81044 time= 0.43901\n",
            "Epoch: 1080 train_loss= 0.40773 train_acc= 0.93137 val_roc= 0.74339 val_ap= 0.81043 time= 0.46641\n",
            "Epoch: 1081 train_loss= 0.40773 train_acc= 0.93138 val_roc= 0.74332 val_ap= 0.81039 time= 0.44581\n",
            "Epoch: 1082 train_loss= 0.40773 train_acc= 0.93138 val_roc= 0.74326 val_ap= 0.81037 time= 0.43863\n",
            "Epoch: 1083 train_loss= 0.40773 train_acc= 0.93139 val_roc= 0.74323 val_ap= 0.81035 time= 0.41633\n",
            "Epoch: 1084 train_loss= 0.40773 train_acc= 0.93140 val_roc= 0.74317 val_ap= 0.81034 time= 0.40965\n",
            "Epoch: 1085 train_loss= 0.40773 train_acc= 0.93141 val_roc= 0.74312 val_ap= 0.81031 time= 0.41785\n",
            "Epoch: 1086 train_loss= 0.40773 train_acc= 0.93142 val_roc= 0.74305 val_ap= 0.81026 time= 0.41000\n",
            "Epoch: 1087 train_loss= 0.40773 train_acc= 0.93142 val_roc= 0.74300 val_ap= 0.81024 time= 0.41241\n",
            "Epoch: 1088 train_loss= 0.40773 train_acc= 0.93143 val_roc= 0.74295 val_ap= 0.81021 time= 0.40873\n",
            "Epoch: 1089 train_loss= 0.40773 train_acc= 0.93143 val_roc= 0.74291 val_ap= 0.81018 time= 0.41959\n",
            "Epoch: 1090 train_loss= 0.40773 train_acc= 0.93144 val_roc= 0.74288 val_ap= 0.81016 time= 0.41298\n",
            "Epoch: 1091 train_loss= 0.40773 train_acc= 0.93144 val_roc= 0.74282 val_ap= 0.81012 time= 0.42167\n",
            "Epoch: 1092 train_loss= 0.40773 train_acc= 0.93145 val_roc= 0.74280 val_ap= 0.81013 time= 0.41417\n",
            "Epoch: 1093 train_loss= 0.40773 train_acc= 0.93145 val_roc= 0.74275 val_ap= 0.81009 time= 0.41438\n",
            "Epoch: 1094 train_loss= 0.40773 train_acc= 0.93146 val_roc= 0.74272 val_ap= 0.81008 time= 0.41335\n",
            "Epoch: 1095 train_loss= 0.40773 train_acc= 0.93146 val_roc= 0.74269 val_ap= 0.81006 time= 0.41784\n",
            "Epoch: 1096 train_loss= 0.40772 train_acc= 0.93147 val_roc= 0.74263 val_ap= 0.81001 time= 0.40734\n",
            "Epoch: 1097 train_loss= 0.40772 train_acc= 0.93147 val_roc= 0.74260 val_ap= 0.81000 time= 0.41657\n",
            "Epoch: 1098 train_loss= 0.40772 train_acc= 0.93147 val_roc= 0.74254 val_ap= 0.80995 time= 0.41561\n",
            "Epoch: 1099 train_loss= 0.40772 train_acc= 0.93149 val_roc= 0.74247 val_ap= 0.80991 time= 0.41074\n",
            "Epoch: 1100 train_loss= 0.40772 train_acc= 0.93149 val_roc= 0.74240 val_ap= 0.80989 time= 0.41914\n",
            "Epoch: 1101 train_loss= 0.40772 train_acc= 0.93151 val_roc= 0.74232 val_ap= 0.80984 time= 0.41110\n",
            "Epoch: 1102 train_loss= 0.40772 train_acc= 0.93152 val_roc= 0.74226 val_ap= 0.80980 time= 0.41715\n",
            "Epoch: 1103 train_loss= 0.40772 train_acc= 0.93152 val_roc= 0.74222 val_ap= 0.80977 time= 0.40961\n",
            "Epoch: 1104 train_loss= 0.40772 train_acc= 0.93155 val_roc= 0.74219 val_ap= 0.80976 time= 0.40619\n",
            "Epoch: 1105 train_loss= 0.40772 train_acc= 0.93155 val_roc= 0.74217 val_ap= 0.80975 time= 0.41808\n",
            "Epoch: 1106 train_loss= 0.40772 train_acc= 0.93156 val_roc= 0.74206 val_ap= 0.80967 time= 0.41922\n",
            "Epoch: 1107 train_loss= 0.40772 train_acc= 0.93156 val_roc= 0.74197 val_ap= 0.80961 time= 0.42032\n",
            "Epoch: 1108 train_loss= 0.40772 train_acc= 0.93157 val_roc= 0.74191 val_ap= 0.80958 time= 0.40763\n",
            "Epoch: 1109 train_loss= 0.40772 train_acc= 0.93158 val_roc= 0.74185 val_ap= 0.80956 time= 0.41858\n",
            "Epoch: 1110 train_loss= 0.40772 train_acc= 0.93161 val_roc= 0.74178 val_ap= 0.80952 time= 0.40993\n",
            "Epoch: 1111 train_loss= 0.40772 train_acc= 0.93163 val_roc= 0.74175 val_ap= 0.80949 time= 0.40679\n",
            "Epoch: 1112 train_loss= 0.40772 train_acc= 0.93162 val_roc= 0.74168 val_ap= 0.80948 time= 0.42562\n",
            "Epoch: 1113 train_loss= 0.40772 train_acc= 0.93163 val_roc= 0.74163 val_ap= 0.80945 time= 0.43346\n",
            "Epoch: 1114 train_loss= 0.40772 train_acc= 0.93163 val_roc= 0.74162 val_ap= 0.80944 time= 0.41563\n",
            "Epoch: 1115 train_loss= 0.40772 train_acc= 0.93164 val_roc= 0.74158 val_ap= 0.80942 time= 0.43467\n",
            "Epoch: 1116 train_loss= 0.40772 train_acc= 0.93164 val_roc= 0.74158 val_ap= 0.80942 time= 0.42931\n",
            "Epoch: 1117 train_loss= 0.40772 train_acc= 0.93165 val_roc= 0.74159 val_ap= 0.80942 time= 0.42415\n",
            "Epoch: 1118 train_loss= 0.40772 train_acc= 0.93165 val_roc= 0.74159 val_ap= 0.80940 time= 0.40743\n",
            "Epoch: 1119 train_loss= 0.40772 train_acc= 0.93166 val_roc= 0.74159 val_ap= 0.80944 time= 0.42701\n",
            "Epoch: 1120 train_loss= 0.40772 train_acc= 0.93166 val_roc= 0.74155 val_ap= 0.80940 time= 0.43760\n",
            "Epoch: 1121 train_loss= 0.40772 train_acc= 0.93167 val_roc= 0.74153 val_ap= 0.80939 time= 0.42799\n",
            "Epoch: 1122 train_loss= 0.40771 train_acc= 0.93172 val_roc= 0.74145 val_ap= 0.80935 time= 0.44014\n",
            "Epoch: 1123 train_loss= 0.40771 train_acc= 0.93172 val_roc= 0.74141 val_ap= 0.80934 time= 0.42210\n",
            "Epoch: 1124 train_loss= 0.40771 train_acc= 0.93175 val_roc= 0.74142 val_ap= 0.80934 time= 0.41395\n",
            "Epoch: 1125 train_loss= 0.40771 train_acc= 0.93176 val_roc= 0.74143 val_ap= 0.80935 time= 0.41184\n",
            "Epoch: 1126 train_loss= 0.40771 train_acc= 0.93177 val_roc= 0.74140 val_ap= 0.80932 time= 0.41961\n",
            "Epoch: 1127 train_loss= 0.40771 train_acc= 0.93177 val_roc= 0.74137 val_ap= 0.80931 time= 0.40408\n",
            "Epoch: 1128 train_loss= 0.40771 train_acc= 0.93180 val_roc= 0.74135 val_ap= 0.80930 time= 0.40868\n",
            "Epoch: 1129 train_loss= 0.40771 train_acc= 0.93185 val_roc= 0.74132 val_ap= 0.80929 time= 0.43353\n",
            "Epoch: 1130 train_loss= 0.40771 train_acc= 0.93185 val_roc= 0.74129 val_ap= 0.80928 time= 0.43674\n",
            "Epoch: 1131 train_loss= 0.40771 train_acc= 0.93185 val_roc= 0.74126 val_ap= 0.80926 time= 0.41524\n",
            "Epoch: 1132 train_loss= 0.40771 train_acc= 0.93186 val_roc= 0.74126 val_ap= 0.80926 time= 0.41381\n",
            "Epoch: 1133 train_loss= 0.40771 train_acc= 0.93186 val_roc= 0.74121 val_ap= 0.80923 time= 0.41540\n",
            "Epoch: 1134 train_loss= 0.40771 train_acc= 0.93187 val_roc= 0.74122 val_ap= 0.80924 time= 0.41536\n",
            "Epoch: 1135 train_loss= 0.40771 train_acc= 0.93187 val_roc= 0.74117 val_ap= 0.80920 time= 0.40700\n",
            "Epoch: 1136 train_loss= 0.40771 train_acc= 0.93188 val_roc= 0.74117 val_ap= 0.80921 time= 0.42165\n",
            "Epoch: 1137 train_loss= 0.40771 train_acc= 0.93189 val_roc= 0.74120 val_ap= 0.80921 time= 0.40841\n",
            "Epoch: 1138 train_loss= 0.40771 train_acc= 0.93194 val_roc= 0.74122 val_ap= 0.80922 time= 0.43093\n",
            "Epoch: 1139 train_loss= 0.40771 train_acc= 0.93197 val_roc= 0.74120 val_ap= 0.80920 time= 0.43888\n",
            "Epoch: 1140 train_loss= 0.40771 train_acc= 0.93198 val_roc= 0.74120 val_ap= 0.80921 time= 0.40426\n",
            "Epoch: 1141 train_loss= 0.40771 train_acc= 0.93201 val_roc= 0.74121 val_ap= 0.80923 time= 0.41699\n",
            "Epoch: 1142 train_loss= 0.40771 train_acc= 0.93206 val_roc= 0.74120 val_ap= 0.80923 time= 0.40658\n",
            "Epoch: 1143 train_loss= 0.40771 train_acc= 0.93208 val_roc= 0.74118 val_ap= 0.80920 time= 0.43195\n",
            "Epoch: 1144 train_loss= 0.40771 train_acc= 0.93209 val_roc= 0.74117 val_ap= 0.80919 time= 0.40707\n",
            "Epoch: 1145 train_loss= 0.40771 train_acc= 0.93210 val_roc= 0.74117 val_ap= 0.80920 time= 0.42341\n",
            "Epoch: 1146 train_loss= 0.40771 train_acc= 0.93210 val_roc= 0.74113 val_ap= 0.80918 time= 0.43404\n",
            "Epoch: 1147 train_loss= 0.40771 train_acc= 0.93211 val_roc= 0.74111 val_ap= 0.80916 time= 0.41167\n",
            "Epoch: 1148 train_loss= 0.40770 train_acc= 0.93215 val_roc= 0.74108 val_ap= 0.80915 time= 0.41510\n",
            "Epoch: 1149 train_loss= 0.40770 train_acc= 0.93216 val_roc= 0.74107 val_ap= 0.80914 time= 0.41234\n",
            "Epoch: 1150 train_loss= 0.40770 train_acc= 0.93216 val_roc= 0.74107 val_ap= 0.80914 time= 0.42520\n",
            "Epoch: 1151 train_loss= 0.40770 train_acc= 0.93216 val_roc= 0.74107 val_ap= 0.80916 time= 0.45158\n",
            "Epoch: 1152 train_loss= 0.40770 train_acc= 0.93217 val_roc= 0.74104 val_ap= 0.80917 time= 0.41498\n",
            "Epoch: 1153 train_loss= 0.40770 train_acc= 0.93217 val_roc= 0.74100 val_ap= 0.80913 time= 0.42646\n",
            "Epoch: 1154 train_loss= 0.40770 train_acc= 0.93218 val_roc= 0.74098 val_ap= 0.80913 time= 0.41279\n",
            "Epoch: 1155 train_loss= 0.40770 train_acc= 0.93220 val_roc= 0.74096 val_ap= 0.80912 time= 0.41999\n",
            "Epoch: 1156 train_loss= 0.40770 train_acc= 0.93221 val_roc= 0.74097 val_ap= 0.80910 time= 0.41118\n",
            "Epoch: 1157 train_loss= 0.40770 train_acc= 0.93221 val_roc= 0.74098 val_ap= 0.80911 time= 0.44015\n",
            "Epoch: 1158 train_loss= 0.40770 train_acc= 0.93219 val_roc= 0.74097 val_ap= 0.80910 time= 0.41508\n",
            "Epoch: 1159 train_loss= 0.40770 train_acc= 0.93222 val_roc= 0.74098 val_ap= 0.80908 time= 0.40773\n",
            "Epoch: 1160 train_loss= 0.40770 train_acc= 0.93225 val_roc= 0.74100 val_ap= 0.80909 time= 0.41388\n",
            "Epoch: 1161 train_loss= 0.40770 train_acc= 0.93225 val_roc= 0.74099 val_ap= 0.80908 time= 0.40672\n",
            "Epoch: 1162 train_loss= 0.40770 train_acc= 0.93226 val_roc= 0.74095 val_ap= 0.80904 time= 0.41336\n",
            "Epoch: 1163 train_loss= 0.40770 train_acc= 0.93227 val_roc= 0.74095 val_ap= 0.80904 time= 0.40264\n",
            "Epoch: 1164 train_loss= 0.40770 train_acc= 0.93232 val_roc= 0.74093 val_ap= 0.80904 time= 0.41903\n",
            "Epoch: 1165 train_loss= 0.40770 train_acc= 0.93232 val_roc= 0.74088 val_ap= 0.80900 time= 0.41618\n",
            "Epoch: 1166 train_loss= 0.40770 train_acc= 0.93233 val_roc= 0.74085 val_ap= 0.80898 time= 0.41271\n",
            "Epoch: 1167 train_loss= 0.40770 train_acc= 0.93234 val_roc= 0.74084 val_ap= 0.80898 time= 0.44060\n",
            "Epoch: 1168 train_loss= 0.40770 train_acc= 0.93234 val_roc= 0.74082 val_ap= 0.80896 time= 0.40677\n",
            "Epoch: 1169 train_loss= 0.40770 train_acc= 0.93234 val_roc= 0.74078 val_ap= 0.80894 time= 0.42385\n",
            "Epoch: 1170 train_loss= 0.40770 train_acc= 0.93234 val_roc= 0.74078 val_ap= 0.80894 time= 0.44951\n",
            "Epoch: 1171 train_loss= 0.40770 train_acc= 0.93237 val_roc= 0.74074 val_ap= 0.80891 time= 0.43085\n",
            "Epoch: 1172 train_loss= 0.40770 train_acc= 0.93237 val_roc= 0.74069 val_ap= 0.80889 time= 0.44252\n",
            "Epoch: 1173 train_loss= 0.40769 train_acc= 0.93236 val_roc= 0.74066 val_ap= 0.80887 time= 0.41996\n",
            "Epoch: 1174 train_loss= 0.40769 train_acc= 0.93236 val_roc= 0.74066 val_ap= 0.80885 time= 0.44516\n",
            "Epoch: 1175 train_loss= 0.40769 train_acc= 0.93236 val_roc= 0.74066 val_ap= 0.80885 time= 0.40634\n",
            "Epoch: 1176 train_loss= 0.40769 train_acc= 0.93237 val_roc= 0.74064 val_ap= 0.80884 time= 0.41228\n",
            "Epoch: 1177 train_loss= 0.40769 train_acc= 0.93239 val_roc= 0.74062 val_ap= 0.80883 time= 0.41429\n",
            "Epoch: 1178 train_loss= 0.40769 train_acc= 0.93240 val_roc= 0.74059 val_ap= 0.80880 time= 0.41056\n",
            "Epoch: 1179 train_loss= 0.40769 train_acc= 0.93241 val_roc= 0.74056 val_ap= 0.80877 time= 0.44079\n",
            "Epoch: 1180 train_loss= 0.40769 train_acc= 0.93241 val_roc= 0.74055 val_ap= 0.80877 time= 0.42820\n",
            "Epoch: 1181 train_loss= 0.40769 train_acc= 0.93241 val_roc= 0.74053 val_ap= 0.80878 time= 0.40561\n",
            "Epoch: 1182 train_loss= 0.40769 train_acc= 0.93244 val_roc= 0.74050 val_ap= 0.80876 time= 0.41897\n",
            "Epoch: 1183 train_loss= 0.40769 train_acc= 0.93245 val_roc= 0.74050 val_ap= 0.80877 time= 0.40967\n",
            "Epoch: 1184 train_loss= 0.40769 train_acc= 0.93243 val_roc= 0.74045 val_ap= 0.80871 time= 0.41854\n",
            "Epoch: 1185 train_loss= 0.40769 train_acc= 0.93244 val_roc= 0.74045 val_ap= 0.80875 time= 0.41205\n",
            "Epoch: 1186 train_loss= 0.40769 train_acc= 0.93244 val_roc= 0.74045 val_ap= 0.80875 time= 0.42229\n",
            "Epoch: 1187 train_loss= 0.40769 train_acc= 0.93244 val_roc= 0.74042 val_ap= 0.80872 time= 0.40726\n",
            "Epoch: 1188 train_loss= 0.40769 train_acc= 0.93245 val_roc= 0.74037 val_ap= 0.80869 time= 0.42025\n",
            "Epoch: 1189 train_loss= 0.40769 train_acc= 0.93245 val_roc= 0.74031 val_ap= 0.80866 time= 0.44378\n",
            "Epoch: 1190 train_loss= 0.40769 train_acc= 0.93246 val_roc= 0.74031 val_ap= 0.80867 time= 0.41170\n",
            "Epoch: 1191 train_loss= 0.40769 train_acc= 0.93246 val_roc= 0.74027 val_ap= 0.80866 time= 0.40759\n",
            "Epoch: 1192 train_loss= 0.40769 train_acc= 0.93246 val_roc= 0.74021 val_ap= 0.80864 time= 0.41068\n",
            "Epoch: 1193 train_loss= 0.40769 train_acc= 0.93248 val_roc= 0.74016 val_ap= 0.80859 time= 0.40466\n",
            "Epoch: 1194 train_loss= 0.40769 train_acc= 0.93249 val_roc= 0.74011 val_ap= 0.80857 time= 0.41895\n",
            "Epoch: 1195 train_loss= 0.40769 train_acc= 0.93249 val_roc= 0.74007 val_ap= 0.80856 time= 0.41939\n",
            "Epoch: 1196 train_loss= 0.40769 train_acc= 0.93249 val_roc= 0.74007 val_ap= 0.80857 time= 0.44203\n",
            "Epoch: 1197 train_loss= 0.40769 train_acc= 0.93250 val_roc= 0.74007 val_ap= 0.80858 time= 0.40992\n",
            "Epoch: 1198 train_loss= 0.40769 train_acc= 0.93250 val_roc= 0.74003 val_ap= 0.80856 time= 0.40872\n",
            "Epoch: 1199 train_loss= 0.40769 train_acc= 0.93251 val_roc= 0.73998 val_ap= 0.80852 time= 0.41443\n",
            "Epoch: 1200 train_loss= 0.40769 train_acc= 0.93251 val_roc= 0.73995 val_ap= 0.80851 time= 0.40626\n",
            "Epoch: 1201 train_loss= 0.40769 train_acc= 0.93252 val_roc= 0.73993 val_ap= 0.80850 time= 0.41694\n",
            "Epoch: 1202 train_loss= 0.40769 train_acc= 0.93252 val_roc= 0.73996 val_ap= 0.80851 time= 0.41227\n",
            "Epoch: 1203 train_loss= 0.40769 train_acc= 0.93253 val_roc= 0.73990 val_ap= 0.80848 time= 0.41569\n",
            "Epoch: 1204 train_loss= 0.40769 train_acc= 0.93253 val_roc= 0.73991 val_ap= 0.80849 time= 0.40527\n",
            "Epoch: 1205 train_loss= 0.40769 train_acc= 0.93253 val_roc= 0.73989 val_ap= 0.80841 time= 0.40919\n",
            "Epoch: 1206 train_loss= 0.40769 train_acc= 0.93254 val_roc= 0.73986 val_ap= 0.80841 time= 0.41729\n",
            "Epoch: 1207 train_loss= 0.40769 train_acc= 0.93254 val_roc= 0.73983 val_ap= 0.80840 time= 0.40393\n",
            "Epoch: 1208 train_loss= 0.40769 train_acc= 0.93254 val_roc= 0.73981 val_ap= 0.80838 time= 0.41765\n",
            "Epoch: 1209 train_loss= 0.40769 train_acc= 0.93255 val_roc= 0.73976 val_ap= 0.80834 time= 0.41001\n",
            "Epoch: 1210 train_loss= 0.40769 train_acc= 0.93255 val_roc= 0.73970 val_ap= 0.80827 time= 0.41075\n",
            "Epoch: 1211 train_loss= 0.40768 train_acc= 0.93255 val_roc= 0.73970 val_ap= 0.80827 time= 0.41516\n",
            "Epoch: 1212 train_loss= 0.40768 train_acc= 0.93258 val_roc= 0.73971 val_ap= 0.80827 time= 0.41883\n",
            "Epoch: 1213 train_loss= 0.40768 train_acc= 0.93258 val_roc= 0.73966 val_ap= 0.80825 time= 0.44520\n",
            "Epoch: 1214 train_loss= 0.40768 train_acc= 0.93258 val_roc= 0.73963 val_ap= 0.80821 time= 0.41102\n",
            "Epoch: 1215 train_loss= 0.40768 train_acc= 0.93259 val_roc= 0.73961 val_ap= 0.80822 time= 0.44079\n",
            "Epoch: 1216 train_loss= 0.40768 train_acc= 0.93259 val_roc= 0.73957 val_ap= 0.80820 time= 0.44112\n",
            "Epoch: 1217 train_loss= 0.40768 train_acc= 0.93259 val_roc= 0.73953 val_ap= 0.80820 time= 0.41090\n",
            "Epoch: 1218 train_loss= 0.40768 train_acc= 0.93260 val_roc= 0.73947 val_ap= 0.80815 time= 0.43150\n",
            "Epoch: 1219 train_loss= 0.40768 train_acc= 0.93260 val_roc= 0.73946 val_ap= 0.80815 time= 0.40668\n",
            "Epoch: 1220 train_loss= 0.40768 train_acc= 0.93260 val_roc= 0.73938 val_ap= 0.80810 time= 0.41073\n",
            "Epoch: 1221 train_loss= 0.40768 train_acc= 0.93261 val_roc= 0.73936 val_ap= 0.80809 time= 0.41401\n",
            "Epoch: 1222 train_loss= 0.40768 train_acc= 0.93261 val_roc= 0.73931 val_ap= 0.80807 time= 0.43945\n",
            "Epoch: 1223 train_loss= 0.40768 train_acc= 0.93261 val_roc= 0.73928 val_ap= 0.80806 time= 0.43155\n",
            "Epoch: 1224 train_loss= 0.40768 train_acc= 0.93262 val_roc= 0.73924 val_ap= 0.80805 time= 0.42047\n",
            "Epoch: 1225 train_loss= 0.40768 train_acc= 0.93262 val_roc= 0.73919 val_ap= 0.80802 time= 0.41416\n",
            "Epoch: 1226 train_loss= 0.40768 train_acc= 0.93263 val_roc= 0.73912 val_ap= 0.80798 time= 0.43209\n",
            "Epoch: 1227 train_loss= 0.40768 train_acc= 0.93263 val_roc= 0.73910 val_ap= 0.80797 time= 0.44688\n",
            "Epoch: 1228 train_loss= 0.40768 train_acc= 0.93264 val_roc= 0.73907 val_ap= 0.80796 time= 0.43825\n",
            "Epoch: 1229 train_loss= 0.40768 train_acc= 0.93264 val_roc= 0.73907 val_ap= 0.80797 time= 0.43588\n",
            "Epoch: 1230 train_loss= 0.40768 train_acc= 0.93264 val_roc= 0.73903 val_ap= 0.80796 time= 0.43960\n",
            "Epoch: 1231 train_loss= 0.40768 train_acc= 0.93265 val_roc= 0.73902 val_ap= 0.80795 time= 0.40494\n",
            "Epoch: 1232 train_loss= 0.40768 train_acc= 0.93265 val_roc= 0.73897 val_ap= 0.80792 time= 0.42105\n",
            "Epoch: 1233 train_loss= 0.40768 train_acc= 0.93265 val_roc= 0.73896 val_ap= 0.80792 time= 0.40933\n",
            "Epoch: 1234 train_loss= 0.40768 train_acc= 0.93266 val_roc= 0.73893 val_ap= 0.80789 time= 0.41375\n",
            "Epoch: 1235 train_loss= 0.40768 train_acc= 0.93266 val_roc= 0.73890 val_ap= 0.80787 time= 0.41441\n",
            "Epoch: 1236 train_loss= 0.40768 train_acc= 0.93266 val_roc= 0.73886 val_ap= 0.80789 time= 0.40636\n",
            "Epoch: 1237 train_loss= 0.40767 train_acc= 0.93267 val_roc= 0.73883 val_ap= 0.80788 time= 0.41032\n",
            "Epoch: 1238 train_loss= 0.40767 train_acc= 0.93267 val_roc= 0.73879 val_ap= 0.80786 time= 0.40795\n",
            "Epoch: 1239 train_loss= 0.40767 train_acc= 0.93267 val_roc= 0.73876 val_ap= 0.80784 time= 0.40674\n",
            "Epoch: 1240 train_loss= 0.40767 train_acc= 0.93268 val_roc= 0.73874 val_ap= 0.80784 time= 0.41456\n",
            "Epoch: 1241 train_loss= 0.40767 train_acc= 0.93268 val_roc= 0.73871 val_ap= 0.80783 time= 0.40619\n",
            "Epoch: 1242 train_loss= 0.40767 train_acc= 0.93269 val_roc= 0.73868 val_ap= 0.80781 time= 0.41568\n",
            "Epoch: 1243 train_loss= 0.40767 train_acc= 0.93271 val_roc= 0.73865 val_ap= 0.80779 time= 0.45812\n",
            "Epoch: 1244 train_loss= 0.40767 train_acc= 0.93272 val_roc= 0.73863 val_ap= 0.80779 time= 0.44150\n",
            "Epoch: 1245 train_loss= 0.40767 train_acc= 0.93269 val_roc= 0.73859 val_ap= 0.80777 time= 0.41044\n",
            "Epoch: 1246 train_loss= 0.40767 train_acc= 0.93272 val_roc= 0.73857 val_ap= 0.80777 time= 0.43536\n",
            "Epoch: 1247 train_loss= 0.40767 train_acc= 0.93272 val_roc= 0.73855 val_ap= 0.80776 time= 0.42280\n",
            "Epoch: 1248 train_loss= 0.40767 train_acc= 0.93273 val_roc= 0.73855 val_ap= 0.80776 time= 0.41178\n",
            "Epoch: 1249 train_loss= 0.40767 train_acc= 0.93274 val_roc= 0.73855 val_ap= 0.80775 time= 0.41463\n",
            "Epoch: 1250 train_loss= 0.40767 train_acc= 0.93275 val_roc= 0.73856 val_ap= 0.80774 time= 0.43768\n",
            "Epoch: 1251 train_loss= 0.40767 train_acc= 0.93276 val_roc= 0.73856 val_ap= 0.80775 time= 0.43455\n",
            "Epoch: 1252 train_loss= 0.40767 train_acc= 0.93279 val_roc= 0.73858 val_ap= 0.80776 time= 0.41102\n",
            "Epoch: 1253 train_loss= 0.40767 train_acc= 0.93281 val_roc= 0.73861 val_ap= 0.80778 time= 0.40659\n",
            "Epoch: 1254 train_loss= 0.40767 train_acc= 0.93279 val_roc= 0.73864 val_ap= 0.80779 time= 0.42111\n",
            "Epoch: 1255 train_loss= 0.40767 train_acc= 0.93279 val_roc= 0.73867 val_ap= 0.80780 time= 0.40909\n",
            "Epoch: 1256 train_loss= 0.40767 train_acc= 0.93280 val_roc= 0.73866 val_ap= 0.80780 time= 0.41239\n",
            "Epoch: 1257 train_loss= 0.40767 train_acc= 0.93280 val_roc= 0.73867 val_ap= 0.80782 time= 0.40860\n",
            "Epoch: 1258 train_loss= 0.40767 train_acc= 0.93280 val_roc= 0.73867 val_ap= 0.80783 time= 0.43622\n",
            "Epoch: 1259 train_loss= 0.40767 train_acc= 0.93280 val_roc= 0.73870 val_ap= 0.80783 time= 0.44584\n",
            "Epoch: 1260 train_loss= 0.40767 train_acc= 0.93280 val_roc= 0.73866 val_ap= 0.80780 time= 0.43697\n",
            "Epoch: 1261 train_loss= 0.40767 train_acc= 0.93282 val_roc= 0.73866 val_ap= 0.80780 time= 0.44392\n",
            "Epoch: 1262 train_loss= 0.40767 train_acc= 0.93283 val_roc= 0.73865 val_ap= 0.80780 time= 0.43823\n",
            "Epoch: 1263 train_loss= 0.40767 train_acc= 0.93283 val_roc= 0.73868 val_ap= 0.80781 time= 0.44001\n",
            "Epoch: 1264 train_loss= 0.40767 train_acc= 0.93281 val_roc= 0.73867 val_ap= 0.80780 time= 0.43557\n",
            "Epoch: 1265 train_loss= 0.40767 train_acc= 0.93282 val_roc= 0.73865 val_ap= 0.80778 time= 0.43337\n",
            "Epoch: 1266 train_loss= 0.40767 train_acc= 0.93282 val_roc= 0.73868 val_ap= 0.80779 time= 0.42765\n",
            "Epoch: 1267 train_loss= 0.40767 train_acc= 0.93282 val_roc= 0.73868 val_ap= 0.80780 time= 0.44167\n",
            "Epoch: 1268 train_loss= 0.40767 train_acc= 0.93282 val_roc= 0.73865 val_ap= 0.80777 time= 0.45080\n",
            "Epoch: 1269 train_loss= 0.40767 train_acc= 0.93282 val_roc= 0.73864 val_ap= 0.80776 time= 0.43817\n",
            "Epoch: 1270 train_loss= 0.40767 train_acc= 0.93282 val_roc= 0.73861 val_ap= 0.80774 time= 0.42373\n",
            "Epoch: 1271 train_loss= 0.40766 train_acc= 0.93282 val_roc= 0.73857 val_ap= 0.80772 time= 0.40804\n",
            "Epoch: 1272 train_loss= 0.40766 train_acc= 0.93283 val_roc= 0.73853 val_ap= 0.80769 time= 0.40598\n",
            "Epoch: 1273 train_loss= 0.40766 train_acc= 0.93283 val_roc= 0.73848 val_ap= 0.80766 time= 0.41829\n",
            "Epoch: 1274 train_loss= 0.40766 train_acc= 0.93283 val_roc= 0.73850 val_ap= 0.80768 time= 0.40922\n",
            "Epoch: 1275 train_loss= 0.40766 train_acc= 0.93284 val_roc= 0.73844 val_ap= 0.80763 time= 0.41318\n",
            "Epoch: 1276 train_loss= 0.40766 train_acc= 0.93284 val_roc= 0.73843 val_ap= 0.80762 time= 0.41138\n",
            "Epoch: 1277 train_loss= 0.40766 train_acc= 0.93284 val_roc= 0.73842 val_ap= 0.80762 time= 0.40895\n",
            "Epoch: 1278 train_loss= 0.40766 train_acc= 0.93285 val_roc= 0.73840 val_ap= 0.80761 time= 0.44426\n",
            "Epoch: 1279 train_loss= 0.40766 train_acc= 0.93285 val_roc= 0.73840 val_ap= 0.80761 time= 0.43675\n",
            "Epoch: 1280 train_loss= 0.40766 train_acc= 0.93286 val_roc= 0.73835 val_ap= 0.80756 time= 0.43833\n",
            "Epoch: 1281 train_loss= 0.40766 train_acc= 0.93286 val_roc= 0.73833 val_ap= 0.80755 time= 0.41387\n",
            "Epoch: 1282 train_loss= 0.40766 train_acc= 0.93287 val_roc= 0.73834 val_ap= 0.80755 time= 0.41339\n",
            "Epoch: 1283 train_loss= 0.40766 train_acc= 0.93289 val_roc= 0.73834 val_ap= 0.80754 time= 0.44002\n",
            "Epoch: 1284 train_loss= 0.40766 train_acc= 0.93289 val_roc= 0.73833 val_ap= 0.80751 time= 0.43080\n",
            "Epoch: 1285 train_loss= 0.40766 train_acc= 0.93290 val_roc= 0.73831 val_ap= 0.80748 time= 0.41742\n",
            "Epoch: 1286 train_loss= 0.40766 train_acc= 0.93290 val_roc= 0.73828 val_ap= 0.80744 time= 0.40854\n",
            "Epoch: 1287 train_loss= 0.40766 train_acc= 0.93291 val_roc= 0.73826 val_ap= 0.80743 time= 0.41711\n",
            "Epoch: 1288 train_loss= 0.40766 train_acc= 0.93291 val_roc= 0.73824 val_ap= 0.80741 time= 0.41354\n",
            "Epoch: 1289 train_loss= 0.40766 train_acc= 0.93291 val_roc= 0.73822 val_ap= 0.80740 time= 0.41875\n",
            "Epoch: 1290 train_loss= 0.40766 train_acc= 0.93292 val_roc= 0.73823 val_ap= 0.80741 time= 0.44373\n",
            "Epoch: 1291 train_loss= 0.40766 train_acc= 0.93292 val_roc= 0.73822 val_ap= 0.80740 time= 0.44737\n",
            "Epoch: 1292 train_loss= 0.40766 train_acc= 0.93292 val_roc= 0.73820 val_ap= 0.80739 time= 0.41643\n",
            "Epoch: 1293 train_loss= 0.40766 train_acc= 0.93292 val_roc= 0.73818 val_ap= 0.80737 time= 0.40476\n",
            "Epoch: 1294 train_loss= 0.40766 train_acc= 0.93293 val_roc= 0.73813 val_ap= 0.80733 time= 0.41245\n",
            "Epoch: 1295 train_loss= 0.40766 train_acc= 0.93293 val_roc= 0.73809 val_ap= 0.80731 time= 0.42386\n",
            "Epoch: 1296 train_loss= 0.40766 train_acc= 0.93294 val_roc= 0.73808 val_ap= 0.80729 time= 0.43359\n",
            "Epoch: 1297 train_loss= 0.40766 train_acc= 0.93294 val_roc= 0.73807 val_ap= 0.80728 time= 0.41625\n",
            "Epoch: 1298 train_loss= 0.40766 train_acc= 0.93294 val_roc= 0.73802 val_ap= 0.80725 time= 0.40837\n",
            "Epoch: 1299 train_loss= 0.40766 train_acc= 0.93295 val_roc= 0.73794 val_ap= 0.80720 time= 0.42265\n",
            "Epoch: 1300 train_loss= 0.40766 train_acc= 0.93295 val_roc= 0.73789 val_ap= 0.80717 time= 0.40544\n",
            "Epoch: 1301 train_loss= 0.40766 train_acc= 0.93296 val_roc= 0.73789 val_ap= 0.80717 time= 0.40989\n",
            "Epoch: 1302 train_loss= 0.40766 train_acc= 0.93296 val_roc= 0.73784 val_ap= 0.80711 time= 0.42217\n",
            "Epoch: 1303 train_loss= 0.40765 train_acc= 0.93296 val_roc= 0.73783 val_ap= 0.80710 time= 0.42118\n",
            "Epoch: 1304 train_loss= 0.40765 train_acc= 0.93297 val_roc= 0.73779 val_ap= 0.80708 time= 0.44375\n",
            "Epoch: 1305 train_loss= 0.40765 train_acc= 0.93297 val_roc= 0.73777 val_ap= 0.80707 time= 0.43188\n",
            "Epoch: 1306 train_loss= 0.40765 train_acc= 0.93298 val_roc= 0.73773 val_ap= 0.80705 time= 0.42237\n",
            "Epoch: 1307 train_loss= 0.40765 train_acc= 0.93298 val_roc= 0.73766 val_ap= 0.80700 time= 0.40776\n",
            "Epoch: 1308 train_loss= 0.40765 train_acc= 0.93298 val_roc= 0.73763 val_ap= 0.80698 time= 0.40562\n",
            "Epoch: 1309 train_loss= 0.40765 train_acc= 0.93299 val_roc= 0.73759 val_ap= 0.80695 time= 0.42463\n",
            "Epoch: 1310 train_loss= 0.40765 train_acc= 0.93299 val_roc= 0.73758 val_ap= 0.80695 time= 0.41443\n",
            "Epoch: 1311 train_loss= 0.40765 train_acc= 0.93300 val_roc= 0.73758 val_ap= 0.80695 time= 0.41218\n",
            "Epoch: 1312 train_loss= 0.40765 train_acc= 0.93300 val_roc= 0.73760 val_ap= 0.80696 time= 0.40067\n",
            "Epoch: 1313 train_loss= 0.40765 train_acc= 0.93300 val_roc= 0.73759 val_ap= 0.80696 time= 0.41394\n",
            "Epoch: 1314 train_loss= 0.40765 train_acc= 0.93301 val_roc= 0.73757 val_ap= 0.80694 time= 0.43177\n",
            "Epoch: 1315 train_loss= 0.40765 train_acc= 0.93301 val_roc= 0.73754 val_ap= 0.80692 time= 0.41175\n",
            "Epoch: 1316 train_loss= 0.40765 train_acc= 0.93302 val_roc= 0.73751 val_ap= 0.80690 time= 0.42211\n",
            "Epoch: 1317 train_loss= 0.40765 train_acc= 0.93302 val_roc= 0.73750 val_ap= 0.80689 time= 0.43404\n",
            "Epoch: 1318 train_loss= 0.40765 train_acc= 0.93303 val_roc= 0.73744 val_ap= 0.80687 time= 0.40930\n",
            "Epoch: 1319 train_loss= 0.40765 train_acc= 0.93303 val_roc= 0.73742 val_ap= 0.80687 time= 0.42382\n",
            "Epoch: 1320 train_loss= 0.40765 train_acc= 0.93304 val_roc= 0.73740 val_ap= 0.80685 time= 0.41402\n",
            "Epoch: 1321 train_loss= 0.40765 train_acc= 0.93306 val_roc= 0.73742 val_ap= 0.80686 time= 0.41572\n",
            "Epoch: 1322 train_loss= 0.40765 train_acc= 0.93307 val_roc= 0.73739 val_ap= 0.80684 time= 0.40492\n",
            "Epoch: 1323 train_loss= 0.40765 train_acc= 0.93307 val_roc= 0.73737 val_ap= 0.80682 time= 0.41842\n",
            "Epoch: 1324 train_loss= 0.40765 train_acc= 0.93309 val_roc= 0.73732 val_ap= 0.80680 time= 0.40755\n",
            "Epoch: 1325 train_loss= 0.40765 train_acc= 0.93310 val_roc= 0.73731 val_ap= 0.80681 time= 0.41941\n",
            "Epoch: 1326 train_loss= 0.40765 train_acc= 0.93310 val_roc= 0.73725 val_ap= 0.80679 time= 0.44615\n",
            "Epoch: 1327 train_loss= 0.40765 train_acc= 0.93310 val_roc= 0.73722 val_ap= 0.80676 time= 0.43318\n",
            "Epoch: 1328 train_loss= 0.40765 train_acc= 0.93311 val_roc= 0.73719 val_ap= 0.80674 time= 0.41779\n",
            "Epoch: 1329 train_loss= 0.40765 train_acc= 0.93311 val_roc= 0.73716 val_ap= 0.80675 time= 0.41163\n",
            "Epoch: 1330 train_loss= 0.40765 train_acc= 0.93311 val_roc= 0.73716 val_ap= 0.80675 time= 0.40712\n",
            "Epoch: 1331 train_loss= 0.40765 train_acc= 0.93311 val_roc= 0.73712 val_ap= 0.80672 time= 0.42624\n",
            "Epoch: 1332 train_loss= 0.40765 train_acc= 0.93312 val_roc= 0.73707 val_ap= 0.80671 time= 0.40492\n",
            "Epoch: 1333 train_loss= 0.40765 train_acc= 0.93312 val_roc= 0.73706 val_ap= 0.80671 time= 0.42068\n",
            "Epoch: 1334 train_loss= 0.40765 train_acc= 0.93312 val_roc= 0.73705 val_ap= 0.80671 time= 0.40553\n",
            "Epoch: 1335 train_loss= 0.40765 train_acc= 0.93312 val_roc= 0.73702 val_ap= 0.80671 time= 0.41310\n",
            "Epoch: 1336 train_loss= 0.40765 train_acc= 0.93312 val_roc= 0.73700 val_ap= 0.80669 time= 0.40341\n",
            "Epoch: 1337 train_loss= 0.40765 train_acc= 0.93313 val_roc= 0.73699 val_ap= 0.80667 time= 0.40573\n",
            "Epoch: 1338 train_loss= 0.40765 train_acc= 0.93313 val_roc= 0.73694 val_ap= 0.80664 time= 0.42033\n",
            "Epoch: 1339 train_loss= 0.40765 train_acc= 0.93313 val_roc= 0.73688 val_ap= 0.80661 time= 0.40491\n",
            "Epoch: 1340 train_loss= 0.40765 train_acc= 0.93314 val_roc= 0.73685 val_ap= 0.80659 time= 0.42802\n",
            "Epoch: 1341 train_loss= 0.40765 train_acc= 0.93314 val_roc= 0.73684 val_ap= 0.80660 time= 0.40828\n",
            "Epoch: 1342 train_loss= 0.40765 train_acc= 0.93315 val_roc= 0.73682 val_ap= 0.80658 time= 0.40924\n",
            "Epoch: 1343 train_loss= 0.40764 train_acc= 0.93317 val_roc= 0.73680 val_ap= 0.80658 time= 0.42191\n",
            "Epoch: 1344 train_loss= 0.40764 train_acc= 0.93317 val_roc= 0.73677 val_ap= 0.80655 time= 0.41409\n",
            "Epoch: 1345 train_loss= 0.40764 train_acc= 0.93317 val_roc= 0.73675 val_ap= 0.80654 time= 0.41952\n",
            "Epoch: 1346 train_loss= 0.40764 train_acc= 0.93317 val_roc= 0.73671 val_ap= 0.80651 time= 0.40810\n",
            "Epoch: 1347 train_loss= 0.40764 train_acc= 0.93318 val_roc= 0.73668 val_ap= 0.80648 time= 0.40726\n",
            "Epoch: 1348 train_loss= 0.40764 train_acc= 0.93318 val_roc= 0.73661 val_ap= 0.80644 time= 0.42909\n",
            "Epoch: 1349 train_loss= 0.40764 train_acc= 0.93318 val_roc= 0.73657 val_ap= 0.80643 time= 0.42773\n",
            "Epoch: 1350 train_loss= 0.40764 train_acc= 0.93319 val_roc= 0.73655 val_ap= 0.80642 time= 0.41574\n",
            "Epoch: 1351 train_loss= 0.40764 train_acc= 0.93319 val_roc= 0.73653 val_ap= 0.80643 time= 0.40854\n",
            "Epoch: 1352 train_loss= 0.40764 train_acc= 0.93320 val_roc= 0.73648 val_ap= 0.80641 time= 0.41108\n",
            "Epoch: 1353 train_loss= 0.40764 train_acc= 0.93320 val_roc= 0.73642 val_ap= 0.80640 time= 0.41312\n",
            "Epoch: 1354 train_loss= 0.40764 train_acc= 0.93321 val_roc= 0.73641 val_ap= 0.80639 time= 0.41921\n",
            "Epoch: 1355 train_loss= 0.40764 train_acc= 0.93322 val_roc= 0.73637 val_ap= 0.80638 time= 0.42974\n",
            "Epoch: 1356 train_loss= 0.40764 train_acc= 0.93327 val_roc= 0.73636 val_ap= 0.80638 time= 0.42063\n",
            "Epoch: 1357 train_loss= 0.40764 train_acc= 0.93327 val_roc= 0.73636 val_ap= 0.80638 time= 0.43980\n",
            "Epoch: 1358 train_loss= 0.40764 train_acc= 0.93327 val_roc= 0.73633 val_ap= 0.80637 time= 0.42794\n",
            "Epoch: 1359 train_loss= 0.40764 train_acc= 0.93327 val_roc= 0.73631 val_ap= 0.80637 time= 0.44043\n",
            "Epoch: 1360 train_loss= 0.40764 train_acc= 0.93328 val_roc= 0.73628 val_ap= 0.80635 time= 0.44590\n",
            "Epoch: 1361 train_loss= 0.40764 train_acc= 0.93328 val_roc= 0.73627 val_ap= 0.80634 time= 0.41025\n",
            "Epoch: 1362 train_loss= 0.40764 train_acc= 0.93328 val_roc= 0.73624 val_ap= 0.80633 time= 0.41166\n",
            "Epoch: 1363 train_loss= 0.40764 train_acc= 0.93328 val_roc= 0.73623 val_ap= 0.80632 time= 0.40547\n",
            "Epoch: 1364 train_loss= 0.40764 train_acc= 0.93328 val_roc= 0.73623 val_ap= 0.80632 time= 0.41423\n",
            "Epoch: 1365 train_loss= 0.40764 train_acc= 0.93329 val_roc= 0.73620 val_ap= 0.80630 time= 0.44250\n",
            "Epoch: 1366 train_loss= 0.40764 train_acc= 0.93329 val_roc= 0.73617 val_ap= 0.80628 time= 0.41098\n",
            "Epoch: 1367 train_loss= 0.40764 train_acc= 0.93329 val_roc= 0.73615 val_ap= 0.80627 time= 0.43274\n",
            "Epoch: 1368 train_loss= 0.40764 train_acc= 0.93329 val_roc= 0.73612 val_ap= 0.80627 time= 0.42565\n",
            "Epoch: 1369 train_loss= 0.40764 train_acc= 0.93329 val_roc= 0.73612 val_ap= 0.80624 time= 0.43569\n",
            "Epoch: 1370 train_loss= 0.40764 train_acc= 0.93330 val_roc= 0.73610 val_ap= 0.80622 time= 0.40787\n",
            "Epoch: 1371 train_loss= 0.40764 train_acc= 0.93330 val_roc= 0.73610 val_ap= 0.80623 time= 0.44195\n",
            "Epoch: 1372 train_loss= 0.40764 train_acc= 0.93330 val_roc= 0.73607 val_ap= 0.80620 time= 0.43756\n",
            "Epoch: 1373 train_loss= 0.40764 train_acc= 0.93330 val_roc= 0.73605 val_ap= 0.80620 time= 0.42349\n",
            "Epoch: 1374 train_loss= 0.40764 train_acc= 0.93330 val_roc= 0.73606 val_ap= 0.80621 time= 0.41415\n",
            "Epoch: 1375 train_loss= 0.40764 train_acc= 0.93330 val_roc= 0.73603 val_ap= 0.80620 time= 0.42344\n",
            "Epoch: 1376 train_loss= 0.40764 train_acc= 0.93330 val_roc= 0.73602 val_ap= 0.80621 time= 0.42138\n",
            "Epoch: 1377 train_loss= 0.40764 train_acc= 0.93330 val_roc= 0.73599 val_ap= 0.80620 time= 0.41087\n",
            "Epoch: 1378 train_loss= 0.40764 train_acc= 0.93330 val_roc= 0.73596 val_ap= 0.80618 time= 0.40725\n",
            "Epoch: 1379 train_loss= 0.40764 train_acc= 0.93331 val_roc= 0.73597 val_ap= 0.80617 time= 0.41831\n",
            "Epoch: 1380 train_loss= 0.40764 train_acc= 0.93331 val_roc= 0.73595 val_ap= 0.80615 time= 0.40623\n",
            "Epoch: 1381 train_loss= 0.40763 train_acc= 0.93331 val_roc= 0.73595 val_ap= 0.80614 time= 0.41070\n",
            "Epoch: 1382 train_loss= 0.40763 train_acc= 0.93331 val_roc= 0.73592 val_ap= 0.80612 time= 0.40961\n",
            "Epoch: 1383 train_loss= 0.40763 train_acc= 0.93331 val_roc= 0.73588 val_ap= 0.80609 time= 0.40652\n",
            "Epoch: 1384 train_loss= 0.40763 train_acc= 0.93332 val_roc= 0.73586 val_ap= 0.80607 time= 0.41204\n",
            "Epoch: 1385 train_loss= 0.40763 train_acc= 0.93332 val_roc= 0.73581 val_ap= 0.80604 time= 0.40639\n",
            "Epoch: 1386 train_loss= 0.40763 train_acc= 0.93332 val_roc= 0.73576 val_ap= 0.80603 time= 0.41461\n",
            "Epoch: 1387 train_loss= 0.40763 train_acc= 0.93332 val_roc= 0.73574 val_ap= 0.80604 time= 0.41148\n",
            "Epoch: 1388 train_loss= 0.40763 train_acc= 0.93332 val_roc= 0.73572 val_ap= 0.80602 time= 0.41367\n",
            "Epoch: 1389 train_loss= 0.40763 train_acc= 0.93333 val_roc= 0.73575 val_ap= 0.80603 time= 0.41469\n",
            "Epoch: 1390 train_loss= 0.40763 train_acc= 0.93335 val_roc= 0.73574 val_ap= 0.80602 time= 0.40993\n",
            "Epoch: 1391 train_loss= 0.40763 train_acc= 0.93335 val_roc= 0.73574 val_ap= 0.80602 time= 0.41507\n",
            "Epoch: 1392 train_loss= 0.40763 train_acc= 0.93335 val_roc= 0.73571 val_ap= 0.80600 time= 0.41537\n",
            "Epoch: 1393 train_loss= 0.40763 train_acc= 0.93335 val_roc= 0.73568 val_ap= 0.80599 time= 0.40736\n",
            "Epoch: 1394 train_loss= 0.40763 train_acc= 0.93336 val_roc= 0.73566 val_ap= 0.80597 time= 0.41955\n",
            "Epoch: 1395 train_loss= 0.40763 train_acc= 0.93336 val_roc= 0.73565 val_ap= 0.80597 time= 0.40938\n",
            "Epoch: 1396 train_loss= 0.40763 train_acc= 0.93337 val_roc= 0.73564 val_ap= 0.80595 time= 0.41253\n",
            "Epoch: 1397 train_loss= 0.40763 train_acc= 0.93339 val_roc= 0.73561 val_ap= 0.80595 time= 0.41277\n",
            "Epoch: 1398 train_loss= 0.40763 train_acc= 0.93344 val_roc= 0.73559 val_ap= 0.80594 time= 0.41584\n",
            "Epoch: 1399 train_loss= 0.40763 train_acc= 0.93344 val_roc= 0.73561 val_ap= 0.80596 time= 0.41922\n",
            "Epoch: 1400 train_loss= 0.40763 train_acc= 0.93344 val_roc= 0.73560 val_ap= 0.80594 time= 0.44743\n",
            "Epoch: 1401 train_loss= 0.40762 train_acc= 0.93345 val_roc= 0.73562 val_ap= 0.80594 time= 0.41470\n",
            "Epoch: 1402 train_loss= 0.40762 train_acc= 0.93346 val_roc= 0.73562 val_ap= 0.80595 time= 0.41452\n",
            "Epoch: 1403 train_loss= 0.40762 train_acc= 0.93348 val_roc= 0.73562 val_ap= 0.80595 time= 0.41015\n",
            "Epoch: 1404 train_loss= 0.40762 train_acc= 0.93353 val_roc= 0.73563 val_ap= 0.80595 time= 0.41481\n",
            "Epoch: 1405 train_loss= 0.40762 train_acc= 0.93353 val_roc= 0.73564 val_ap= 0.80595 time= 0.40886\n",
            "Epoch: 1406 train_loss= 0.40762 train_acc= 0.93357 val_roc= 0.73564 val_ap= 0.80595 time= 0.43515\n",
            "Epoch: 1407 train_loss= 0.40762 train_acc= 0.93358 val_roc= 0.73565 val_ap= 0.80593 time= 0.43649\n",
            "Epoch: 1408 train_loss= 0.40762 train_acc= 0.93360 val_roc= 0.73565 val_ap= 0.80593 time= 0.44007\n",
            "Epoch: 1409 train_loss= 0.40762 train_acc= 0.93360 val_roc= 0.73562 val_ap= 0.80592 time= 0.41035\n",
            "Epoch: 1410 train_loss= 0.40762 train_acc= 0.93360 val_roc= 0.73559 val_ap= 0.80592 time= 0.41488\n",
            "Epoch: 1411 train_loss= 0.40762 train_acc= 0.93361 val_roc= 0.73559 val_ap= 0.80591 time= 0.42510\n",
            "Epoch: 1412 train_loss= 0.40762 train_acc= 0.93363 val_roc= 0.73561 val_ap= 0.80591 time= 0.41015\n",
            "Epoch: 1413 train_loss= 0.40762 train_acc= 0.93363 val_roc= 0.73559 val_ap= 0.80591 time= 0.41982\n",
            "Epoch: 1414 train_loss= 0.40762 train_acc= 0.93364 val_roc= 0.73558 val_ap= 0.80591 time= 0.44205\n",
            "Epoch: 1415 train_loss= 0.40762 train_acc= 0.93366 val_roc= 0.73558 val_ap= 0.80591 time= 0.44967\n",
            "Epoch: 1416 train_loss= 0.40762 train_acc= 0.93366 val_roc= 0.73558 val_ap= 0.80588 time= 0.41297\n",
            "Epoch: 1417 train_loss= 0.40762 train_acc= 0.93367 val_roc= 0.73555 val_ap= 0.80586 time= 0.40963\n",
            "Epoch: 1418 train_loss= 0.40762 train_acc= 0.93367 val_roc= 0.73556 val_ap= 0.80587 time= 0.42250\n",
            "Epoch: 1419 train_loss= 0.40762 train_acc= 0.93367 val_roc= 0.73557 val_ap= 0.80588 time= 0.40477\n",
            "Epoch: 1420 train_loss= 0.40762 train_acc= 0.93368 val_roc= 0.73553 val_ap= 0.80581 time= 0.41623\n",
            "Epoch: 1421 train_loss= 0.40762 train_acc= 0.93368 val_roc= 0.73553 val_ap= 0.80581 time= 0.41751\n",
            "Epoch: 1422 train_loss= 0.40762 train_acc= 0.93368 val_roc= 0.73555 val_ap= 0.80582 time= 0.43428\n",
            "Epoch: 1423 train_loss= 0.40762 train_acc= 0.93368 val_roc= 0.73555 val_ap= 0.80581 time= 0.42375\n",
            "Epoch: 1424 train_loss= 0.40762 train_acc= 0.93368 val_roc= 0.73554 val_ap= 0.80580 time= 0.44417\n",
            "Epoch: 1425 train_loss= 0.40762 train_acc= 0.93369 val_roc= 0.73554 val_ap= 0.80579 time= 0.46052\n",
            "Epoch: 1426 train_loss= 0.40762 train_acc= 0.93369 val_roc= 0.73555 val_ap= 0.80579 time= 0.44634\n",
            "Epoch: 1427 train_loss= 0.40762 train_acc= 0.93369 val_roc= 0.73556 val_ap= 0.80579 time= 0.42381\n",
            "Epoch: 1428 train_loss= 0.40762 train_acc= 0.93370 val_roc= 0.73557 val_ap= 0.80580 time= 0.41008\n",
            "Epoch: 1429 train_loss= 0.40762 train_acc= 0.93372 val_roc= 0.73559 val_ap= 0.80580 time= 0.41691\n",
            "Epoch: 1430 train_loss= 0.40762 train_acc= 0.93373 val_roc= 0.73557 val_ap= 0.80578 time= 0.42162\n",
            "Epoch: 1431 train_loss= 0.40762 train_acc= 0.93373 val_roc= 0.73557 val_ap= 0.80577 time= 0.40795\n",
            "Epoch: 1432 train_loss= 0.40761 train_acc= 0.93373 val_roc= 0.73556 val_ap= 0.80577 time= 0.41719\n",
            "Epoch: 1433 train_loss= 0.40761 train_acc= 0.93376 val_roc= 0.73548 val_ap= 0.80567 time= 0.41381\n",
            "Epoch: 1434 train_loss= 0.40761 train_acc= 0.93376 val_roc= 0.73545 val_ap= 0.80562 time= 0.41083\n",
            "Epoch: 1435 train_loss= 0.40761 train_acc= 0.93377 val_roc= 0.73541 val_ap= 0.80553 time= 0.41104\n",
            "Epoch: 1436 train_loss= 0.40761 train_acc= 0.93377 val_roc= 0.73517 val_ap= 0.80526 time= 0.40826\n",
            "Epoch: 1437 train_loss= 0.40761 train_acc= 0.93378 val_roc= 0.73483 val_ap= 0.80503 time= 0.42714\n",
            "Epoch: 1438 train_loss= 0.40761 train_acc= 0.93380 val_roc= 0.73454 val_ap= 0.80487 time= 0.43255\n",
            "Epoch: 1439 train_loss= 0.40761 train_acc= 0.93380 val_roc= 0.73430 val_ap= 0.80479 time= 0.43067\n",
            "Epoch: 1440 train_loss= 0.40761 train_acc= 0.93380 val_roc= 0.73423 val_ap= 0.80477 time= 0.42150\n",
            "Epoch: 1441 train_loss= 0.40761 train_acc= 0.93380 val_roc= 0.73414 val_ap= 0.80478 time= 0.41972\n",
            "Epoch: 1442 train_loss= 0.40761 train_acc= 0.93380 val_roc= 0.73421 val_ap= 0.80484 time= 0.41732\n",
            "Epoch: 1443 train_loss= 0.40761 train_acc= 0.93381 val_roc= 0.73421 val_ap= 0.80483 time= 0.40611\n",
            "Epoch: 1444 train_loss= 0.40761 train_acc= 0.93381 val_roc= 0.73420 val_ap= 0.80485 time= 0.41326\n",
            "Epoch: 1445 train_loss= 0.40761 train_acc= 0.93381 val_roc= 0.73427 val_ap= 0.80491 time= 0.42961\n",
            "Epoch: 1446 train_loss= 0.40761 train_acc= 0.93381 val_roc= 0.73433 val_ap= 0.80497 time= 0.41516\n",
            "Epoch: 1447 train_loss= 0.40761 train_acc= 0.93381 val_roc= 0.73438 val_ap= 0.80501 time= 0.40808\n",
            "Epoch: 1448 train_loss= 0.40761 train_acc= 0.93382 val_roc= 0.73434 val_ap= 0.80498 time= 0.44898\n",
            "Epoch: 1449 train_loss= 0.40761 train_acc= 0.93382 val_roc= 0.73426 val_ap= 0.80488 time= 0.42913\n",
            "Epoch: 1450 train_loss= 0.40760 train_acc= 0.93382 val_roc= 0.73408 val_ap= 0.80470 time= 0.42831\n",
            "Epoch: 1451 train_loss= 0.40760 train_acc= 0.93383 val_roc= 0.73387 val_ap= 0.80453 time= 0.41357\n",
            "Epoch: 1452 train_loss= 0.40760 train_acc= 0.93383 val_roc= 0.73366 val_ap= 0.80443 time= 0.41425\n",
            "Epoch: 1453 train_loss= 0.40760 train_acc= 0.93383 val_roc= 0.73338 val_ap= 0.80432 time= 0.41266\n",
            "Epoch: 1454 train_loss= 0.40760 train_acc= 0.93383 val_roc= 0.73313 val_ap= 0.80421 time= 0.44322\n",
            "Epoch: 1455 train_loss= 0.40760 train_acc= 0.93384 val_roc= 0.73300 val_ap= 0.80415 time= 0.41923\n",
            "Epoch: 1456 train_loss= 0.40760 train_acc= 0.93384 val_roc= 0.73290 val_ap= 0.80411 time= 0.42354\n",
            "Epoch: 1457 train_loss= 0.40760 train_acc= 0.93384 val_roc= 0.73284 val_ap= 0.80410 time= 0.43686\n",
            "Epoch: 1458 train_loss= 0.40760 train_acc= 0.93385 val_roc= 0.73280 val_ap= 0.80408 time= 0.43670\n",
            "Epoch: 1459 train_loss= 0.40760 train_acc= 0.93385 val_roc= 0.73278 val_ap= 0.80407 time= 0.42625\n",
            "Epoch: 1460 train_loss= 0.40760 train_acc= 0.93385 val_roc= 0.73278 val_ap= 0.80406 time= 0.41314\n",
            "Epoch: 1461 train_loss= 0.40760 train_acc= 0.93385 val_roc= 0.73279 val_ap= 0.80406 time= 0.41723\n",
            "Epoch: 1462 train_loss= 0.40760 train_acc= 0.93386 val_roc= 0.73283 val_ap= 0.80407 time= 0.40611\n",
            "Epoch: 1463 train_loss= 0.40760 train_acc= 0.93386 val_roc= 0.73286 val_ap= 0.80408 time= 0.43019\n",
            "Epoch: 1464 train_loss= 0.40760 train_acc= 0.93386 val_roc= 0.73287 val_ap= 0.80408 time= 0.40762\n",
            "Epoch: 1465 train_loss= 0.40760 train_acc= 0.93389 val_roc= 0.73288 val_ap= 0.80409 time= 0.41133\n",
            "Epoch: 1466 train_loss= 0.40760 train_acc= 0.93389 val_roc= 0.73292 val_ap= 0.80408 time= 0.41732\n",
            "Epoch: 1467 train_loss= 0.40760 train_acc= 0.93389 val_roc= 0.73290 val_ap= 0.80406 time= 0.41815\n",
            "Epoch: 1468 train_loss= 0.40760 train_acc= 0.93390 val_roc= 0.73294 val_ap= 0.80407 time= 0.41751\n",
            "Epoch: 1469 train_loss= 0.40760 train_acc= 0.93393 val_roc= 0.73294 val_ap= 0.80408 time= 0.40556\n",
            "Epoch: 1470 train_loss= 0.40760 train_acc= 0.93393 val_roc= 0.73297 val_ap= 0.80409 time= 0.41799\n",
            "Epoch: 1471 train_loss= 0.40760 train_acc= 0.93393 val_roc= 0.73294 val_ap= 0.80406 time= 0.41682\n",
            "Epoch: 1472 train_loss= 0.40760 train_acc= 0.93393 val_roc= 0.73296 val_ap= 0.80405 time= 0.41699\n",
            "Epoch: 1473 train_loss= 0.40760 train_acc= 0.93393 val_roc= 0.73297 val_ap= 0.80404 time= 0.41523\n",
            "Epoch: 1474 train_loss= 0.40760 train_acc= 0.93394 val_roc= 0.73300 val_ap= 0.80405 time= 0.41011\n",
            "Epoch: 1475 train_loss= 0.40760 train_acc= 0.93394 val_roc= 0.73300 val_ap= 0.80405 time= 0.41106\n",
            "Epoch: 1476 train_loss= 0.40760 train_acc= 0.93394 val_roc= 0.73298 val_ap= 0.80403 time= 0.41094\n",
            "Epoch: 1477 train_loss= 0.40760 train_acc= 0.93394 val_roc= 0.73298 val_ap= 0.80403 time= 0.40883\n",
            "Epoch: 1478 train_loss= 0.40760 train_acc= 0.93394 val_roc= 0.73301 val_ap= 0.80404 time= 0.41226\n",
            "Epoch: 1479 train_loss= 0.40760 train_acc= 0.93394 val_roc= 0.73302 val_ap= 0.80404 time= 0.40721\n",
            "Epoch: 1480 train_loss= 0.40760 train_acc= 0.93395 val_roc= 0.73302 val_ap= 0.80404 time= 0.41643\n",
            "Epoch: 1481 train_loss= 0.40760 train_acc= 0.93395 val_roc= 0.73304 val_ap= 0.80405 time= 0.40772\n",
            "Epoch: 1482 train_loss= 0.40760 train_acc= 0.93395 val_roc= 0.73302 val_ap= 0.80403 time= 0.42059\n",
            "Epoch: 1483 train_loss= 0.40760 train_acc= 0.93395 val_roc= 0.73295 val_ap= 0.80398 time= 0.42026\n",
            "Epoch: 1484 train_loss= 0.40760 train_acc= 0.93395 val_roc= 0.73294 val_ap= 0.80398 time= 0.42981\n",
            "Epoch: 1485 train_loss= 0.40760 train_acc= 0.93395 val_roc= 0.73288 val_ap= 0.80393 time= 0.43711\n",
            "Epoch: 1486 train_loss= 0.40760 train_acc= 0.93395 val_roc= 0.73283 val_ap= 0.80389 time= 0.41084\n",
            "Epoch: 1487 train_loss= 0.40760 train_acc= 0.93396 val_roc= 0.73280 val_ap= 0.80387 time= 0.42576\n",
            "Epoch: 1488 train_loss= 0.40760 train_acc= 0.93396 val_roc= 0.73276 val_ap= 0.80384 time= 0.44355\n",
            "Epoch: 1489 train_loss= 0.40760 train_acc= 0.93396 val_roc= 0.73273 val_ap= 0.80381 time= 0.43806\n",
            "Epoch: 1490 train_loss= 0.40760 train_acc= 0.93396 val_roc= 0.73271 val_ap= 0.80380 time= 0.43265\n",
            "Epoch: 1491 train_loss= 0.40760 train_acc= 0.93396 val_roc= 0.73267 val_ap= 0.80375 time= 0.40984\n",
            "Epoch: 1492 train_loss= 0.40760 train_acc= 0.93396 val_roc= 0.73264 val_ap= 0.80374 time= 0.41415\n",
            "Epoch: 1493 train_loss= 0.40760 train_acc= 0.93396 val_roc= 0.73259 val_ap= 0.80368 time= 0.40946\n",
            "Epoch: 1494 train_loss= 0.40760 train_acc= 0.93396 val_roc= 0.73259 val_ap= 0.80367 time= 0.40776\n",
            "Epoch: 1495 train_loss= 0.40760 train_acc= 0.93397 val_roc= 0.73253 val_ap= 0.80362 time= 0.43051\n",
            "Epoch: 1496 train_loss= 0.40760 train_acc= 0.93396 val_roc= 0.73249 val_ap= 0.80359 time= 0.41082\n",
            "Epoch: 1497 train_loss= 0.40760 train_acc= 0.93397 val_roc= 0.73243 val_ap= 0.80354 time= 0.41516\n",
            "Epoch: 1498 train_loss= 0.40760 train_acc= 0.93397 val_roc= 0.73239 val_ap= 0.80351 time= 0.41455\n",
            "Epoch: 1499 train_loss= 0.40760 train_acc= 0.93397 val_roc= 0.73235 val_ap= 0.80346 time= 0.41907\n",
            "Epoch: 1500 train_loss= 0.40760 train_acc= 0.93397 val_roc= 0.73236 val_ap= 0.80346 time= 0.41821\n",
            "End of training! test_roc= 0.71344 test_ap= 0.77835\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}