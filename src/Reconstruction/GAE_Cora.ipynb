{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAE_Cora.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoJstoMsmPS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/DaehanKim/vgae_pytorch\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "import scipy.sparse as sp\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87ADSmnpmy0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Args:\n",
        "  dataset = 'cora'\n",
        "  model = 'GAE'\n",
        "\n",
        "  input_dim = 1433 \n",
        "  hidden1_dim = 32\n",
        "  hidden2_dim = 16\n",
        "  use_feature = True\n",
        "\n",
        "  num_epoch = 200\n",
        "  learning_rate = 0.01\n",
        "args=Args()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03DM2VwxmXUs",
        "colab_type": "code",
        "outputId": "5e50d4c0-2893-4e73-9fa3-e220e340fcfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "****************NOTE*****************\n",
        "CREDITS : Thomas Kipf\n",
        "since datasets are the same as those in kipf's implementation, \n",
        "Their preprocessing source was used as-is.\n",
        "*************************************\n",
        "'''\n",
        "import numpy as np\n",
        "import sys\n",
        "import pickle as pkl\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "colab='Colab Notebooks'\n",
        "path = F\"/content/gdrive/My Drive/{colab}/GraphNN/data/\"\n",
        "\n",
        "def parse_index_file(filename):\n",
        "    index = []\n",
        "    for line in open(filename):\n",
        "        index.append(int(line.strip()))\n",
        "    return index\n",
        "\n",
        "def load_data(dataset):\n",
        "    # load the data: x, tx, allx, graph\n",
        "    names = ['x', 'tx', 'allx', 'graph']\n",
        "    objects = []\n",
        "    for i in range(len(names)):\n",
        "        with open(path+\"ind.{}.{}\".format(dataset, names[i]), 'rb') as f:\n",
        "            if sys.version_info > (3, 0):\n",
        "                objects.append(pkl.load(f, encoding='latin1'))\n",
        "            else:\n",
        "                objects.append(pkl.load(f))\n",
        "    x, tx, allx, graph = tuple(objects)\n",
        "    test_idx_reorder = parse_index_file(path+\"ind.{}.test.index\".format(dataset))\n",
        "    test_idx_range = np.sort(test_idx_reorder)\n",
        "\n",
        "    if dataset == 'citeseer':\n",
        "        # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
        "        # Find isolated nodes, add them as zero-vecs into the right position\n",
        "        test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
        "        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
        "        tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
        "        tx = tx_extended\n",
        "\n",
        "    features = sp.vstack((allx, tx)).tolil()\n",
        "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
        "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
        "\n",
        "    return adj, features"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q60gv7pmdil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "****************NOTE*****************\n",
        "CREDITS : Thomas Kipf\n",
        "since datasets are the same as those in kipf's implementation, \n",
        "Their preprocessing source was used as-is.\n",
        "*************************************\n",
        "'''\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "def sparse_to_tuple(sparse_mx):\n",
        "    if not sp.isspmatrix_coo(sparse_mx):\n",
        "        sparse_mx = sparse_mx.tocoo()\n",
        "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
        "    values = sparse_mx.data\n",
        "    shape = sparse_mx.shape\n",
        "    return coords, values, shape\n",
        "\n",
        "def preprocess_graph(adj):\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    adj_ = adj + sp.eye(adj.shape[0])\n",
        "    rowsum = np.array(adj_.sum(1))\n",
        "    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n",
        "    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n",
        "    return sparse_to_tuple(adj_normalized)\n",
        "\n",
        "def mask_test_edges(adj):\n",
        "    # Function to build test set with 10% positive links\n",
        "    # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n",
        "    # TODO: Clean up.\n",
        "\n",
        "    # Remove diagonal elements\n",
        "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
        "    adj.eliminate_zeros()\n",
        "    # Check that diag is zero:\n",
        "    assert np.diag(adj.todense()).sum() == 0\n",
        "\n",
        "    adj_triu = sp.triu(adj)\n",
        "    adj_tuple = sparse_to_tuple(adj_triu)\n",
        "    edges = adj_tuple[0]\n",
        "    edges_all = sparse_to_tuple(adj)[0]\n",
        "    #num_test = int(np.floor(edges.shape[0] / 60.))\n",
        "    #num_val = int(np.floor(edges.shape[0] / 10.))\n",
        "    num_val=int(edges.shape[0]*0.1)\n",
        "    num_test=int(edges.shape[0]*0.6)\n",
        "    all_edge_idx = list(range(edges.shape[0]))\n",
        "    np.random.shuffle(all_edge_idx)\n",
        "    val_edge_idx = all_edge_idx[:num_val]\n",
        "    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
        "    test_edges = edges[test_edge_idx]\n",
        "    val_edges = edges[val_edge_idx]\n",
        "    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
        "\n",
        "    def ismember(a, b, tol=5):\n",
        "        rows_close = np.all(np.round(a - b[:, None], tol) == 0, axis=-1)\n",
        "        return np.any(rows_close)\n",
        "\n",
        "    test_edges_false = []\n",
        "    while len(test_edges_false) < len(test_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], edges_all):\n",
        "            continue\n",
        "        if test_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(test_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(test_edges_false)):\n",
        "                continue\n",
        "        test_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    val_edges_false = []\n",
        "    while len(val_edges_false) < len(val_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], train_edges):\n",
        "            continue\n",
        "        if ismember([idx_j, idx_i], train_edges):\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], val_edges):\n",
        "            continue\n",
        "        if ismember([idx_j, idx_i], val_edges):\n",
        "            continue\n",
        "        if val_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(val_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(val_edges_false)):\n",
        "                continue\n",
        "        val_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    assert ~ismember(test_edges_false, edges_all)\n",
        "    assert ~ismember(val_edges_false, edges_all)\n",
        "    assert ~ismember(val_edges, train_edges)\n",
        "    assert ~ismember(test_edges, train_edges)\n",
        "    assert ~ismember(val_edges, test_edges)\n",
        "\n",
        "    data = np.ones(train_edges.shape[0])\n",
        "\n",
        "    # Re-build adj matrix\n",
        "    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n",
        "    adj_train = adj_train + adj_train.T\n",
        "\n",
        "    # NOTE: these edge lists only contain single direction of edge!\n",
        "    return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VoHmNaFmkjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "class GraphConvSparse(nn.Module):\n",
        "\tdef __init__(self, input_dim, output_dim, adj, activation = F.relu, **kwargs):\n",
        "\t\tsuper(GraphConvSparse, self).__init__(**kwargs)\n",
        "\t\tself.weight = glorot_init(input_dim, output_dim) \n",
        "\t\tself.adj = adj\n",
        "\t\tself.activation = activation\n",
        "\n",
        "\tdef forward(self, inputs):\n",
        "\t\tx = inputs\n",
        "\t\tx = torch.mm(x,self.weight)\n",
        "\t\tx = torch.mm(self.adj, x)\n",
        "\t\toutputs = self.activation(x)\n",
        "\t\treturn outputs\n",
        "\n",
        "\n",
        "def dot_product_decode(Z):\n",
        "\tA_pred = torch.sigmoid(torch.matmul(Z,Z.t()))\n",
        "\treturn A_pred\n",
        "\n",
        "def glorot_init(input_dim, output_dim):\n",
        "\tinit_range = np.sqrt(6.0/(input_dim + output_dim))\n",
        "\tinitial = torch.rand(input_dim, output_dim)*2*init_range - init_range\n",
        "\treturn nn.Parameter(initial)\n",
        "\n",
        "\n",
        "class GAE(nn.Module):\n",
        "\tdef __init__(self,adj):\n",
        "\t\tsuper(GAE,self).__init__()\n",
        "\t\tself.base_gcn = GraphConvSparse(args.input_dim, args.hidden1_dim, adj)\n",
        "\t\tself.gcn_mean = GraphConvSparse(args.hidden1_dim, args.hidden2_dim, adj, activation=lambda x:x)\n",
        "\n",
        "\tdef encode(self, X):\n",
        "\t\thidden = self.base_gcn(X)\n",
        "\t\tz = self.mean = self.gcn_mean(hidden)\n",
        "\t\treturn z\n",
        "\n",
        "\tdef forward(self, X):\n",
        "\t\tZ = self.encode(X)\n",
        "\t\tA_pred = dot_product_decode(Z)\n",
        "\t\treturn A_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDfaB6uwnFAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
        "\n",
        "adj, features = load_data(args.dataset)\n",
        "\n",
        "# Store original adjacency matrix (without diagonal entries) for later\n",
        "adj_orig = adj\n",
        "adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
        "adj_orig.eliminate_zeros()\n",
        "\n",
        "adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
        "adj = adj_train\n",
        "# Some preprocessing\n",
        "adj_norm = preprocess_graph(adj)\n",
        "\n",
        "\n",
        "num_nodes = adj.shape[0]\n",
        "\n",
        "features = sparse_to_tuple(features.tocoo())\n",
        "num_features = features[2][1]\n",
        "features_nonzero = features[1].shape[0]\n",
        "\n",
        "# Create Model\n",
        "pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
        "norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
        "\n",
        "\n",
        "adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
        "adj_label = sparse_to_tuple(adj_label)\n",
        "\n",
        "\n",
        "adj_norm = torch.sparse.FloatTensor(torch.LongTensor(adj_norm[0].T), torch.FloatTensor(adj_norm[1]), torch.Size(adj_norm[2]))\n",
        "adj_label = torch.sparse.FloatTensor(torch.LongTensor(adj_label[0].T),  torch.FloatTensor(adj_label[1]), torch.Size(adj_label[2]))\n",
        "features = torch.sparse.FloatTensor(torch.LongTensor(features[0].T), torch.FloatTensor(features[1]), torch.Size(features[2]))\n",
        "\n",
        "weight_mask = adj_label.to_dense().view(-1) == 1\n",
        "weight_tensor = torch.ones(weight_mask.size(0)) \n",
        "weight_tensor[weight_mask] = pos_weight\n",
        "\n",
        "# init model and optimizer\n",
        "#model = getattr(model,\"GAE\")(adj_norm)\n",
        "#model=VGAE(adj_norm)\n",
        "model=GAE(adj_norm)\n",
        "optimizer = Adam(model.parameters(), lr=args.learning_rate)\n",
        "\n",
        "\n",
        "def get_scores(edges_pos, edges_neg, adj_rec):\n",
        "\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # Predict on test set of edges\n",
        "    preds = []\n",
        "    pos = []\n",
        "    for e in edges_pos:\n",
        "        # print(e)\n",
        "        # print(adj_rec[e[0], e[1]])\n",
        "        preds.append(sigmoid(adj_rec[e[0], e[1]].item()))\n",
        "        pos.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_neg = []\n",
        "    neg = []\n",
        "    for e in edges_neg:\n",
        "\n",
        "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]].data))\n",
        "        neg.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_all = np.hstack([preds, preds_neg])\n",
        "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
        "    roc_score = roc_auc_score(labels_all, preds_all)\n",
        "    ap_score = average_precision_score(labels_all, preds_all)\n",
        "\n",
        "    return roc_score, ap_score\n",
        "\n",
        "def get_acc(adj_rec, adj_label):\n",
        "    labels_all = adj_label.to_dense().view(-1).long()\n",
        "    preds_all = (adj_rec > 0.5).view(-1).long()\n",
        "    accuracy = (preds_all == labels_all).sum().float() / labels_all.size(0)\n",
        "    return accuracy\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK5JgeJ_NLPT",
        "colab_type": "code",
        "outputId": "a0980eea-7fd2-458e-b53f-ad24cc96ea24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train model\n",
        "for epoch in range(1500):\n",
        "    t = time.time()\n",
        "\n",
        "    A_pred = model(features)\n",
        "    optimizer.zero_grad()\n",
        "    loss = log_lik = norm*F.binary_cross_entropy(A_pred.view(-1), adj_label.to_dense().view(-1), weight = weight_tensor)\n",
        "    if args.model == 'VGAE':\n",
        "        kl_divergence = 0.5/ A_pred.size(0) * (1 + 2*model.logstd - model.mean**2 - torch.exp(model.logstd)).sum(1).mean()\n",
        "        loss -= kl_divergence\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_acc = get_acc(A_pred,adj_label)\n",
        "\n",
        "    val_roc, val_ap = get_scores(val_edges, val_edges_false, A_pred)\n",
        "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(loss.item()),\n",
        "          \"train_acc=\", \"{:.5f}\".format(train_acc), \"val_roc=\", \"{:.5f}\".format(val_roc),\n",
        "          \"val_ap=\", \"{:.5f}\".format(val_ap),\n",
        "          \"time=\", \"{:.5f}\".format(time.time() - t))\n",
        "\n",
        "\n",
        "test_roc, test_ap = get_scores(test_edges, test_edges_false, A_pred)\n",
        "print(\"End of training!\", \"test_roc=\", \"{:.5f}\".format(test_roc),\n",
        "      \"test_ap=\", \"{:.5f}\".format(test_ap))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 train_loss= 0.94271 train_acc= 0.04756 val_roc= 0.62206 val_ap= 0.63246 time= 0.29675\n",
            "Epoch: 0002 train_loss= 0.91823 train_acc= 0.00083 val_roc= 0.62517 val_ap= 0.65987 time= 0.29761\n",
            "Epoch: 0003 train_loss= 0.83989 train_acc= 0.02980 val_roc= 0.69071 val_ap= 0.69497 time= 0.30790\n",
            "Epoch: 0004 train_loss= 0.81096 train_acc= 0.08202 val_roc= 0.69228 val_ap= 0.68219 time= 0.29510\n",
            "Epoch: 0005 train_loss= 0.78848 train_acc= 0.06698 val_roc= 0.69466 val_ap= 0.69225 time= 0.30388\n",
            "Epoch: 0006 train_loss= 0.73750 train_acc= 0.15107 val_roc= 0.73189 val_ap= 0.72945 time= 0.30009\n",
            "Epoch: 0007 train_loss= 0.68358 train_acc= 0.30338 val_roc= 0.76008 val_ap= 0.74467 time= 0.31717\n",
            "Epoch: 0008 train_loss= 0.63717 train_acc= 0.41499 val_roc= 0.77585 val_ap= 0.75869 time= 0.31326\n",
            "Epoch: 0009 train_loss= 0.60354 train_acc= 0.45304 val_roc= 0.78750 val_ap= 0.77683 time= 0.30820\n",
            "Epoch: 0010 train_loss= 0.58830 train_acc= 0.46004 val_roc= 0.79632 val_ap= 0.78998 time= 0.30225\n",
            "Epoch: 0011 train_loss= 0.57565 train_acc= 0.46857 val_roc= 0.80550 val_ap= 0.79901 time= 0.30105\n",
            "Epoch: 0012 train_loss= 0.56411 train_acc= 0.48000 val_roc= 0.81130 val_ap= 0.80333 time= 0.29518\n",
            "Epoch: 0013 train_loss= 0.55093 train_acc= 0.48966 val_roc= 0.81545 val_ap= 0.80908 time= 0.30785\n",
            "Epoch: 0014 train_loss= 0.53634 train_acc= 0.49783 val_roc= 0.81876 val_ap= 0.81494 time= 0.29721\n",
            "Epoch: 0015 train_loss= 0.52741 train_acc= 0.50215 val_roc= 0.81994 val_ap= 0.81898 time= 0.29570\n",
            "Epoch: 0016 train_loss= 0.52242 train_acc= 0.50300 val_roc= 0.82023 val_ap= 0.82174 time= 0.30117\n",
            "Epoch: 0017 train_loss= 0.51738 train_acc= 0.50467 val_roc= 0.81918 val_ap= 0.82320 time= 0.30377\n",
            "Epoch: 0018 train_loss= 0.51219 train_acc= 0.50857 val_roc= 0.81840 val_ap= 0.82508 time= 0.29731\n",
            "Epoch: 0019 train_loss= 0.50820 train_acc= 0.51282 val_roc= 0.81746 val_ap= 0.82613 time= 0.31916\n",
            "Epoch: 0020 train_loss= 0.50485 train_acc= 0.51583 val_roc= 0.81752 val_ap= 0.82733 time= 0.31018\n",
            "Epoch: 0021 train_loss= 0.50071 train_acc= 0.51736 val_roc= 0.81837 val_ap= 0.82922 time= 0.31124\n",
            "Epoch: 0022 train_loss= 0.49561 train_acc= 0.51769 val_roc= 0.81965 val_ap= 0.83157 time= 0.29684\n",
            "Epoch: 0023 train_loss= 0.49037 train_acc= 0.51713 val_roc= 0.82180 val_ap= 0.83431 time= 0.30804\n",
            "Epoch: 0024 train_loss= 0.48555 train_acc= 0.51698 val_roc= 0.82445 val_ap= 0.83744 time= 0.29536\n",
            "Epoch: 0025 train_loss= 0.48105 train_acc= 0.51786 val_roc= 0.82734 val_ap= 0.84082 time= 0.29806\n",
            "Epoch: 0026 train_loss= 0.47684 train_acc= 0.51959 val_roc= 0.83005 val_ap= 0.84354 time= 0.30160\n",
            "Epoch: 0027 train_loss= 0.47316 train_acc= 0.52146 val_roc= 0.83237 val_ap= 0.84618 time= 0.31233\n",
            "Epoch: 0028 train_loss= 0.47016 train_acc= 0.52267 val_roc= 0.83385 val_ap= 0.84746 time= 0.30004\n",
            "Epoch: 0029 train_loss= 0.46787 train_acc= 0.52323 val_roc= 0.83417 val_ap= 0.84758 time= 0.30005\n",
            "Epoch: 0030 train_loss= 0.46612 train_acc= 0.52296 val_roc= 0.83415 val_ap= 0.84728 time= 0.30757\n",
            "Epoch: 0031 train_loss= 0.46463 train_acc= 0.52252 val_roc= 0.83369 val_ap= 0.84672 time= 0.29784\n",
            "Epoch: 0032 train_loss= 0.46312 train_acc= 0.52241 val_roc= 0.83288 val_ap= 0.84570 time= 0.30110\n",
            "Epoch: 0033 train_loss= 0.46138 train_acc= 0.52324 val_roc= 0.83190 val_ap= 0.84478 time= 0.30348\n",
            "Epoch: 0034 train_loss= 0.45946 train_acc= 0.52472 val_roc= 0.83112 val_ap= 0.84440 time= 0.29543\n",
            "Epoch: 0035 train_loss= 0.45766 train_acc= 0.52632 val_roc= 0.82998 val_ap= 0.84343 time= 0.31136\n",
            "Epoch: 0036 train_loss= 0.45606 train_acc= 0.52753 val_roc= 0.82902 val_ap= 0.84248 time= 0.30017\n",
            "Epoch: 0037 train_loss= 0.45448 train_acc= 0.52856 val_roc= 0.82781 val_ap= 0.84126 time= 0.30596\n",
            "Epoch: 0038 train_loss= 0.45285 train_acc= 0.52927 val_roc= 0.82671 val_ap= 0.84066 time= 0.30495\n",
            "Epoch: 0039 train_loss= 0.45137 train_acc= 0.52982 val_roc= 0.82549 val_ap= 0.83978 time= 0.30029\n",
            "Epoch: 0040 train_loss= 0.45016 train_acc= 0.53007 val_roc= 0.82458 val_ap= 0.83948 time= 0.31495\n",
            "Epoch: 0041 train_loss= 0.44911 train_acc= 0.53028 val_roc= 0.82363 val_ap= 0.83890 time= 0.30455\n",
            "Epoch: 0042 train_loss= 0.44812 train_acc= 0.53052 val_roc= 0.82304 val_ap= 0.83862 time= 0.31101\n",
            "Epoch: 0043 train_loss= 0.44717 train_acc= 0.53075 val_roc= 0.82224 val_ap= 0.83811 time= 0.30915\n",
            "Epoch: 0044 train_loss= 0.44624 train_acc= 0.53101 val_roc= 0.82103 val_ap= 0.83740 time= 0.29673\n",
            "Epoch: 0045 train_loss= 0.44526 train_acc= 0.53143 val_roc= 0.81995 val_ap= 0.83651 time= 0.30179\n",
            "Epoch: 0046 train_loss= 0.44427 train_acc= 0.53201 val_roc= 0.81851 val_ap= 0.83562 time= 0.29431\n",
            "Epoch: 0047 train_loss= 0.44337 train_acc= 0.53244 val_roc= 0.81742 val_ap= 0.83458 time= 0.32249\n",
            "Epoch: 0048 train_loss= 0.44262 train_acc= 0.53274 val_roc= 0.81669 val_ap= 0.83412 time= 0.29910\n",
            "Epoch: 0049 train_loss= 0.44201 train_acc= 0.53288 val_roc= 0.81652 val_ap= 0.83417 time= 0.32258\n",
            "Epoch: 0050 train_loss= 0.44147 train_acc= 0.53292 val_roc= 0.81630 val_ap= 0.83434 time= 0.32690\n",
            "Epoch: 0051 train_loss= 0.44094 train_acc= 0.53309 val_roc= 0.81652 val_ap= 0.83470 time= 0.31209\n",
            "Epoch: 0052 train_loss= 0.44035 train_acc= 0.53331 val_roc= 0.81648 val_ap= 0.83488 time= 0.30963\n",
            "Epoch: 0053 train_loss= 0.43967 train_acc= 0.53364 val_roc= 0.81656 val_ap= 0.83508 time= 0.32204\n",
            "Epoch: 0054 train_loss= 0.43898 train_acc= 0.53391 val_roc= 0.81653 val_ap= 0.83532 time= 0.31194\n",
            "Epoch: 0055 train_loss= 0.43836 train_acc= 0.53407 val_roc= 0.81626 val_ap= 0.83527 time= 0.30372\n",
            "Epoch: 0056 train_loss= 0.43784 train_acc= 0.53398 val_roc= 0.81616 val_ap= 0.83552 time= 0.32191\n",
            "Epoch: 0057 train_loss= 0.43738 train_acc= 0.53387 val_roc= 0.81609 val_ap= 0.83569 time= 0.30650\n",
            "Epoch: 0058 train_loss= 0.43692 train_acc= 0.53383 val_roc= 0.81609 val_ap= 0.83587 time= 0.29838\n",
            "Epoch: 0059 train_loss= 0.43640 train_acc= 0.53397 val_roc= 0.81634 val_ap= 0.83626 time= 0.29983\n",
            "Epoch: 0060 train_loss= 0.43586 train_acc= 0.53422 val_roc= 0.81657 val_ap= 0.83646 time= 0.30497\n",
            "Epoch: 0061 train_loss= 0.43532 train_acc= 0.53440 val_roc= 0.81666 val_ap= 0.83644 time= 0.30756\n",
            "Epoch: 0062 train_loss= 0.43483 train_acc= 0.53450 val_roc= 0.81667 val_ap= 0.83657 time= 0.31902\n",
            "Epoch: 0063 train_loss= 0.43438 train_acc= 0.53461 val_roc= 0.81650 val_ap= 0.83647 time= 0.32152\n",
            "Epoch: 0064 train_loss= 0.43397 train_acc= 0.53464 val_roc= 0.81640 val_ap= 0.83634 time= 0.29479\n",
            "Epoch: 0065 train_loss= 0.43356 train_acc= 0.53462 val_roc= 0.81608 val_ap= 0.83609 time= 0.30823\n",
            "Epoch: 0066 train_loss= 0.43315 train_acc= 0.53467 val_roc= 0.81578 val_ap= 0.83605 time= 0.30550\n",
            "Epoch: 0067 train_loss= 0.43272 train_acc= 0.53470 val_roc= 0.81559 val_ap= 0.83608 time= 0.32551\n",
            "Epoch: 0068 train_loss= 0.43231 train_acc= 0.53480 val_roc= 0.81554 val_ap= 0.83619 time= 0.30066\n",
            "Epoch: 0069 train_loss= 0.43190 train_acc= 0.53496 val_roc= 0.81566 val_ap= 0.83644 time= 0.30879\n",
            "Epoch: 0070 train_loss= 0.43150 train_acc= 0.53506 val_roc= 0.81559 val_ap= 0.83668 time= 0.31400\n",
            "Epoch: 0071 train_loss= 0.43112 train_acc= 0.53505 val_roc= 0.81551 val_ap= 0.83676 time= 0.31102\n",
            "Epoch: 0072 train_loss= 0.43076 train_acc= 0.53510 val_roc= 0.81523 val_ap= 0.83670 time= 0.29754\n",
            "Epoch: 0073 train_loss= 0.43040 train_acc= 0.53514 val_roc= 0.81514 val_ap= 0.83664 time= 0.34513\n",
            "Epoch: 0074 train_loss= 0.43004 train_acc= 0.53531 val_roc= 0.81521 val_ap= 0.83682 time= 0.31980\n",
            "Epoch: 0075 train_loss= 0.42967 train_acc= 0.53549 val_roc= 0.81508 val_ap= 0.83684 time= 0.30327\n",
            "Epoch: 0076 train_loss= 0.42931 train_acc= 0.53563 val_roc= 0.81509 val_ap= 0.83701 time= 0.32441\n",
            "Epoch: 0077 train_loss= 0.42897 train_acc= 0.53578 val_roc= 0.81497 val_ap= 0.83705 time= 0.31953\n",
            "Epoch: 0078 train_loss= 0.42863 train_acc= 0.53583 val_roc= 0.81484 val_ap= 0.83711 time= 0.31166\n",
            "Epoch: 0079 train_loss= 0.42831 train_acc= 0.53587 val_roc= 0.81473 val_ap= 0.83732 time= 0.31707\n",
            "Epoch: 0080 train_loss= 0.42798 train_acc= 0.53593 val_roc= 0.81464 val_ap= 0.83735 time= 0.29971\n",
            "Epoch: 0081 train_loss= 0.42766 train_acc= 0.53603 val_roc= 0.81481 val_ap= 0.83753 time= 0.31793\n",
            "Epoch: 0082 train_loss= 0.42734 train_acc= 0.53617 val_roc= 0.81474 val_ap= 0.83763 time= 0.32060\n",
            "Epoch: 0083 train_loss= 0.42703 train_acc= 0.53629 val_roc= 0.81466 val_ap= 0.83769 time= 0.32518\n",
            "Epoch: 0084 train_loss= 0.42673 train_acc= 0.53645 val_roc= 0.81474 val_ap= 0.83799 time= 0.31207\n",
            "Epoch: 0085 train_loss= 0.42644 train_acc= 0.53656 val_roc= 0.81472 val_ap= 0.83819 time= 0.30958\n",
            "Epoch: 0086 train_loss= 0.42615 train_acc= 0.53669 val_roc= 0.81465 val_ap= 0.83831 time= 0.31321\n",
            "Epoch: 0087 train_loss= 0.42587 train_acc= 0.53676 val_roc= 0.81454 val_ap= 0.83832 time= 0.30291\n",
            "Epoch: 0088 train_loss= 0.42559 train_acc= 0.53683 val_roc= 0.81447 val_ap= 0.83835 time= 0.32095\n",
            "Epoch: 0089 train_loss= 0.42532 train_acc= 0.53696 val_roc= 0.81436 val_ap= 0.83830 time= 0.34029\n",
            "Epoch: 0090 train_loss= 0.42506 train_acc= 0.53707 val_roc= 0.81427 val_ap= 0.83829 time= 0.29993\n",
            "Epoch: 0091 train_loss= 0.42480 train_acc= 0.53717 val_roc= 0.81416 val_ap= 0.83825 time= 0.30037\n",
            "Epoch: 0092 train_loss= 0.42455 train_acc= 0.53733 val_roc= 0.81411 val_ap= 0.83848 time= 0.30947\n",
            "Epoch: 0093 train_loss= 0.42431 train_acc= 0.53740 val_roc= 0.81394 val_ap= 0.83857 time= 0.29902\n",
            "Epoch: 0094 train_loss= 0.42407 train_acc= 0.53755 val_roc= 0.81367 val_ap= 0.83848 time= 0.29806\n",
            "Epoch: 0095 train_loss= 0.42384 train_acc= 0.53772 val_roc= 0.81355 val_ap= 0.83850 time= 0.30614\n",
            "Epoch: 0096 train_loss= 0.42361 train_acc= 0.53785 val_roc= 0.81325 val_ap= 0.83837 time= 0.29967\n",
            "Epoch: 0097 train_loss= 0.42339 train_acc= 0.53806 val_roc= 0.81308 val_ap= 0.83846 time= 0.30015\n",
            "Epoch: 0098 train_loss= 0.42317 train_acc= 0.53821 val_roc= 0.81291 val_ap= 0.83847 time= 0.29449\n",
            "Epoch: 0099 train_loss= 0.42296 train_acc= 0.53834 val_roc= 0.81272 val_ap= 0.83851 time= 0.30672\n",
            "Epoch: 0100 train_loss= 0.42275 train_acc= 0.53843 val_roc= 0.81258 val_ap= 0.83855 time= 0.29775\n",
            "Epoch: 0101 train_loss= 0.42254 train_acc= 0.53851 val_roc= 0.81254 val_ap= 0.83863 time= 0.29827\n",
            "Epoch: 0102 train_loss= 0.42235 train_acc= 0.53863 val_roc= 0.81227 val_ap= 0.83859 time= 0.30950\n",
            "Epoch: 0103 train_loss= 0.42215 train_acc= 0.53876 val_roc= 0.81207 val_ap= 0.83856 time= 0.29939\n",
            "Epoch: 0104 train_loss= 0.42196 train_acc= 0.53884 val_roc= 0.81191 val_ap= 0.83850 time= 0.31370\n",
            "Epoch: 0105 train_loss= 0.42177 train_acc= 0.53902 val_roc= 0.81177 val_ap= 0.83858 time= 0.32090\n",
            "Epoch: 0106 train_loss= 0.42159 train_acc= 0.53917 val_roc= 0.81160 val_ap= 0.83847 time= 0.29977\n",
            "Epoch: 0107 train_loss= 0.42141 train_acc= 0.53929 val_roc= 0.81142 val_ap= 0.83842 time= 0.29692\n",
            "Epoch: 0108 train_loss= 0.42123 train_acc= 0.53938 val_roc= 0.81134 val_ap= 0.83843 time= 0.33450\n",
            "Epoch: 0109 train_loss= 0.42106 train_acc= 0.53953 val_roc= 0.81116 val_ap= 0.83838 time= 0.32219\n",
            "Epoch: 0110 train_loss= 0.42089 train_acc= 0.53963 val_roc= 0.81119 val_ap= 0.83845 time= 0.31360\n",
            "Epoch: 0111 train_loss= 0.42072 train_acc= 0.53971 val_roc= 0.81124 val_ap= 0.83855 time= 0.30354\n",
            "Epoch: 0112 train_loss= 0.42055 train_acc= 0.53985 val_roc= 0.81125 val_ap= 0.83861 time= 0.30781\n",
            "Epoch: 0113 train_loss= 0.42039 train_acc= 0.53998 val_roc= 0.81117 val_ap= 0.83865 time= 0.30093\n",
            "Epoch: 0114 train_loss= 0.42023 train_acc= 0.54011 val_roc= 0.81119 val_ap= 0.83875 time= 0.29857\n",
            "Epoch: 0115 train_loss= 0.42006 train_acc= 0.54028 val_roc= 0.81118 val_ap= 0.83881 time= 0.33088\n",
            "Epoch: 0116 train_loss= 0.41990 train_acc= 0.54044 val_roc= 0.81123 val_ap= 0.83894 time= 0.29646\n",
            "Epoch: 0117 train_loss= 0.41974 train_acc= 0.54056 val_roc= 0.81125 val_ap= 0.83908 time= 0.29836\n",
            "Epoch: 0118 train_loss= 0.41958 train_acc= 0.54072 val_roc= 0.81130 val_ap= 0.83927 time= 0.30898\n",
            "Epoch: 0119 train_loss= 0.41942 train_acc= 0.54086 val_roc= 0.81127 val_ap= 0.83932 time= 0.29878\n",
            "Epoch: 0120 train_loss= 0.41926 train_acc= 0.54103 val_roc= 0.81142 val_ap= 0.83968 time= 0.30459\n",
            "Epoch: 0121 train_loss= 0.41911 train_acc= 0.54119 val_roc= 0.81140 val_ap= 0.83970 time= 0.30100\n",
            "Epoch: 0122 train_loss= 0.41895 train_acc= 0.54134 val_roc= 0.81155 val_ap= 0.83987 time= 0.31007\n",
            "Epoch: 0123 train_loss= 0.41879 train_acc= 0.54149 val_roc= 0.81161 val_ap= 0.84005 time= 0.31213\n",
            "Epoch: 0124 train_loss= 0.41864 train_acc= 0.54166 val_roc= 0.81167 val_ap= 0.84018 time= 0.30438\n",
            "Epoch: 0125 train_loss= 0.41848 train_acc= 0.54181 val_roc= 0.81190 val_ap= 0.84041 time= 0.31321\n",
            "Epoch: 0126 train_loss= 0.41833 train_acc= 0.54201 val_roc= 0.81207 val_ap= 0.84070 time= 0.29806\n",
            "Epoch: 0127 train_loss= 0.41818 train_acc= 0.54216 val_roc= 0.81225 val_ap= 0.84088 time= 0.30466\n",
            "Epoch: 0128 train_loss= 0.41803 train_acc= 0.54238 val_roc= 0.81233 val_ap= 0.84105 time= 0.30254\n",
            "Epoch: 0129 train_loss= 0.41788 train_acc= 0.54264 val_roc= 0.81244 val_ap= 0.84136 time= 0.29945\n",
            "Epoch: 0130 train_loss= 0.41773 train_acc= 0.54283 val_roc= 0.81250 val_ap= 0.84161 time= 0.29831\n",
            "Epoch: 0131 train_loss= 0.41759 train_acc= 0.54303 val_roc= 0.81244 val_ap= 0.84163 time= 0.29946\n",
            "Epoch: 0132 train_loss= 0.41745 train_acc= 0.54322 val_roc= 0.81243 val_ap= 0.84163 time= 0.30352\n",
            "Epoch: 0133 train_loss= 0.41731 train_acc= 0.54342 val_roc= 0.81259 val_ap= 0.84179 time= 0.30167\n",
            "Epoch: 0134 train_loss= 0.41717 train_acc= 0.54359 val_roc= 0.81273 val_ap= 0.84197 time= 0.29707\n",
            "Epoch: 0135 train_loss= 0.41704 train_acc= 0.54380 val_roc= 0.81297 val_ap= 0.84219 time= 0.31010\n",
            "Epoch: 0136 train_loss= 0.41691 train_acc= 0.54403 val_roc= 0.81308 val_ap= 0.84242 time= 0.29673\n",
            "Epoch: 0137 train_loss= 0.41678 train_acc= 0.54428 val_roc= 0.81313 val_ap= 0.84253 time= 0.30213\n",
            "Epoch: 0138 train_loss= 0.41666 train_acc= 0.54448 val_roc= 0.81324 val_ap= 0.84271 time= 0.30176\n",
            "Epoch: 0139 train_loss= 0.41654 train_acc= 0.54465 val_roc= 0.81321 val_ap= 0.84274 time= 0.30036\n",
            "Epoch: 0140 train_loss= 0.41642 train_acc= 0.54491 val_roc= 0.81319 val_ap= 0.84276 time= 0.30715\n",
            "Epoch: 0141 train_loss= 0.41631 train_acc= 0.54510 val_roc= 0.81313 val_ap= 0.84283 time= 0.29822\n",
            "Epoch: 0142 train_loss= 0.41620 train_acc= 0.54529 val_roc= 0.81330 val_ap= 0.84303 time= 0.30504\n",
            "Epoch: 0143 train_loss= 0.41610 train_acc= 0.54547 val_roc= 0.81329 val_ap= 0.84300 time= 0.29760\n",
            "Epoch: 0144 train_loss= 0.41599 train_acc= 0.54563 val_roc= 0.81345 val_ap= 0.84319 time= 0.31061\n",
            "Epoch: 0145 train_loss= 0.41589 train_acc= 0.54584 val_roc= 0.81344 val_ap= 0.84323 time= 0.30625\n",
            "Epoch: 0146 train_loss= 0.41580 train_acc= 0.54600 val_roc= 0.81353 val_ap= 0.84325 time= 0.30075\n",
            "Epoch: 0147 train_loss= 0.41571 train_acc= 0.54618 val_roc= 0.81355 val_ap= 0.84324 time= 0.29614\n",
            "Epoch: 0148 train_loss= 0.41561 train_acc= 0.54631 val_roc= 0.81355 val_ap= 0.84322 time= 0.30191\n",
            "Epoch: 0149 train_loss= 0.41553 train_acc= 0.54650 val_roc= 0.81353 val_ap= 0.84321 time= 0.30135\n",
            "Epoch: 0150 train_loss= 0.41544 train_acc= 0.54662 val_roc= 0.81346 val_ap= 0.84312 time= 0.29860\n",
            "Epoch: 0151 train_loss= 0.41536 train_acc= 0.54678 val_roc= 0.81345 val_ap= 0.84325 time= 0.30190\n",
            "Epoch: 0152 train_loss= 0.41528 train_acc= 0.54694 val_roc= 0.81347 val_ap= 0.84327 time= 0.30335\n",
            "Epoch: 0153 train_loss= 0.41519 train_acc= 0.54711 val_roc= 0.81348 val_ap= 0.84333 time= 0.29808\n",
            "Epoch: 0154 train_loss= 0.41512 train_acc= 0.54727 val_roc= 0.81359 val_ap= 0.84335 time= 0.30467\n",
            "Epoch: 0155 train_loss= 0.41504 train_acc= 0.54747 val_roc= 0.81362 val_ap= 0.84341 time= 0.30626\n",
            "Epoch: 0156 train_loss= 0.41496 train_acc= 0.54760 val_roc= 0.81373 val_ap= 0.84345 time= 0.29491\n",
            "Epoch: 0157 train_loss= 0.41489 train_acc= 0.54781 val_roc= 0.81383 val_ap= 0.84352 time= 0.29588\n",
            "Epoch: 0158 train_loss= 0.41481 train_acc= 0.54796 val_roc= 0.81387 val_ap= 0.84351 time= 0.30529\n",
            "Epoch: 0159 train_loss= 0.41474 train_acc= 0.54813 val_roc= 0.81394 val_ap= 0.84354 time= 0.29743\n",
            "Epoch: 0160 train_loss= 0.41467 train_acc= 0.54830 val_roc= 0.81405 val_ap= 0.84361 time= 0.30222\n",
            "Epoch: 0161 train_loss= 0.41460 train_acc= 0.54848 val_roc= 0.81409 val_ap= 0.84366 time= 0.30179\n",
            "Epoch: 0162 train_loss= 0.41453 train_acc= 0.54865 val_roc= 0.81408 val_ap= 0.84364 time= 0.30322\n",
            "Epoch: 0163 train_loss= 0.41446 train_acc= 0.54882 val_roc= 0.81402 val_ap= 0.84360 time= 0.30052\n",
            "Epoch: 0164 train_loss= 0.41440 train_acc= 0.54896 val_roc= 0.81404 val_ap= 0.84359 time= 0.29680\n",
            "Epoch: 0165 train_loss= 0.41433 train_acc= 0.54908 val_roc= 0.81403 val_ap= 0.84359 time= 0.30433\n",
            "Epoch: 0166 train_loss= 0.41427 train_acc= 0.54927 val_roc= 0.81406 val_ap= 0.84359 time= 0.29898\n",
            "Epoch: 0167 train_loss= 0.41421 train_acc= 0.54944 val_roc= 0.81410 val_ap= 0.84358 time= 0.29508\n",
            "Epoch: 0168 train_loss= 0.41415 train_acc= 0.54962 val_roc= 0.81426 val_ap= 0.84366 time= 0.30470\n",
            "Epoch: 0169 train_loss= 0.41410 train_acc= 0.54977 val_roc= 0.81429 val_ap= 0.84369 time= 0.29968\n",
            "Epoch: 0170 train_loss= 0.41404 train_acc= 0.54991 val_roc= 0.81432 val_ap= 0.84377 time= 0.29792\n",
            "Epoch: 0171 train_loss= 0.41399 train_acc= 0.55003 val_roc= 0.81431 val_ap= 0.84377 time= 0.31362\n",
            "Epoch: 0172 train_loss= 0.41394 train_acc= 0.55018 val_roc= 0.81447 val_ap= 0.84389 time= 0.30240\n",
            "Epoch: 0173 train_loss= 0.41389 train_acc= 0.55033 val_roc= 0.81443 val_ap= 0.84385 time= 0.29788\n",
            "Epoch: 0174 train_loss= 0.41385 train_acc= 0.55049 val_roc= 0.81441 val_ap= 0.84381 time= 0.29665\n",
            "Epoch: 0175 train_loss= 0.41381 train_acc= 0.55056 val_roc= 0.81451 val_ap= 0.84394 time= 0.31786\n",
            "Epoch: 0176 train_loss= 0.41377 train_acc= 0.55071 val_roc= 0.81443 val_ap= 0.84389 time= 0.30167\n",
            "Epoch: 0177 train_loss= 0.41373 train_acc= 0.55084 val_roc= 0.81448 val_ap= 0.84392 time= 0.29817\n",
            "Epoch: 0178 train_loss= 0.41369 train_acc= 0.55098 val_roc= 0.81451 val_ap= 0.84395 time= 0.32771\n",
            "Epoch: 0179 train_loss= 0.41366 train_acc= 0.55110 val_roc= 0.81442 val_ap= 0.84386 time= 0.29921\n",
            "Epoch: 0180 train_loss= 0.41362 train_acc= 0.55123 val_roc= 0.81435 val_ap= 0.84385 time= 0.31279\n",
            "Epoch: 0181 train_loss= 0.41359 train_acc= 0.55136 val_roc= 0.81429 val_ap= 0.84384 time= 0.29709\n",
            "Epoch: 0182 train_loss= 0.41356 train_acc= 0.55148 val_roc= 0.81431 val_ap= 0.84384 time= 0.31021\n",
            "Epoch: 0183 train_loss= 0.41354 train_acc= 0.55161 val_roc= 0.81439 val_ap= 0.84389 time= 0.29555\n",
            "Epoch: 0184 train_loss= 0.41351 train_acc= 0.55176 val_roc= 0.81437 val_ap= 0.84385 time= 0.29604\n",
            "Epoch: 0185 train_loss= 0.41348 train_acc= 0.55189 val_roc= 0.81432 val_ap= 0.84380 time= 0.30563\n",
            "Epoch: 0186 train_loss= 0.41346 train_acc= 0.55201 val_roc= 0.81432 val_ap= 0.84375 time= 0.30274\n",
            "Epoch: 0187 train_loss= 0.41344 train_acc= 0.55220 val_roc= 0.81432 val_ap= 0.84374 time= 0.31860\n",
            "Epoch: 0188 train_loss= 0.41342 train_acc= 0.55234 val_roc= 0.81429 val_ap= 0.84375 time= 0.30127\n",
            "Epoch: 0189 train_loss= 0.41339 train_acc= 0.55248 val_roc= 0.81424 val_ap= 0.84366 time= 0.30605\n",
            "Epoch: 0190 train_loss= 0.41338 train_acc= 0.55260 val_roc= 0.81418 val_ap= 0.84359 time= 0.29871\n",
            "Epoch: 0191 train_loss= 0.41336 train_acc= 0.55274 val_roc= 0.81413 val_ap= 0.84356 time= 0.30049\n",
            "Epoch: 0192 train_loss= 0.41334 train_acc= 0.55288 val_roc= 0.81410 val_ap= 0.84356 time= 0.30601\n",
            "Epoch: 0193 train_loss= 0.41332 train_acc= 0.55302 val_roc= 0.81412 val_ap= 0.84358 time= 0.32775\n",
            "Epoch: 0194 train_loss= 0.41330 train_acc= 0.55317 val_roc= 0.81416 val_ap= 0.84366 time= 0.31512\n",
            "Epoch: 0195 train_loss= 0.41329 train_acc= 0.55339 val_roc= 0.81415 val_ap= 0.84363 time= 0.31153\n",
            "Epoch: 0196 train_loss= 0.41327 train_acc= 0.55356 val_roc= 0.81421 val_ap= 0.84366 time= 0.29535\n",
            "Epoch: 0197 train_loss= 0.41326 train_acc= 0.55371 val_roc= 0.81423 val_ap= 0.84367 time= 0.29667\n",
            "Epoch: 0198 train_loss= 0.41324 train_acc= 0.55385 val_roc= 0.81421 val_ap= 0.84365 time= 0.30313\n",
            "Epoch: 0199 train_loss= 0.41323 train_acc= 0.55397 val_roc= 0.81426 val_ap= 0.84370 time= 0.29846\n",
            "Epoch: 0200 train_loss= 0.41321 train_acc= 0.55409 val_roc= 0.81434 val_ap= 0.84378 time= 0.29912\n",
            "Epoch: 0201 train_loss= 0.41320 train_acc= 0.55424 val_roc= 0.81436 val_ap= 0.84380 time= 0.29688\n",
            "Epoch: 0202 train_loss= 0.41318 train_acc= 0.55441 val_roc= 0.81433 val_ap= 0.84372 time= 0.30332\n",
            "Epoch: 0203 train_loss= 0.41317 train_acc= 0.55455 val_roc= 0.81430 val_ap= 0.84371 time= 0.29962\n",
            "Epoch: 0204 train_loss= 0.41316 train_acc= 0.55470 val_roc= 0.81432 val_ap= 0.84373 time= 0.29867\n",
            "Epoch: 0205 train_loss= 0.41314 train_acc= 0.55486 val_roc= 0.81433 val_ap= 0.84375 time= 0.31451\n",
            "Epoch: 0206 train_loss= 0.41313 train_acc= 0.55504 val_roc= 0.81432 val_ap= 0.84377 time= 0.29594\n",
            "Epoch: 0207 train_loss= 0.41312 train_acc= 0.55520 val_roc= 0.81430 val_ap= 0.84373 time= 0.30404\n",
            "Epoch: 0208 train_loss= 0.41311 train_acc= 0.55535 val_roc= 0.81432 val_ap= 0.84376 time= 0.31029\n",
            "Epoch: 0209 train_loss= 0.41309 train_acc= 0.55551 val_roc= 0.81428 val_ap= 0.84375 time= 0.30831\n",
            "Epoch: 0210 train_loss= 0.41308 train_acc= 0.55564 val_roc= 0.81426 val_ap= 0.84373 time= 0.32265\n",
            "Epoch: 0211 train_loss= 0.41307 train_acc= 0.55582 val_roc= 0.81425 val_ap= 0.84374 time= 0.32118\n",
            "Epoch: 0212 train_loss= 0.41305 train_acc= 0.55599 val_roc= 0.81423 val_ap= 0.84376 time= 0.29431\n",
            "Epoch: 0213 train_loss= 0.41304 train_acc= 0.55614 val_roc= 0.81425 val_ap= 0.84376 time= 0.29865\n",
            "Epoch: 0214 train_loss= 0.41303 train_acc= 0.55631 val_roc= 0.81417 val_ap= 0.84371 time= 0.29491\n",
            "Epoch: 0215 train_loss= 0.41302 train_acc= 0.55650 val_roc= 0.81423 val_ap= 0.84375 time= 0.30710\n",
            "Epoch: 0216 train_loss= 0.41301 train_acc= 0.55666 val_roc= 0.81426 val_ap= 0.84380 time= 0.31889\n",
            "Epoch: 0217 train_loss= 0.41300 train_acc= 0.55684 val_roc= 0.81425 val_ap= 0.84376 time= 0.30413\n",
            "Epoch: 0218 train_loss= 0.41298 train_acc= 0.55704 val_roc= 0.81420 val_ap= 0.84374 time= 0.31711\n",
            "Epoch: 0219 train_loss= 0.41297 train_acc= 0.55721 val_roc= 0.81424 val_ap= 0.84377 time= 0.33264\n",
            "Epoch: 0220 train_loss= 0.41296 train_acc= 0.55742 val_roc= 0.81440 val_ap= 0.84390 time= 0.32222\n",
            "Epoch: 0221 train_loss= 0.41295 train_acc= 0.55762 val_roc= 0.81444 val_ap= 0.84395 time= 0.31417\n",
            "Epoch: 0222 train_loss= 0.41294 train_acc= 0.55781 val_roc= 0.81438 val_ap= 0.84391 time= 0.30141\n",
            "Epoch: 0223 train_loss= 0.41292 train_acc= 0.55799 val_roc= 0.81437 val_ap= 0.84392 time= 0.32551\n",
            "Epoch: 0224 train_loss= 0.41291 train_acc= 0.55817 val_roc= 0.81440 val_ap= 0.84394 time= 0.32645\n",
            "Epoch: 0225 train_loss= 0.41290 train_acc= 0.55839 val_roc= 0.81445 val_ap= 0.84398 time= 0.29536\n",
            "Epoch: 0226 train_loss= 0.41289 train_acc= 0.55858 val_roc= 0.81442 val_ap= 0.84394 time= 0.29801\n",
            "Epoch: 0227 train_loss= 0.41288 train_acc= 0.55878 val_roc= 0.81439 val_ap= 0.84394 time= 0.29821\n",
            "Epoch: 0228 train_loss= 0.41287 train_acc= 0.55899 val_roc= 0.81444 val_ap= 0.84403 time= 0.30179\n",
            "Epoch: 0229 train_loss= 0.41286 train_acc= 0.55915 val_roc= 0.81446 val_ap= 0.84401 time= 0.30342\n",
            "Epoch: 0230 train_loss= 0.41285 train_acc= 0.55938 val_roc= 0.81444 val_ap= 0.84401 time= 0.29727\n",
            "Epoch: 0231 train_loss= 0.41283 train_acc= 0.55955 val_roc= 0.81440 val_ap= 0.84398 time= 0.29972\n",
            "Epoch: 0232 train_loss= 0.41282 train_acc= 0.55976 val_roc= 0.81436 val_ap= 0.84399 time= 0.29573\n",
            "Epoch: 0233 train_loss= 0.41281 train_acc= 0.55994 val_roc= 0.81432 val_ap= 0.84396 time= 0.32365\n",
            "Epoch: 0234 train_loss= 0.41280 train_acc= 0.56015 val_roc= 0.81432 val_ap= 0.84401 time= 0.30267\n",
            "Epoch: 0235 train_loss= 0.41279 train_acc= 0.56033 val_roc= 0.81426 val_ap= 0.84395 time= 0.30395\n",
            "Epoch: 0236 train_loss= 0.41278 train_acc= 0.56055 val_roc= 0.81433 val_ap= 0.84402 time= 0.29433\n",
            "Epoch: 0237 train_loss= 0.41277 train_acc= 0.56076 val_roc= 0.81429 val_ap= 0.84394 time= 0.29926\n",
            "Epoch: 0238 train_loss= 0.41276 train_acc= 0.56096 val_roc= 0.81430 val_ap= 0.84396 time= 0.30151\n",
            "Epoch: 0239 train_loss= 0.41275 train_acc= 0.56114 val_roc= 0.81423 val_ap= 0.84390 time= 0.29702\n",
            "Epoch: 0240 train_loss= 0.41273 train_acc= 0.56137 val_roc= 0.81425 val_ap= 0.84393 time= 0.29776\n",
            "Epoch: 0241 train_loss= 0.41272 train_acc= 0.56157 val_roc= 0.81426 val_ap= 0.84395 time= 0.31256\n",
            "Epoch: 0242 train_loss= 0.41271 train_acc= 0.56176 val_roc= 0.81426 val_ap= 0.84395 time= 0.29576\n",
            "Epoch: 0243 train_loss= 0.41270 train_acc= 0.56198 val_roc= 0.81425 val_ap= 0.84389 time= 0.31240\n",
            "Epoch: 0244 train_loss= 0.41269 train_acc= 0.56220 val_roc= 0.81422 val_ap= 0.84387 time= 0.29601\n",
            "Epoch: 0245 train_loss= 0.41268 train_acc= 0.56241 val_roc= 0.81425 val_ap= 0.84391 time= 0.33242\n",
            "Epoch: 0246 train_loss= 0.41267 train_acc= 0.56265 val_roc= 0.81426 val_ap= 0.84392 time= 0.31277\n",
            "Epoch: 0247 train_loss= 0.41266 train_acc= 0.56287 val_roc= 0.81430 val_ap= 0.84395 time= 0.29682\n",
            "Epoch: 0248 train_loss= 0.41265 train_acc= 0.56313 val_roc= 0.81425 val_ap= 0.84392 time= 0.32839\n",
            "Epoch: 0249 train_loss= 0.41264 train_acc= 0.56335 val_roc= 0.81422 val_ap= 0.84390 time= 0.31865\n",
            "Epoch: 0250 train_loss= 0.41263 train_acc= 0.56354 val_roc= 0.81433 val_ap= 0.84400 time= 0.29839\n",
            "Epoch: 0251 train_loss= 0.41261 train_acc= 0.56376 val_roc= 0.81438 val_ap= 0.84404 time= 0.31563\n",
            "Epoch: 0252 train_loss= 0.41260 train_acc= 0.56401 val_roc= 0.81440 val_ap= 0.84404 time= 0.32589\n",
            "Epoch: 0253 train_loss= 0.41259 train_acc= 0.56424 val_roc= 0.81445 val_ap= 0.84406 time= 0.30768\n",
            "Epoch: 0254 train_loss= 0.41258 train_acc= 0.56446 val_roc= 0.81446 val_ap= 0.84403 time= 0.30148\n",
            "Epoch: 0255 train_loss= 0.41257 train_acc= 0.56470 val_roc= 0.81444 val_ap= 0.84406 time= 0.32225\n",
            "Epoch: 0256 train_loss= 0.41256 train_acc= 0.56495 val_roc= 0.81438 val_ap= 0.84399 time= 0.31207\n",
            "Epoch: 0257 train_loss= 0.41255 train_acc= 0.56520 val_roc= 0.81438 val_ap= 0.84402 time= 0.30360\n",
            "Epoch: 0258 train_loss= 0.41254 train_acc= 0.56545 val_roc= 0.81435 val_ap= 0.84400 time= 0.31711\n",
            "Epoch: 0259 train_loss= 0.41253 train_acc= 0.56568 val_roc= 0.81432 val_ap= 0.84399 time= 0.33435\n",
            "Epoch: 0260 train_loss= 0.41252 train_acc= 0.56591 val_roc= 0.81430 val_ap= 0.84397 time= 0.29598\n",
            "Epoch: 0261 train_loss= 0.41250 train_acc= 0.56616 val_roc= 0.81432 val_ap= 0.84393 time= 0.31760\n",
            "Epoch: 0262 train_loss= 0.41249 train_acc= 0.56640 val_roc= 0.81427 val_ap= 0.84388 time= 0.29793\n",
            "Epoch: 0263 train_loss= 0.41248 train_acc= 0.56666 val_roc= 0.81429 val_ap= 0.84383 time= 0.30265\n",
            "Epoch: 0264 train_loss= 0.41247 train_acc= 0.56693 val_roc= 0.81420 val_ap= 0.84377 time= 0.29998\n",
            "Epoch: 0265 train_loss= 0.41246 train_acc= 0.56716 val_roc= 0.81413 val_ap= 0.84366 time= 0.30058\n",
            "Epoch: 0266 train_loss= 0.41245 train_acc= 0.56738 val_roc= 0.81410 val_ap= 0.84360 time= 0.30356\n",
            "Epoch: 0267 train_loss= 0.41244 train_acc= 0.56765 val_roc= 0.81410 val_ap= 0.84358 time= 0.30357\n",
            "Epoch: 0268 train_loss= 0.41243 train_acc= 0.56788 val_roc= 0.81413 val_ap= 0.84363 time= 0.31221\n",
            "Epoch: 0269 train_loss= 0.41242 train_acc= 0.56814 val_roc= 0.81407 val_ap= 0.84360 time= 0.29480\n",
            "Epoch: 0270 train_loss= 0.41240 train_acc= 0.56841 val_roc= 0.81401 val_ap= 0.84352 time= 0.30430\n",
            "Epoch: 0271 train_loss= 0.41239 train_acc= 0.56865 val_roc= 0.81406 val_ap= 0.84352 time= 0.32040\n",
            "Epoch: 0272 train_loss= 0.41238 train_acc= 0.56893 val_roc= 0.81407 val_ap= 0.84355 time= 0.29550\n",
            "Epoch: 0273 train_loss= 0.41237 train_acc= 0.56923 val_roc= 0.81407 val_ap= 0.84355 time= 0.30194\n",
            "Epoch: 0274 train_loss= 0.41236 train_acc= 0.56951 val_roc= 0.81397 val_ap= 0.84350 time= 0.29967\n",
            "Epoch: 0275 train_loss= 0.41235 train_acc= 0.56979 val_roc= 0.81389 val_ap= 0.84345 time= 0.29911\n",
            "Epoch: 0276 train_loss= 0.41234 train_acc= 0.57010 val_roc= 0.81385 val_ap= 0.84345 time= 0.29417\n",
            "Epoch: 0277 train_loss= 0.41233 train_acc= 0.57039 val_roc= 0.81387 val_ap= 0.84349 time= 0.30247\n",
            "Epoch: 0278 train_loss= 0.41231 train_acc= 0.57066 val_roc= 0.81384 val_ap= 0.84348 time= 0.30027\n",
            "Epoch: 0279 train_loss= 0.41230 train_acc= 0.57094 val_roc= 0.81383 val_ap= 0.84350 time= 0.29605\n",
            "Epoch: 0280 train_loss= 0.41229 train_acc= 0.57121 val_roc= 0.81371 val_ap= 0.84337 time= 0.30038\n",
            "Epoch: 0281 train_loss= 0.41228 train_acc= 0.57148 val_roc= 0.81374 val_ap= 0.84336 time= 0.31464\n",
            "Epoch: 0282 train_loss= 0.41227 train_acc= 0.57177 val_roc= 0.81372 val_ap= 0.84333 time= 0.29642\n",
            "Epoch: 0283 train_loss= 0.41226 train_acc= 0.57207 val_roc= 0.81365 val_ap= 0.84328 time= 0.29996\n",
            "Epoch: 0284 train_loss= 0.41225 train_acc= 0.57233 val_roc= 0.81360 val_ap= 0.84316 time= 0.29873\n",
            "Epoch: 0285 train_loss= 0.41223 train_acc= 0.57262 val_roc= 0.81358 val_ap= 0.84314 time= 0.29650\n",
            "Epoch: 0286 train_loss= 0.41222 train_acc= 0.57287 val_roc= 0.81358 val_ap= 0.84317 time= 0.29537\n",
            "Epoch: 0287 train_loss= 0.41221 train_acc= 0.57316 val_roc= 0.81354 val_ap= 0.84312 time= 0.30345\n",
            "Epoch: 0288 train_loss= 0.41220 train_acc= 0.57348 val_roc= 0.81354 val_ap= 0.84310 time= 0.29559\n",
            "Epoch: 0289 train_loss= 0.41219 train_acc= 0.57378 val_roc= 0.81350 val_ap= 0.84307 time= 0.29867\n",
            "Epoch: 0290 train_loss= 0.41218 train_acc= 0.57404 val_roc= 0.81342 val_ap= 0.84296 time= 0.30325\n",
            "Epoch: 0291 train_loss= 0.41216 train_acc= 0.57431 val_roc= 0.81340 val_ap= 0.84291 time= 0.30349\n",
            "Epoch: 0292 train_loss= 0.41215 train_acc= 0.57462 val_roc= 0.81343 val_ap= 0.84292 time= 0.30005\n",
            "Epoch: 0293 train_loss= 0.41214 train_acc= 0.57492 val_roc= 0.81338 val_ap= 0.84288 time= 0.30212\n",
            "Epoch: 0294 train_loss= 0.41213 train_acc= 0.57521 val_roc= 0.81333 val_ap= 0.84280 time= 0.29766\n",
            "Epoch: 0295 train_loss= 0.41212 train_acc= 0.57551 val_roc= 0.81329 val_ap= 0.84276 time= 0.31203\n",
            "Epoch: 0296 train_loss= 0.41210 train_acc= 0.57583 val_roc= 0.81327 val_ap= 0.84275 time= 0.31384\n",
            "Epoch: 0297 train_loss= 0.41209 train_acc= 0.57614 val_roc= 0.81327 val_ap= 0.84277 time= 0.30735\n",
            "Epoch: 0298 train_loss= 0.41208 train_acc= 0.57641 val_roc= 0.81329 val_ap= 0.84275 time= 0.29689\n",
            "Epoch: 0299 train_loss= 0.41207 train_acc= 0.57670 val_roc= 0.81322 val_ap= 0.84269 time= 0.29972\n",
            "Epoch: 0300 train_loss= 0.41206 train_acc= 0.57700 val_roc= 0.81320 val_ap= 0.84273 time= 0.29805\n",
            "Epoch: 0301 train_loss= 0.41205 train_acc= 0.57731 val_roc= 0.81314 val_ap= 0.84267 time= 0.30300\n",
            "Epoch: 0302 train_loss= 0.41203 train_acc= 0.57760 val_roc= 0.81312 val_ap= 0.84264 time= 0.29678\n",
            "Epoch: 0303 train_loss= 0.41202 train_acc= 0.57790 val_roc= 0.81312 val_ap= 0.84264 time= 0.29798\n",
            "Epoch: 0304 train_loss= 0.41201 train_acc= 0.57827 val_roc= 0.81308 val_ap= 0.84256 time= 0.33887\n",
            "Epoch: 0305 train_loss= 0.41200 train_acc= 0.57862 val_roc= 0.81301 val_ap= 0.84248 time= 0.32131\n",
            "Epoch: 0306 train_loss= 0.41198 train_acc= 0.57894 val_roc= 0.81300 val_ap= 0.84248 time= 0.29506\n",
            "Epoch: 0307 train_loss= 0.41197 train_acc= 0.57928 val_roc= 0.81302 val_ap= 0.84249 time= 0.30680\n",
            "Epoch: 0308 train_loss= 0.41196 train_acc= 0.57963 val_roc= 0.81303 val_ap= 0.84248 time= 0.29661\n",
            "Epoch: 0309 train_loss= 0.41195 train_acc= 0.57995 val_roc= 0.81299 val_ap= 0.84246 time= 0.29897\n",
            "Epoch: 0310 train_loss= 0.41194 train_acc= 0.58027 val_roc= 0.81295 val_ap= 0.84238 time= 0.29683\n",
            "Epoch: 0311 train_loss= 0.41192 train_acc= 0.58061 val_roc= 0.81289 val_ap= 0.84232 time= 0.30682\n",
            "Epoch: 0312 train_loss= 0.41191 train_acc= 0.58097 val_roc= 0.81283 val_ap= 0.84230 time= 0.29935\n",
            "Epoch: 0313 train_loss= 0.41190 train_acc= 0.58133 val_roc= 0.81283 val_ap= 0.84237 time= 0.30998\n",
            "Epoch: 0314 train_loss= 0.41189 train_acc= 0.58167 val_roc= 0.81274 val_ap= 0.84237 time= 0.30524\n",
            "Epoch: 0315 train_loss= 0.41187 train_acc= 0.58200 val_roc= 0.81270 val_ap= 0.84234 time= 0.29983\n",
            "Epoch: 0316 train_loss= 0.41186 train_acc= 0.58234 val_roc= 0.81263 val_ap= 0.84228 time= 0.29824\n",
            "Epoch: 0317 train_loss= 0.41185 train_acc= 0.58269 val_roc= 0.81259 val_ap= 0.84225 time= 0.29973\n",
            "Epoch: 0318 train_loss= 0.41183 train_acc= 0.58301 val_roc= 0.81255 val_ap= 0.84223 time= 0.29958\n",
            "Epoch: 0319 train_loss= 0.41182 train_acc= 0.58334 val_roc= 0.81253 val_ap= 0.84225 time= 0.30310\n",
            "Epoch: 0320 train_loss= 0.41181 train_acc= 0.58367 val_roc= 0.81243 val_ap= 0.84212 time= 0.29687\n",
            "Epoch: 0321 train_loss= 0.41180 train_acc= 0.58403 val_roc= 0.81233 val_ap= 0.84199 time= 0.30982\n",
            "Epoch: 0322 train_loss= 0.41178 train_acc= 0.58437 val_roc= 0.81229 val_ap= 0.84191 time= 0.30221\n",
            "Epoch: 0323 train_loss= 0.41177 train_acc= 0.58472 val_roc= 0.81221 val_ap= 0.84183 time= 0.30477\n",
            "Epoch: 0324 train_loss= 0.41176 train_acc= 0.58511 val_roc= 0.81216 val_ap= 0.84174 time= 0.30237\n",
            "Epoch: 0325 train_loss= 0.41175 train_acc= 0.58548 val_roc= 0.81211 val_ap= 0.84174 time= 0.30106\n",
            "Epoch: 0326 train_loss= 0.41173 train_acc= 0.58583 val_roc= 0.81208 val_ap= 0.84174 time= 0.31065\n",
            "Epoch: 0327 train_loss= 0.41172 train_acc= 0.58615 val_roc= 0.81196 val_ap= 0.84167 time= 0.30941\n",
            "Epoch: 0328 train_loss= 0.41171 train_acc= 0.58649 val_roc= 0.81192 val_ap= 0.84161 time= 0.30802\n",
            "Epoch: 0329 train_loss= 0.41169 train_acc= 0.58687 val_roc= 0.81187 val_ap= 0.84157 time= 0.29663\n",
            "Epoch: 0330 train_loss= 0.41168 train_acc= 0.58725 val_roc= 0.81172 val_ap= 0.84144 time= 0.29898\n",
            "Epoch: 0331 train_loss= 0.41167 train_acc= 0.58760 val_roc= 0.81173 val_ap= 0.84145 time= 0.30434\n",
            "Epoch: 0332 train_loss= 0.41165 train_acc= 0.58797 val_roc= 0.81159 val_ap= 0.84134 time= 0.29469\n",
            "Epoch: 0333 train_loss= 0.41164 train_acc= 0.58834 val_roc= 0.81154 val_ap= 0.84132 time= 0.30177\n",
            "Epoch: 0334 train_loss= 0.41163 train_acc= 0.58875 val_roc= 0.81144 val_ap= 0.84123 time= 0.30156\n",
            "Epoch: 0335 train_loss= 0.41162 train_acc= 0.58914 val_roc= 0.81134 val_ap= 0.84116 time= 0.29777\n",
            "Epoch: 0336 train_loss= 0.41160 train_acc= 0.58956 val_roc= 0.81119 val_ap= 0.84104 time= 0.30685\n",
            "Epoch: 0337 train_loss= 0.41159 train_acc= 0.58996 val_roc= 0.81104 val_ap= 0.84090 time= 0.30332\n",
            "Epoch: 0338 train_loss= 0.41158 train_acc= 0.59036 val_roc= 0.81091 val_ap= 0.84077 time= 0.29999\n",
            "Epoch: 0339 train_loss= 0.41156 train_acc= 0.59073 val_roc= 0.81080 val_ap= 0.84058 time= 0.29980\n",
            "Epoch: 0340 train_loss= 0.41155 train_acc= 0.59113 val_roc= 0.81064 val_ap= 0.84044 time= 0.30833\n",
            "Epoch: 0341 train_loss= 0.41153 train_acc= 0.59155 val_roc= 0.81054 val_ap= 0.84032 time= 0.30353\n",
            "Epoch: 0342 train_loss= 0.41152 train_acc= 0.59196 val_roc= 0.81049 val_ap= 0.84030 time= 0.30952\n",
            "Epoch: 0343 train_loss= 0.41151 train_acc= 0.59234 val_roc= 0.81038 val_ap= 0.84015 time= 0.29983\n",
            "Epoch: 0344 train_loss= 0.41149 train_acc= 0.59273 val_roc= 0.81029 val_ap= 0.84009 time= 0.30386\n",
            "Epoch: 0345 train_loss= 0.41148 train_acc= 0.59314 val_roc= 0.81017 val_ap= 0.83993 time= 0.30349\n",
            "Epoch: 0346 train_loss= 0.41147 train_acc= 0.59354 val_roc= 0.81013 val_ap= 0.83984 time= 0.30108\n",
            "Epoch: 0347 train_loss= 0.41145 train_acc= 0.59392 val_roc= 0.81003 val_ap= 0.83972 time= 0.30470\n",
            "Epoch: 0348 train_loss= 0.41144 train_acc= 0.59436 val_roc= 0.80998 val_ap= 0.83966 time= 0.29698\n",
            "Epoch: 0349 train_loss= 0.41142 train_acc= 0.59475 val_roc= 0.80985 val_ap= 0.83955 time= 0.31028\n",
            "Epoch: 0350 train_loss= 0.41141 train_acc= 0.59515 val_roc= 0.80973 val_ap= 0.83946 time= 0.29507\n",
            "Epoch: 0351 train_loss= 0.41140 train_acc= 0.59555 val_roc= 0.80961 val_ap= 0.83936 time= 0.30471\n",
            "Epoch: 0352 train_loss= 0.41138 train_acc= 0.59598 val_roc= 0.80946 val_ap= 0.83925 time= 0.30182\n",
            "Epoch: 0353 train_loss= 0.41137 train_acc= 0.59638 val_roc= 0.80929 val_ap= 0.83914 time= 0.29823\n",
            "Epoch: 0354 train_loss= 0.41135 train_acc= 0.59681 val_roc= 0.80916 val_ap= 0.83899 time= 0.30263\n",
            "Epoch: 0355 train_loss= 0.41134 train_acc= 0.59723 val_roc= 0.80904 val_ap= 0.83890 time= 0.29908\n",
            "Epoch: 0356 train_loss= 0.41133 train_acc= 0.59763 val_roc= 0.80889 val_ap= 0.83877 time= 0.29479\n",
            "Epoch: 0357 train_loss= 0.41131 train_acc= 0.59802 val_roc= 0.80872 val_ap= 0.83856 time= 0.29940\n",
            "Epoch: 0358 train_loss= 0.41130 train_acc= 0.59842 val_roc= 0.80863 val_ap= 0.83847 time= 0.30737\n",
            "Epoch: 0359 train_loss= 0.41128 train_acc= 0.59889 val_roc= 0.80846 val_ap= 0.83832 time= 0.29854\n",
            "Epoch: 0360 train_loss= 0.41127 train_acc= 0.59931 val_roc= 0.80840 val_ap= 0.83820 time= 0.29844\n",
            "Epoch: 0361 train_loss= 0.41126 train_acc= 0.59971 val_roc= 0.80825 val_ap= 0.83808 time= 0.30397\n",
            "Epoch: 0362 train_loss= 0.41124 train_acc= 0.60015 val_roc= 0.80817 val_ap= 0.83798 time= 0.30089\n",
            "Epoch: 0363 train_loss= 0.41123 train_acc= 0.60062 val_roc= 0.80806 val_ap= 0.83787 time= 0.29464\n",
            "Epoch: 0364 train_loss= 0.41121 train_acc= 0.60105 val_roc= 0.80795 val_ap= 0.83778 time= 0.30082\n",
            "Epoch: 0365 train_loss= 0.41120 train_acc= 0.60147 val_roc= 0.80782 val_ap= 0.83768 time= 0.29813\n",
            "Epoch: 0366 train_loss= 0.41118 train_acc= 0.60193 val_roc= 0.80763 val_ap= 0.83750 time= 0.31678\n",
            "Epoch: 0367 train_loss= 0.41117 train_acc= 0.60235 val_roc= 0.80737 val_ap= 0.83728 time= 0.30105\n",
            "Epoch: 0368 train_loss= 0.41115 train_acc= 0.60280 val_roc= 0.80731 val_ap= 0.83720 time= 0.30251\n",
            "Epoch: 0369 train_loss= 0.41114 train_acc= 0.60329 val_roc= 0.80725 val_ap= 0.83712 time= 0.30171\n",
            "Epoch: 0370 train_loss= 0.41112 train_acc= 0.60372 val_roc= 0.80727 val_ap= 0.83711 time= 0.29521\n",
            "Epoch: 0371 train_loss= 0.41111 train_acc= 0.60417 val_roc= 0.80713 val_ap= 0.83696 time= 0.30176\n",
            "Epoch: 0372 train_loss= 0.41109 train_acc= 0.60464 val_roc= 0.80709 val_ap= 0.83687 time= 0.29815\n",
            "Epoch: 0373 train_loss= 0.41108 train_acc= 0.60507 val_roc= 0.80692 val_ap= 0.83671 time= 0.29869\n",
            "Epoch: 0374 train_loss= 0.41106 train_acc= 0.60557 val_roc= 0.80688 val_ap= 0.83665 time= 0.30373\n",
            "Epoch: 0375 train_loss= 0.41105 train_acc= 0.60605 val_roc= 0.80681 val_ap= 0.83650 time= 0.30082\n",
            "Epoch: 0376 train_loss= 0.41103 train_acc= 0.60650 val_roc= 0.80670 val_ap= 0.83640 time= 0.29860\n",
            "Epoch: 0377 train_loss= 0.41102 train_acc= 0.60697 val_roc= 0.80659 val_ap= 0.83627 time= 0.30267\n",
            "Epoch: 0378 train_loss= 0.41100 train_acc= 0.60744 val_roc= 0.80652 val_ap= 0.83620 time= 0.30267\n",
            "Epoch: 0379 train_loss= 0.41099 train_acc= 0.60791 val_roc= 0.80636 val_ap= 0.83603 time= 0.30192\n",
            "Epoch: 0380 train_loss= 0.41097 train_acc= 0.60836 val_roc= 0.80625 val_ap= 0.83593 time= 0.29732\n",
            "Epoch: 0381 train_loss= 0.41096 train_acc= 0.60879 val_roc= 0.80620 val_ap= 0.83589 time= 0.32078\n",
            "Epoch: 0382 train_loss= 0.41094 train_acc= 0.60928 val_roc= 0.80615 val_ap= 0.83582 time= 0.30057\n",
            "Epoch: 0383 train_loss= 0.41093 train_acc= 0.60975 val_roc= 0.80601 val_ap= 0.83572 time= 0.29681\n",
            "Epoch: 0384 train_loss= 0.41091 train_acc= 0.61026 val_roc= 0.80587 val_ap= 0.83563 time= 0.30453\n",
            "Epoch: 0385 train_loss= 0.41090 train_acc= 0.61073 val_roc= 0.80575 val_ap= 0.83548 time= 0.29723\n",
            "Epoch: 0386 train_loss= 0.41088 train_acc= 0.61125 val_roc= 0.80559 val_ap= 0.83533 time= 0.32324\n",
            "Epoch: 0387 train_loss= 0.41086 train_acc= 0.61176 val_roc= 0.80547 val_ap= 0.83524 time= 0.32441\n",
            "Epoch: 0388 train_loss= 0.41085 train_acc= 0.61221 val_roc= 0.80534 val_ap= 0.83506 time= 0.30925\n",
            "Epoch: 0389 train_loss= 0.41083 train_acc= 0.61268 val_roc= 0.80525 val_ap= 0.83492 time= 0.30121\n",
            "Epoch: 0390 train_loss= 0.41082 train_acc= 0.61318 val_roc= 0.80516 val_ap= 0.83482 time= 0.29509\n",
            "Epoch: 0391 train_loss= 0.41080 train_acc= 0.61365 val_roc= 0.80495 val_ap= 0.83468 time= 0.30456\n",
            "Epoch: 0392 train_loss= 0.41079 train_acc= 0.61415 val_roc= 0.80485 val_ap= 0.83461 time= 0.29689\n",
            "Epoch: 0393 train_loss= 0.41077 train_acc= 0.61461 val_roc= 0.80471 val_ap= 0.83449 time= 0.29616\n",
            "Epoch: 0394 train_loss= 0.41076 train_acc= 0.61511 val_roc= 0.80451 val_ap= 0.83433 time= 0.30626\n",
            "Epoch: 0395 train_loss= 0.41074 train_acc= 0.61560 val_roc= 0.80431 val_ap= 0.83427 time= 0.29970\n",
            "Epoch: 0396 train_loss= 0.41072 train_acc= 0.61608 val_roc= 0.80417 val_ap= 0.83418 time= 0.30711\n",
            "Epoch: 0397 train_loss= 0.41071 train_acc= 0.61655 val_roc= 0.80399 val_ap= 0.83405 time= 0.29781\n",
            "Epoch: 0398 train_loss= 0.41069 train_acc= 0.61705 val_roc= 0.80378 val_ap= 0.83389 time= 0.30472\n",
            "Epoch: 0399 train_loss= 0.41068 train_acc= 0.61756 val_roc= 0.80361 val_ap= 0.83383 time= 0.29976\n",
            "Epoch: 0400 train_loss= 0.41066 train_acc= 0.61804 val_roc= 0.80340 val_ap= 0.83362 time= 0.29555\n",
            "Epoch: 0401 train_loss= 0.41064 train_acc= 0.61852 val_roc= 0.80318 val_ap= 0.83344 time= 0.30649\n",
            "Epoch: 0402 train_loss= 0.41063 train_acc= 0.61901 val_roc= 0.80304 val_ap= 0.83331 time= 0.29594\n",
            "Epoch: 0403 train_loss= 0.41061 train_acc= 0.61950 val_roc= 0.80287 val_ap= 0.83314 time= 0.29968\n",
            "Epoch: 0404 train_loss= 0.41060 train_acc= 0.61999 val_roc= 0.80265 val_ap= 0.83290 time= 0.30202\n",
            "Epoch: 0405 train_loss= 0.41058 train_acc= 0.62049 val_roc= 0.80240 val_ap= 0.83271 time= 0.30518\n",
            "Epoch: 0406 train_loss= 0.41056 train_acc= 0.62097 val_roc= 0.80222 val_ap= 0.83261 time= 0.29766\n",
            "Epoch: 0407 train_loss= 0.41055 train_acc= 0.62146 val_roc= 0.80200 val_ap= 0.83250 time= 0.29867\n",
            "Epoch: 0408 train_loss= 0.41053 train_acc= 0.62195 val_roc= 0.80184 val_ap= 0.83236 time= 0.30555\n",
            "Epoch: 0409 train_loss= 0.41051 train_acc= 0.62246 val_roc= 0.80168 val_ap= 0.83228 time= 0.29898\n",
            "Epoch: 0410 train_loss= 0.41050 train_acc= 0.62294 val_roc= 0.80156 val_ap= 0.83217 time= 0.30253\n",
            "Epoch: 0411 train_loss= 0.41048 train_acc= 0.62345 val_roc= 0.80131 val_ap= 0.83193 time= 0.30450\n",
            "Epoch: 0412 train_loss= 0.41046 train_acc= 0.62398 val_roc= 0.80119 val_ap= 0.83178 time= 0.30050\n",
            "Epoch: 0413 train_loss= 0.41045 train_acc= 0.62449 val_roc= 0.80101 val_ap= 0.83167 time= 0.30696\n",
            "Epoch: 0414 train_loss= 0.41043 train_acc= 0.62501 val_roc= 0.80080 val_ap= 0.83151 time= 0.30207\n",
            "Epoch: 0415 train_loss= 0.41041 train_acc= 0.62554 val_roc= 0.80057 val_ap= 0.83134 time= 0.30016\n",
            "Epoch: 0416 train_loss= 0.41039 train_acc= 0.62603 val_roc= 0.80036 val_ap= 0.83119 time= 0.29608\n",
            "Epoch: 0417 train_loss= 0.41038 train_acc= 0.62656 val_roc= 0.80021 val_ap= 0.83106 time= 0.29885\n",
            "Epoch: 0418 train_loss= 0.41036 train_acc= 0.62712 val_roc= 0.80001 val_ap= 0.83095 time= 0.30423\n",
            "Epoch: 0419 train_loss= 0.41034 train_acc= 0.62760 val_roc= 0.79973 val_ap= 0.83072 time= 0.29953\n",
            "Epoch: 0420 train_loss= 0.41033 train_acc= 0.62812 val_roc= 0.79953 val_ap= 0.83053 time= 0.29956\n",
            "Epoch: 0421 train_loss= 0.41031 train_acc= 0.62865 val_roc= 0.79922 val_ap= 0.83026 time= 0.30799\n",
            "Epoch: 0422 train_loss= 0.41029 train_acc= 0.62915 val_roc= 0.79901 val_ap= 0.83006 time= 0.31454\n",
            "Epoch: 0423 train_loss= 0.41028 train_acc= 0.62965 val_roc= 0.79871 val_ap= 0.82980 time= 0.29622\n",
            "Epoch: 0424 train_loss= 0.41026 train_acc= 0.63018 val_roc= 0.79847 val_ap= 0.82958 time= 0.30689\n",
            "Epoch: 0425 train_loss= 0.41024 train_acc= 0.63074 val_roc= 0.79822 val_ap= 0.82935 time= 0.29968\n",
            "Epoch: 0426 train_loss= 0.41023 train_acc= 0.63126 val_roc= 0.79799 val_ap= 0.82916 time= 0.29919\n",
            "Epoch: 0427 train_loss= 0.41021 train_acc= 0.63182 val_roc= 0.79771 val_ap= 0.82895 time= 0.30742\n",
            "Epoch: 0428 train_loss= 0.41019 train_acc= 0.63233 val_roc= 0.79749 val_ap= 0.82879 time= 0.31645\n",
            "Epoch: 0429 train_loss= 0.41017 train_acc= 0.63285 val_roc= 0.79726 val_ap= 0.82859 time= 0.29774\n",
            "Epoch: 0430 train_loss= 0.41015 train_acc= 0.63338 val_roc= 0.79700 val_ap= 0.82849 time= 0.30177\n",
            "Epoch: 0431 train_loss= 0.41014 train_acc= 0.63393 val_roc= 0.79678 val_ap= 0.82829 time= 0.30579\n",
            "Epoch: 0432 train_loss= 0.41012 train_acc= 0.63449 val_roc= 0.79651 val_ap= 0.82809 time= 0.30137\n",
            "Epoch: 0433 train_loss= 0.41010 train_acc= 0.63506 val_roc= 0.79622 val_ap= 0.82784 time= 0.30004\n",
            "Epoch: 0434 train_loss= 0.41009 train_acc= 0.63562 val_roc= 0.79597 val_ap= 0.82762 time= 0.30893\n",
            "Epoch: 0435 train_loss= 0.41007 train_acc= 0.63615 val_roc= 0.79563 val_ap= 0.82734 time= 0.29964\n",
            "Epoch: 0436 train_loss= 0.41005 train_acc= 0.63666 val_roc= 0.79540 val_ap= 0.82719 time= 0.31958\n",
            "Epoch: 0437 train_loss= 0.41003 train_acc= 0.63722 val_roc= 0.79520 val_ap= 0.82706 time= 0.31465\n",
            "Epoch: 0438 train_loss= 0.41001 train_acc= 0.63779 val_roc= 0.79487 val_ap= 0.82680 time= 0.31619\n",
            "Epoch: 0439 train_loss= 0.40999 train_acc= 0.63832 val_roc= 0.79454 val_ap= 0.82646 time= 0.32713\n",
            "Epoch: 0440 train_loss= 0.40998 train_acc= 0.63889 val_roc= 0.79427 val_ap= 0.82623 time= 0.32054\n",
            "Epoch: 0441 train_loss= 0.40996 train_acc= 0.63944 val_roc= 0.79413 val_ap= 0.82609 time= 0.32742\n",
            "Epoch: 0442 train_loss= 0.40994 train_acc= 0.63998 val_roc= 0.79383 val_ap= 0.82589 time= 0.29526\n",
            "Epoch: 0443 train_loss= 0.40992 train_acc= 0.64057 val_roc= 0.79361 val_ap= 0.82572 time= 0.30100\n",
            "Epoch: 0444 train_loss= 0.40990 train_acc= 0.64109 val_roc= 0.79332 val_ap= 0.82549 time= 0.30430\n",
            "Epoch: 0445 train_loss= 0.40988 train_acc= 0.64165 val_roc= 0.79309 val_ap= 0.82527 time= 0.29755\n",
            "Epoch: 0446 train_loss= 0.40987 train_acc= 0.64220 val_roc= 0.79291 val_ap= 0.82511 time= 0.29940\n",
            "Epoch: 0447 train_loss= 0.40985 train_acc= 0.64274 val_roc= 0.79264 val_ap= 0.82492 time= 0.30336\n",
            "Epoch: 0448 train_loss= 0.40983 train_acc= 0.64330 val_roc= 0.79234 val_ap= 0.82465 time= 0.29945\n",
            "Epoch: 0449 train_loss= 0.40981 train_acc= 0.64387 val_roc= 0.79214 val_ap= 0.82443 time= 0.29659\n",
            "Epoch: 0450 train_loss= 0.40979 train_acc= 0.64444 val_roc= 0.79197 val_ap= 0.82432 time= 0.29483\n",
            "Epoch: 0451 train_loss= 0.40977 train_acc= 0.64504 val_roc= 0.79170 val_ap= 0.82410 time= 0.30932\n",
            "Epoch: 0452 train_loss= 0.40975 train_acc= 0.64561 val_roc= 0.79139 val_ap= 0.82391 time= 0.29688\n",
            "Epoch: 0453 train_loss= 0.40974 train_acc= 0.64617 val_roc= 0.79109 val_ap= 0.82369 time= 0.29866\n",
            "Epoch: 0454 train_loss= 0.40972 train_acc= 0.64669 val_roc= 0.79082 val_ap= 0.82342 time= 0.30643\n",
            "Epoch: 0455 train_loss= 0.40970 train_acc= 0.64725 val_roc= 0.79053 val_ap= 0.82322 time= 0.29699\n",
            "Epoch: 0456 train_loss= 0.40968 train_acc= 0.64782 val_roc= 0.79027 val_ap= 0.82302 time= 0.29989\n",
            "Epoch: 0457 train_loss= 0.40966 train_acc= 0.64840 val_roc= 0.79008 val_ap= 0.82280 time= 0.30276\n",
            "Epoch: 0458 train_loss= 0.40964 train_acc= 0.64899 val_roc= 0.78987 val_ap= 0.82262 time= 0.29687\n",
            "Epoch: 0459 train_loss= 0.40962 train_acc= 0.64956 val_roc= 0.78954 val_ap= 0.82236 time= 0.30757\n",
            "Epoch: 0460 train_loss= 0.40961 train_acc= 0.65014 val_roc= 0.78924 val_ap= 0.82216 time= 0.29701\n",
            "Epoch: 0461 train_loss= 0.40958 train_acc= 0.65074 val_roc= 0.78894 val_ap= 0.82193 time= 0.30918\n",
            "Epoch: 0462 train_loss= 0.40957 train_acc= 0.65134 val_roc= 0.78862 val_ap= 0.82168 time= 0.29569\n",
            "Epoch: 0463 train_loss= 0.40955 train_acc= 0.65192 val_roc= 0.78821 val_ap= 0.82133 time= 0.30347\n",
            "Epoch: 0464 train_loss= 0.40953 train_acc= 0.65252 val_roc= 0.78802 val_ap= 0.82112 time= 0.30228\n",
            "Epoch: 0465 train_loss= 0.40951 train_acc= 0.65310 val_roc= 0.78776 val_ap= 0.82098 time= 0.30500\n",
            "Epoch: 0466 train_loss= 0.40949 train_acc= 0.65373 val_roc= 0.78737 val_ap= 0.82064 time= 0.30317\n",
            "Epoch: 0467 train_loss= 0.40947 train_acc= 0.65436 val_roc= 0.78710 val_ap= 0.82047 time= 0.31712\n",
            "Epoch: 0468 train_loss= 0.40945 train_acc= 0.65495 val_roc= 0.78692 val_ap= 0.82029 time= 0.32146\n",
            "Epoch: 0469 train_loss= 0.40943 train_acc= 0.65550 val_roc= 0.78660 val_ap= 0.82001 time= 0.31747\n",
            "Epoch: 0470 train_loss= 0.40941 train_acc= 0.65614 val_roc= 0.78627 val_ap= 0.81972 time= 0.29819\n",
            "Epoch: 0471 train_loss= 0.40939 train_acc= 0.65674 val_roc= 0.78591 val_ap= 0.81947 time= 0.31525\n",
            "Epoch: 0472 train_loss= 0.40937 train_acc= 0.65736 val_roc= 0.78563 val_ap= 0.81927 time= 0.30122\n",
            "Epoch: 0473 train_loss= 0.40935 train_acc= 0.65797 val_roc= 0.78531 val_ap= 0.81903 time= 0.30008\n",
            "Epoch: 0474 train_loss= 0.40933 train_acc= 0.65859 val_roc= 0.78509 val_ap= 0.81890 time= 0.30528\n",
            "Epoch: 0475 train_loss= 0.40931 train_acc= 0.65923 val_roc= 0.78474 val_ap= 0.81859 time= 0.31560\n",
            "Epoch: 0476 train_loss= 0.40929 train_acc= 0.65985 val_roc= 0.78456 val_ap= 0.81844 time= 0.31162\n",
            "Epoch: 0477 train_loss= 0.40927 train_acc= 0.66044 val_roc= 0.78426 val_ap= 0.81818 time= 0.31590\n",
            "Epoch: 0478 train_loss= 0.40925 train_acc= 0.66108 val_roc= 0.78390 val_ap= 0.81782 time= 0.29409\n",
            "Epoch: 0479 train_loss= 0.40923 train_acc= 0.66168 val_roc= 0.78359 val_ap= 0.81756 time= 0.29517\n",
            "Epoch: 0480 train_loss= 0.40921 train_acc= 0.66230 val_roc= 0.78334 val_ap= 0.81730 time= 0.30064\n",
            "Epoch: 0481 train_loss= 0.40919 train_acc= 0.66291 val_roc= 0.78301 val_ap= 0.81705 time= 0.30463\n",
            "Epoch: 0482 train_loss= 0.40917 train_acc= 0.66352 val_roc= 0.78272 val_ap= 0.81679 time= 0.30021\n",
            "Epoch: 0483 train_loss= 0.40915 train_acc= 0.66416 val_roc= 0.78243 val_ap= 0.81660 time= 0.29720\n",
            "Epoch: 0484 train_loss= 0.40913 train_acc= 0.66476 val_roc= 0.78193 val_ap= 0.81616 time= 0.30110\n",
            "Epoch: 0485 train_loss= 0.40911 train_acc= 0.66536 val_roc= 0.78155 val_ap= 0.81581 time= 0.30956\n",
            "Epoch: 0486 train_loss= 0.40909 train_acc= 0.66598 val_roc= 0.78112 val_ap= 0.81544 time= 0.30724\n",
            "Epoch: 0487 train_loss= 0.40907 train_acc= 0.66663 val_roc= 0.78082 val_ap= 0.81519 time= 0.30290\n",
            "Epoch: 0488 train_loss= 0.40905 train_acc= 0.66725 val_roc= 0.78049 val_ap= 0.81496 time= 0.29499\n",
            "Epoch: 0489 train_loss= 0.40903 train_acc= 0.66789 val_roc= 0.78013 val_ap= 0.81463 time= 0.30251\n",
            "Epoch: 0490 train_loss= 0.40901 train_acc= 0.66853 val_roc= 0.77982 val_ap= 0.81439 time= 0.29746\n",
            "Epoch: 0491 train_loss= 0.40899 train_acc= 0.66917 val_roc= 0.77950 val_ap= 0.81410 time= 0.30166\n",
            "Epoch: 0492 train_loss= 0.40897 train_acc= 0.66982 val_roc= 0.77922 val_ap= 0.81388 time= 0.29824\n",
            "Epoch: 0493 train_loss= 0.40895 train_acc= 0.67045 val_roc= 0.77888 val_ap= 0.81363 time= 0.29616\n",
            "Epoch: 0494 train_loss= 0.40893 train_acc= 0.67112 val_roc= 0.77851 val_ap= 0.81332 time= 0.30435\n",
            "Epoch: 0495 train_loss= 0.40891 train_acc= 0.67175 val_roc= 0.77820 val_ap= 0.81308 time= 0.32465\n",
            "Epoch: 0496 train_loss= 0.40889 train_acc= 0.67237 val_roc= 0.77783 val_ap= 0.81277 time= 0.31601\n",
            "Epoch: 0497 train_loss= 0.40887 train_acc= 0.67302 val_roc= 0.77747 val_ap= 0.81243 time= 0.30354\n",
            "Epoch: 0498 train_loss= 0.40885 train_acc= 0.67366 val_roc= 0.77713 val_ap= 0.81218 time= 0.29709\n",
            "Epoch: 0499 train_loss= 0.40883 train_acc= 0.67436 val_roc= 0.77679 val_ap= 0.81199 time= 0.30237\n",
            "Epoch: 0500 train_loss= 0.40881 train_acc= 0.67499 val_roc= 0.77640 val_ap= 0.81163 time= 0.29777\n",
            "Epoch: 0501 train_loss= 0.40879 train_acc= 0.67566 val_roc= 0.77607 val_ap= 0.81131 time= 0.30366\n",
            "Epoch: 0502 train_loss= 0.40877 train_acc= 0.67633 val_roc= 0.77567 val_ap= 0.81097 time= 0.30745\n",
            "Epoch: 0503 train_loss= 0.40875 train_acc= 0.67700 val_roc= 0.77538 val_ap= 0.81076 time= 0.31227\n",
            "Epoch: 0504 train_loss= 0.40873 train_acc= 0.67767 val_roc= 0.77502 val_ap= 0.81048 time= 0.30569\n",
            "Epoch: 0505 train_loss= 0.40871 train_acc= 0.67834 val_roc= 0.77468 val_ap= 0.81019 time= 0.29936\n",
            "Epoch: 0506 train_loss= 0.40869 train_acc= 0.67900 val_roc= 0.77439 val_ap= 0.80990 time= 0.29798\n",
            "Epoch: 0507 train_loss= 0.40867 train_acc= 0.67965 val_roc= 0.77405 val_ap= 0.80963 time= 0.30069\n",
            "Epoch: 0508 train_loss= 0.40865 train_acc= 0.68030 val_roc= 0.77360 val_ap= 0.80933 time= 0.29556\n",
            "Epoch: 0509 train_loss= 0.40863 train_acc= 0.68095 val_roc= 0.77335 val_ap= 0.80909 time= 0.30196\n",
            "Epoch: 0510 train_loss= 0.40861 train_acc= 0.68160 val_roc= 0.77298 val_ap= 0.80883 time= 0.29603\n",
            "Epoch: 0511 train_loss= 0.40859 train_acc= 0.68226 val_roc= 0.77261 val_ap= 0.80856 time= 0.30477\n",
            "Epoch: 0512 train_loss= 0.40857 train_acc= 0.68289 val_roc= 0.77217 val_ap= 0.80811 time= 0.29507\n",
            "Epoch: 0513 train_loss= 0.40855 train_acc= 0.68355 val_roc= 0.77177 val_ap= 0.80784 time= 0.30209\n",
            "Epoch: 0514 train_loss= 0.40853 train_acc= 0.68420 val_roc= 0.77134 val_ap= 0.80752 time= 0.30346\n",
            "Epoch: 0515 train_loss= 0.40851 train_acc= 0.68487 val_roc= 0.77081 val_ap= 0.80713 time= 0.29828\n",
            "Epoch: 0516 train_loss= 0.40849 train_acc= 0.68554 val_roc= 0.77033 val_ap= 0.80685 time= 0.29600\n",
            "Epoch: 0517 train_loss= 0.40847 train_acc= 0.68623 val_roc= 0.76997 val_ap= 0.80656 time= 0.30461\n",
            "Epoch: 0518 train_loss= 0.40845 train_acc= 0.68691 val_roc= 0.76958 val_ap= 0.80625 time= 0.29348\n",
            "Epoch: 0519 train_loss= 0.40843 train_acc= 0.68758 val_roc= 0.76914 val_ap= 0.80595 time= 0.30057\n",
            "Epoch: 0520 train_loss= 0.40841 train_acc= 0.68827 val_roc= 0.76878 val_ap= 0.80563 time= 0.30221\n",
            "Epoch: 0521 train_loss= 0.40839 train_acc= 0.68893 val_roc= 0.76832 val_ap= 0.80532 time= 0.31504\n",
            "Epoch: 0522 train_loss= 0.40837 train_acc= 0.68960 val_roc= 0.76796 val_ap= 0.80507 time= 0.29769\n",
            "Epoch: 0523 train_loss= 0.40834 train_acc= 0.69030 val_roc= 0.76751 val_ap= 0.80472 time= 0.29858\n",
            "Epoch: 0524 train_loss= 0.40832 train_acc= 0.69096 val_roc= 0.76716 val_ap= 0.80441 time= 0.31591\n",
            "Epoch: 0525 train_loss= 0.40830 train_acc= 0.69168 val_roc= 0.76677 val_ap= 0.80423 time= 0.31996\n",
            "Epoch: 0526 train_loss= 0.40828 train_acc= 0.69238 val_roc= 0.76637 val_ap= 0.80393 time= 0.30666\n",
            "Epoch: 0527 train_loss= 0.40826 train_acc= 0.69306 val_roc= 0.76598 val_ap= 0.80364 time= 0.30283\n",
            "Epoch: 0528 train_loss= 0.40824 train_acc= 0.69374 val_roc= 0.76566 val_ap= 0.80337 time= 0.29934\n",
            "Epoch: 0529 train_loss= 0.40822 train_acc= 0.69442 val_roc= 0.76531 val_ap= 0.80309 time= 0.29921\n",
            "Epoch: 0530 train_loss= 0.40820 train_acc= 0.69515 val_roc= 0.76504 val_ap= 0.80294 time= 0.30127\n",
            "Epoch: 0531 train_loss= 0.40818 train_acc= 0.69583 val_roc= 0.76474 val_ap= 0.80268 time= 0.31826\n",
            "Epoch: 0532 train_loss= 0.40816 train_acc= 0.69647 val_roc= 0.76446 val_ap= 0.80242 time= 0.30066\n",
            "Epoch: 0533 train_loss= 0.40814 train_acc= 0.69718 val_roc= 0.76414 val_ap= 0.80217 time= 0.29736\n",
            "Epoch: 0534 train_loss= 0.40812 train_acc= 0.69785 val_roc= 0.76388 val_ap= 0.80193 time= 0.30049\n",
            "Epoch: 0535 train_loss= 0.40810 train_acc= 0.69856 val_roc= 0.76374 val_ap= 0.80176 time= 0.29718\n",
            "Epoch: 0536 train_loss= 0.40808 train_acc= 0.69927 val_roc= 0.76341 val_ap= 0.80146 time= 0.30456\n",
            "Epoch: 0537 train_loss= 0.40806 train_acc= 0.69996 val_roc= 0.76312 val_ap= 0.80127 time= 0.30185\n",
            "Epoch: 0538 train_loss= 0.40804 train_acc= 0.70066 val_roc= 0.76286 val_ap= 0.80101 time= 0.29771\n",
            "Epoch: 0539 train_loss= 0.40802 train_acc= 0.70138 val_roc= 0.76259 val_ap= 0.80087 time= 0.29798\n",
            "Epoch: 0540 train_loss= 0.40800 train_acc= 0.70208 val_roc= 0.76229 val_ap= 0.80056 time= 0.30168\n",
            "Epoch: 0541 train_loss= 0.40798 train_acc= 0.70277 val_roc= 0.76197 val_ap= 0.80025 time= 0.31060\n",
            "Epoch: 0542 train_loss= 0.40796 train_acc= 0.70351 val_roc= 0.76175 val_ap= 0.80008 time= 0.29740\n",
            "Epoch: 0543 train_loss= 0.40794 train_acc= 0.70422 val_roc= 0.76141 val_ap= 0.79979 time= 0.30898\n",
            "Epoch: 0544 train_loss= 0.40792 train_acc= 0.70493 val_roc= 0.76107 val_ap= 0.79952 time= 0.30075\n",
            "Epoch: 0545 train_loss= 0.40790 train_acc= 0.70558 val_roc= 0.76071 val_ap= 0.79917 time= 0.29714\n",
            "Epoch: 0546 train_loss= 0.40788 train_acc= 0.70630 val_roc= 0.76033 val_ap= 0.79879 time= 0.30215\n",
            "Epoch: 0547 train_loss= 0.40786 train_acc= 0.70695 val_roc= 0.76005 val_ap= 0.79838 time= 0.30445\n",
            "Epoch: 0548 train_loss= 0.40784 train_acc= 0.70766 val_roc= 0.75979 val_ap= 0.79799 time= 0.30147\n",
            "Epoch: 0549 train_loss= 0.40782 train_acc= 0.70837 val_roc= 0.75947 val_ap= 0.79759 time= 0.29681\n",
            "Epoch: 0550 train_loss= 0.40780 train_acc= 0.70911 val_roc= 0.75918 val_ap= 0.79731 time= 0.29560\n",
            "Epoch: 0551 train_loss= 0.40778 train_acc= 0.70978 val_roc= 0.75887 val_ap= 0.79701 time= 0.30521\n",
            "Epoch: 0552 train_loss= 0.40776 train_acc= 0.71052 val_roc= 0.75847 val_ap= 0.79663 time= 0.30206\n",
            "Epoch: 0553 train_loss= 0.40774 train_acc= 0.71125 val_roc= 0.75809 val_ap= 0.79632 time= 0.30207\n",
            "Epoch: 0554 train_loss= 0.40772 train_acc= 0.71198 val_roc= 0.75777 val_ap= 0.79607 time= 0.29744\n",
            "Epoch: 0555 train_loss= 0.40770 train_acc= 0.71272 val_roc= 0.75734 val_ap= 0.79559 time= 0.31032\n",
            "Epoch: 0556 train_loss= 0.40768 train_acc= 0.71343 val_roc= 0.75691 val_ap= 0.79508 time= 0.29717\n",
            "Epoch: 0557 train_loss= 0.40765 train_acc= 0.71413 val_roc= 0.75658 val_ap= 0.79480 time= 0.31088\n",
            "Epoch: 0558 train_loss= 0.40763 train_acc= 0.71486 val_roc= 0.75624 val_ap= 0.79453 time= 0.29642\n",
            "Epoch: 0559 train_loss= 0.40761 train_acc= 0.71556 val_roc= 0.75595 val_ap= 0.79418 time= 0.29644\n",
            "Epoch: 0560 train_loss= 0.40759 train_acc= 0.71630 val_roc= 0.75564 val_ap= 0.79398 time= 0.29949\n",
            "Epoch: 0561 train_loss= 0.40757 train_acc= 0.71699 val_roc= 0.75534 val_ap= 0.79368 time= 0.30353\n",
            "Epoch: 0562 train_loss= 0.40755 train_acc= 0.71770 val_roc= 0.75505 val_ap= 0.79347 time= 0.30247\n",
            "Epoch: 0563 train_loss= 0.40753 train_acc= 0.71844 val_roc= 0.75469 val_ap= 0.79320 time= 0.29834\n",
            "Epoch: 0564 train_loss= 0.40751 train_acc= 0.71918 val_roc= 0.75434 val_ap= 0.79277 time= 0.31152\n",
            "Epoch: 0565 train_loss= 0.40749 train_acc= 0.71989 val_roc= 0.75400 val_ap= 0.79244 time= 0.30027\n",
            "Epoch: 0566 train_loss= 0.40747 train_acc= 0.72064 val_roc= 0.75362 val_ap= 0.79215 time= 0.30420\n",
            "Epoch: 0567 train_loss= 0.40745 train_acc= 0.72138 val_roc= 0.75322 val_ap= 0.79178 time= 0.30383\n",
            "Epoch: 0568 train_loss= 0.40743 train_acc= 0.72207 val_roc= 0.75290 val_ap= 0.79148 time= 0.29755\n",
            "Epoch: 0569 train_loss= 0.40741 train_acc= 0.72279 val_roc= 0.75259 val_ap= 0.79114 time= 0.30336\n",
            "Epoch: 0570 train_loss= 0.40739 train_acc= 0.72350 val_roc= 0.75218 val_ap= 0.79076 time= 0.29777\n",
            "Epoch: 0571 train_loss= 0.40737 train_acc= 0.72423 val_roc= 0.75174 val_ap= 0.79030 time= 0.30719\n",
            "Epoch: 0572 train_loss= 0.40735 train_acc= 0.72497 val_roc= 0.75133 val_ap= 0.78997 time= 0.30288\n",
            "Epoch: 0573 train_loss= 0.40733 train_acc= 0.72569 val_roc= 0.75106 val_ap= 0.78973 time= 0.30223\n",
            "Epoch: 0574 train_loss= 0.40731 train_acc= 0.72643 val_roc= 0.75054 val_ap= 0.78925 time= 0.32698\n",
            "Epoch: 0575 train_loss= 0.40729 train_acc= 0.72719 val_roc= 0.74996 val_ap= 0.78877 time= 0.31363\n",
            "Epoch: 0576 train_loss= 0.40727 train_acc= 0.72793 val_roc= 0.74964 val_ap= 0.78844 time= 0.31485\n",
            "Epoch: 0577 train_loss= 0.40725 train_acc= 0.72862 val_roc= 0.74917 val_ap= 0.78803 time= 0.31361\n",
            "Epoch: 0578 train_loss= 0.40723 train_acc= 0.72936 val_roc= 0.74863 val_ap= 0.78751 time= 0.29991\n",
            "Epoch: 0579 train_loss= 0.40721 train_acc= 0.73010 val_roc= 0.74815 val_ap= 0.78713 time= 0.30235\n",
            "Epoch: 0580 train_loss= 0.40719 train_acc= 0.73081 val_roc= 0.74780 val_ap= 0.78680 time= 0.29787\n",
            "Epoch: 0581 train_loss= 0.40717 train_acc= 0.73154 val_roc= 0.74742 val_ap= 0.78648 time= 0.30455\n",
            "Epoch: 0582 train_loss= 0.40715 train_acc= 0.73226 val_roc= 0.74703 val_ap= 0.78620 time= 0.30160\n",
            "Epoch: 0583 train_loss= 0.40713 train_acc= 0.73300 val_roc= 0.74661 val_ap= 0.78583 time= 0.29909\n",
            "Epoch: 0584 train_loss= 0.40711 train_acc= 0.73373 val_roc= 0.74616 val_ap= 0.78556 time= 0.30435\n",
            "Epoch: 0585 train_loss= 0.40709 train_acc= 0.73447 val_roc= 0.74578 val_ap= 0.78522 time= 0.29916\n",
            "Epoch: 0586 train_loss= 0.40707 train_acc= 0.73516 val_roc= 0.74533 val_ap= 0.78480 time= 0.31951\n",
            "Epoch: 0587 train_loss= 0.40705 train_acc= 0.73589 val_roc= 0.74482 val_ap= 0.78431 time= 0.32269\n",
            "Epoch: 0588 train_loss= 0.40703 train_acc= 0.73658 val_roc= 0.74439 val_ap= 0.78397 time= 0.31624\n",
            "Epoch: 0589 train_loss= 0.40701 train_acc= 0.73729 val_roc= 0.74396 val_ap= 0.78350 time= 0.29732\n",
            "Epoch: 0590 train_loss= 0.40699 train_acc= 0.73805 val_roc= 0.74361 val_ap= 0.78325 time= 0.32849\n",
            "Epoch: 0591 train_loss= 0.40697 train_acc= 0.73878 val_roc= 0.74316 val_ap= 0.78284 time= 0.31074\n",
            "Epoch: 0592 train_loss= 0.40695 train_acc= 0.73951 val_roc= 0.74279 val_ap= 0.78261 time= 0.29424\n",
            "Epoch: 0593 train_loss= 0.40693 train_acc= 0.74023 val_roc= 0.74220 val_ap= 0.78216 time= 0.29892\n",
            "Epoch: 0594 train_loss= 0.40691 train_acc= 0.74093 val_roc= 0.74174 val_ap= 0.78181 time= 0.30009\n",
            "Epoch: 0595 train_loss= 0.40689 train_acc= 0.74163 val_roc= 0.74132 val_ap= 0.78146 time= 0.29707\n",
            "Epoch: 0596 train_loss= 0.40687 train_acc= 0.74233 val_roc= 0.74088 val_ap= 0.78106 time= 0.29927\n",
            "Epoch: 0597 train_loss= 0.40685 train_acc= 0.74307 val_roc= 0.74050 val_ap= 0.78069 time= 0.30164\n",
            "Epoch: 0598 train_loss= 0.40683 train_acc= 0.74377 val_roc= 0.74013 val_ap= 0.78044 time= 0.29375\n",
            "Epoch: 0599 train_loss= 0.40681 train_acc= 0.74451 val_roc= 0.73969 val_ap= 0.77992 time= 0.29903\n",
            "Epoch: 0600 train_loss= 0.40679 train_acc= 0.74528 val_roc= 0.73921 val_ap= 0.77961 time= 0.29745\n",
            "Epoch: 0601 train_loss= 0.40677 train_acc= 0.74600 val_roc= 0.73878 val_ap= 0.77924 time= 0.30519\n",
            "Epoch: 0602 train_loss= 0.40675 train_acc= 0.74675 val_roc= 0.73842 val_ap= 0.77898 time= 0.30955\n",
            "Epoch: 0603 train_loss= 0.40673 train_acc= 0.74748 val_roc= 0.73796 val_ap= 0.77860 time= 0.29716\n",
            "Epoch: 0604 train_loss= 0.40671 train_acc= 0.74821 val_roc= 0.73747 val_ap= 0.77815 time= 0.30409\n",
            "Epoch: 0605 train_loss= 0.40670 train_acc= 0.74896 val_roc= 0.73713 val_ap= 0.77790 time= 0.29761\n",
            "Epoch: 0606 train_loss= 0.40668 train_acc= 0.74966 val_roc= 0.73673 val_ap= 0.77754 time= 0.31714\n",
            "Epoch: 0607 train_loss= 0.40666 train_acc= 0.75039 val_roc= 0.73626 val_ap= 0.77723 time= 0.30739\n",
            "Epoch: 0608 train_loss= 0.40664 train_acc= 0.75108 val_roc= 0.73579 val_ap= 0.77687 time= 0.29700\n",
            "Epoch: 0609 train_loss= 0.40662 train_acc= 0.75181 val_roc= 0.73540 val_ap= 0.77656 time= 0.30495\n",
            "Epoch: 0610 train_loss= 0.40660 train_acc= 0.75246 val_roc= 0.73501 val_ap= 0.77621 time= 0.29637\n",
            "Epoch: 0611 train_loss= 0.40658 train_acc= 0.75318 val_roc= 0.73460 val_ap= 0.77588 time= 0.30459\n",
            "Epoch: 0612 train_loss= 0.40656 train_acc= 0.75393 val_roc= 0.73415 val_ap= 0.77558 time= 0.30079\n",
            "Epoch: 0613 train_loss= 0.40654 train_acc= 0.75464 val_roc= 0.73381 val_ap= 0.77526 time= 0.29507\n",
            "Epoch: 0614 train_loss= 0.40652 train_acc= 0.75532 val_roc= 0.73350 val_ap= 0.77491 time= 0.30249\n",
            "Epoch: 0615 train_loss= 0.40650 train_acc= 0.75606 val_roc= 0.73310 val_ap= 0.77451 time= 0.30172\n",
            "Epoch: 0616 train_loss= 0.40648 train_acc= 0.75679 val_roc= 0.73269 val_ap= 0.77422 time= 0.29493\n",
            "Epoch: 0617 train_loss= 0.40646 train_acc= 0.75750 val_roc= 0.73242 val_ap= 0.77393 time= 0.29997\n",
            "Epoch: 0618 train_loss= 0.40644 train_acc= 0.75823 val_roc= 0.73188 val_ap= 0.77349 time= 0.30022\n",
            "Epoch: 0619 train_loss= 0.40643 train_acc= 0.75897 val_roc= 0.73147 val_ap= 0.77311 time= 0.30251\n",
            "Epoch: 0620 train_loss= 0.40641 train_acc= 0.75965 val_roc= 0.73097 val_ap= 0.77273 time= 0.29756\n",
            "Epoch: 0621 train_loss= 0.40639 train_acc= 0.76035 val_roc= 0.73063 val_ap= 0.77246 time= 0.30382\n",
            "Epoch: 0622 train_loss= 0.40637 train_acc= 0.76103 val_roc= 0.73026 val_ap= 0.77212 time= 0.30294\n",
            "Epoch: 0623 train_loss= 0.40635 train_acc= 0.76172 val_roc= 0.72971 val_ap= 0.77170 time= 0.29495\n",
            "Epoch: 0624 train_loss= 0.40633 train_acc= 0.76242 val_roc= 0.72926 val_ap= 0.77132 time= 0.30878\n",
            "Epoch: 0625 train_loss= 0.40631 train_acc= 0.76311 val_roc= 0.72896 val_ap= 0.77101 time= 0.31249\n",
            "Epoch: 0626 train_loss= 0.40629 train_acc= 0.76378 val_roc= 0.72857 val_ap= 0.77074 time= 0.30792\n",
            "Epoch: 0627 train_loss= 0.40627 train_acc= 0.76452 val_roc= 0.72814 val_ap= 0.77041 time= 0.30232\n",
            "Epoch: 0628 train_loss= 0.40626 train_acc= 0.76520 val_roc= 0.72765 val_ap= 0.76996 time= 0.29739\n",
            "Epoch: 0629 train_loss= 0.40624 train_acc= 0.76591 val_roc= 0.72709 val_ap= 0.76950 time= 0.31971\n",
            "Epoch: 0630 train_loss= 0.40622 train_acc= 0.76658 val_roc= 0.72661 val_ap= 0.76914 time= 0.30020\n",
            "Epoch: 0631 train_loss= 0.40620 train_acc= 0.76726 val_roc= 0.72610 val_ap= 0.76870 time= 0.30766\n",
            "Epoch: 0632 train_loss= 0.40618 train_acc= 0.76796 val_roc= 0.72552 val_ap= 0.76815 time= 0.31018\n",
            "Epoch: 0633 train_loss= 0.40616 train_acc= 0.76864 val_roc= 0.72494 val_ap= 0.76780 time= 0.29932\n",
            "Epoch: 0634 train_loss= 0.40615 train_acc= 0.76931 val_roc= 0.72439 val_ap= 0.76752 time= 0.30530\n",
            "Epoch: 0635 train_loss= 0.40613 train_acc= 0.76995 val_roc= 0.72393 val_ap= 0.76724 time= 0.30476\n",
            "Epoch: 0636 train_loss= 0.40611 train_acc= 0.77063 val_roc= 0.72345 val_ap= 0.76693 time= 0.30077\n",
            "Epoch: 0637 train_loss= 0.40609 train_acc= 0.77130 val_roc= 0.72299 val_ap= 0.76658 time= 0.33560\n",
            "Epoch: 0638 train_loss= 0.40607 train_acc= 0.77197 val_roc= 0.72254 val_ap= 0.76614 time= 0.29699\n",
            "Epoch: 0639 train_loss= 0.40605 train_acc= 0.77265 val_roc= 0.72211 val_ap= 0.76585 time= 0.30316\n",
            "Epoch: 0640 train_loss= 0.40604 train_acc= 0.77336 val_roc= 0.72168 val_ap= 0.76552 time= 0.31414\n",
            "Epoch: 0641 train_loss= 0.40602 train_acc= 0.77405 val_roc= 0.72119 val_ap= 0.76506 time= 0.30023\n",
            "Epoch: 0642 train_loss= 0.40600 train_acc= 0.77479 val_roc= 0.72077 val_ap= 0.76479 time= 0.29735\n",
            "Epoch: 0643 train_loss= 0.40598 train_acc= 0.77543 val_roc= 0.72028 val_ap= 0.76439 time= 0.31024\n",
            "Epoch: 0644 train_loss= 0.40597 train_acc= 0.77610 val_roc= 0.71988 val_ap= 0.76420 time= 0.30503\n",
            "Epoch: 0645 train_loss= 0.40595 train_acc= 0.77677 val_roc= 0.71945 val_ap= 0.76387 time= 0.30705\n",
            "Epoch: 0646 train_loss= 0.40593 train_acc= 0.77747 val_roc= 0.71901 val_ap= 0.76347 time= 0.30208\n",
            "Epoch: 0647 train_loss= 0.40591 train_acc= 0.77813 val_roc= 0.71860 val_ap= 0.76313 time= 0.32160\n",
            "Epoch: 0648 train_loss= 0.40590 train_acc= 0.77880 val_roc= 0.71820 val_ap= 0.76286 time= 0.29860\n",
            "Epoch: 0649 train_loss= 0.40588 train_acc= 0.77948 val_roc= 0.71784 val_ap= 0.76254 time= 0.29991\n",
            "Epoch: 0650 train_loss= 0.40586 train_acc= 0.78018 val_roc= 0.71735 val_ap= 0.76215 time= 0.31167\n",
            "Epoch: 0651 train_loss= 0.40584 train_acc= 0.78086 val_roc= 0.71698 val_ap= 0.76187 time= 0.31093\n",
            "Epoch: 0652 train_loss= 0.40583 train_acc= 0.78153 val_roc= 0.71659 val_ap= 0.76155 time= 0.32008\n",
            "Epoch: 0653 train_loss= 0.40581 train_acc= 0.78219 val_roc= 0.71617 val_ap= 0.76117 time= 0.33128\n",
            "Epoch: 0654 train_loss= 0.40579 train_acc= 0.78285 val_roc= 0.71570 val_ap= 0.76084 time= 0.30491\n",
            "Epoch: 0655 train_loss= 0.40578 train_acc= 0.78352 val_roc= 0.71527 val_ap= 0.76052 time= 0.30147\n",
            "Epoch: 0656 train_loss= 0.40576 train_acc= 0.78421 val_roc= 0.71490 val_ap= 0.76025 time= 0.29812\n",
            "Epoch: 0657 train_loss= 0.40574 train_acc= 0.78486 val_roc= 0.71452 val_ap= 0.75986 time= 0.31367\n",
            "Epoch: 0658 train_loss= 0.40573 train_acc= 0.78556 val_roc= 0.71412 val_ap= 0.75946 time= 0.31257\n",
            "Epoch: 0659 train_loss= 0.40571 train_acc= 0.78624 val_roc= 0.71386 val_ap= 0.75928 time= 0.29743\n",
            "Epoch: 0660 train_loss= 0.40570 train_acc= 0.78693 val_roc= 0.71352 val_ap= 0.75900 time= 0.30933\n",
            "Epoch: 0661 train_loss= 0.40568 train_acc= 0.78762 val_roc= 0.71331 val_ap= 0.75881 time= 0.30184\n",
            "Epoch: 0662 train_loss= 0.40566 train_acc= 0.78831 val_roc= 0.71294 val_ap= 0.75844 time= 0.29822\n",
            "Epoch: 0663 train_loss= 0.40565 train_acc= 0.78898 val_roc= 0.71266 val_ap= 0.75819 time= 0.29582\n",
            "Epoch: 0664 train_loss= 0.40563 train_acc= 0.78964 val_roc= 0.71232 val_ap= 0.75787 time= 0.30758\n",
            "Epoch: 0665 train_loss= 0.40562 train_acc= 0.79032 val_roc= 0.71192 val_ap= 0.75744 time= 0.29658\n",
            "Epoch: 0666 train_loss= 0.40560 train_acc= 0.79096 val_roc= 0.71161 val_ap= 0.75718 time= 0.29955\n",
            "Epoch: 0667 train_loss= 0.40559 train_acc= 0.79162 val_roc= 0.71126 val_ap= 0.75688 time= 0.31521\n",
            "Epoch: 0668 train_loss= 0.40557 train_acc= 0.79230 val_roc= 0.71092 val_ap= 0.75651 time= 0.29466\n",
            "Epoch: 0669 train_loss= 0.40556 train_acc= 0.79294 val_roc= 0.71062 val_ap= 0.75627 time= 0.29897\n",
            "Epoch: 0670 train_loss= 0.40554 train_acc= 0.79358 val_roc= 0.71030 val_ap= 0.75590 time= 0.31028\n",
            "Epoch: 0671 train_loss= 0.40552 train_acc= 0.79427 val_roc= 0.70997 val_ap= 0.75566 time= 0.31722\n",
            "Epoch: 0672 train_loss= 0.40551 train_acc= 0.79490 val_roc= 0.70952 val_ap= 0.75530 time= 0.31919\n",
            "Epoch: 0673 train_loss= 0.40550 train_acc= 0.79555 val_roc= 0.70912 val_ap= 0.75498 time= 0.31810\n",
            "Epoch: 0674 train_loss= 0.40548 train_acc= 0.79618 val_roc= 0.70882 val_ap= 0.75472 time= 0.30570\n",
            "Epoch: 0675 train_loss= 0.40547 train_acc= 0.79684 val_roc= 0.70842 val_ap= 0.75442 time= 0.29808\n",
            "Epoch: 0676 train_loss= 0.40545 train_acc= 0.79749 val_roc= 0.70813 val_ap= 0.75418 time= 0.30021\n",
            "Epoch: 0677 train_loss= 0.40544 train_acc= 0.79812 val_roc= 0.70784 val_ap= 0.75389 time= 0.31208\n",
            "Epoch: 0678 train_loss= 0.40542 train_acc= 0.79874 val_roc= 0.70752 val_ap= 0.75362 time= 0.32256\n",
            "Epoch: 0679 train_loss= 0.40541 train_acc= 0.79936 val_roc= 0.70722 val_ap= 0.75341 time= 0.31933\n",
            "Epoch: 0680 train_loss= 0.40539 train_acc= 0.79996 val_roc= 0.70707 val_ap= 0.75326 time= 0.30615\n",
            "Epoch: 0681 train_loss= 0.40538 train_acc= 0.80060 val_roc= 0.70683 val_ap= 0.75306 time= 0.29907\n",
            "Epoch: 0682 train_loss= 0.40537 train_acc= 0.80121 val_roc= 0.70656 val_ap= 0.75290 time= 0.29815\n",
            "Epoch: 0683 train_loss= 0.40535 train_acc= 0.80184 val_roc= 0.70620 val_ap= 0.75271 time= 0.30332\n",
            "Epoch: 0684 train_loss= 0.40534 train_acc= 0.80250 val_roc= 0.70581 val_ap= 0.75239 time= 0.29489\n",
            "Epoch: 0685 train_loss= 0.40533 train_acc= 0.80312 val_roc= 0.70557 val_ap= 0.75214 time= 0.29556\n",
            "Epoch: 0686 train_loss= 0.40531 train_acc= 0.80374 val_roc= 0.70536 val_ap= 0.75192 time= 0.30131\n",
            "Epoch: 0687 train_loss= 0.40530 train_acc= 0.80439 val_roc= 0.70502 val_ap= 0.75163 time= 0.30420\n",
            "Epoch: 0688 train_loss= 0.40528 train_acc= 0.80499 val_roc= 0.70472 val_ap= 0.75141 time= 0.30462\n",
            "Epoch: 0689 train_loss= 0.40527 train_acc= 0.80562 val_roc= 0.70444 val_ap= 0.75109 time= 0.32365\n",
            "Epoch: 0690 train_loss= 0.40526 train_acc= 0.80629 val_roc= 0.70409 val_ap= 0.75083 time= 0.31074\n",
            "Epoch: 0691 train_loss= 0.40524 train_acc= 0.80692 val_roc= 0.70389 val_ap= 0.75053 time= 0.31231\n",
            "Epoch: 0692 train_loss= 0.40523 train_acc= 0.80754 val_roc= 0.70349 val_ap= 0.75027 time= 0.29558\n",
            "Epoch: 0693 train_loss= 0.40522 train_acc= 0.80814 val_roc= 0.70321 val_ap= 0.75000 time= 0.30570\n",
            "Epoch: 0694 train_loss= 0.40520 train_acc= 0.80878 val_roc= 0.70304 val_ap= 0.74985 time= 0.29732\n",
            "Epoch: 0695 train_loss= 0.40519 train_acc= 0.80944 val_roc= 0.70278 val_ap= 0.74964 time= 0.31878\n",
            "Epoch: 0696 train_loss= 0.40518 train_acc= 0.81008 val_roc= 0.70258 val_ap= 0.74949 time= 0.32630\n",
            "Epoch: 0697 train_loss= 0.40516 train_acc= 0.81071 val_roc= 0.70240 val_ap= 0.74934 time= 0.29959\n",
            "Epoch: 0698 train_loss= 0.40515 train_acc= 0.81135 val_roc= 0.70212 val_ap= 0.74918 time= 0.29529\n",
            "Epoch: 0699 train_loss= 0.40514 train_acc= 0.81199 val_roc= 0.70175 val_ap= 0.74886 time= 0.29739\n",
            "Epoch: 0700 train_loss= 0.40512 train_acc= 0.81258 val_roc= 0.70132 val_ap= 0.74858 time= 0.30400\n",
            "Epoch: 0701 train_loss= 0.40511 train_acc= 0.81318 val_roc= 0.70095 val_ap= 0.74832 time= 0.29506\n",
            "Epoch: 0702 train_loss= 0.40510 train_acc= 0.81376 val_roc= 0.70065 val_ap= 0.74816 time= 0.29549\n",
            "Epoch: 0703 train_loss= 0.40509 train_acc= 0.81436 val_roc= 0.70027 val_ap= 0.74789 time= 0.30305\n",
            "Epoch: 0704 train_loss= 0.40507 train_acc= 0.81499 val_roc= 0.70006 val_ap= 0.74776 time= 0.29441\n",
            "Epoch: 0705 train_loss= 0.40506 train_acc= 0.81559 val_roc= 0.69989 val_ap= 0.74762 time= 0.29974\n",
            "Epoch: 0706 train_loss= 0.40505 train_acc= 0.81618 val_roc= 0.69954 val_ap= 0.74731 time= 0.30283\n",
            "Epoch: 0707 train_loss= 0.40504 train_acc= 0.81681 val_roc= 0.69924 val_ap= 0.74702 time= 0.30845\n",
            "Epoch: 0708 train_loss= 0.40502 train_acc= 0.81740 val_roc= 0.69904 val_ap= 0.74690 time= 0.30926\n",
            "Epoch: 0709 train_loss= 0.40501 train_acc= 0.81802 val_roc= 0.69876 val_ap= 0.74661 time= 0.29919\n",
            "Epoch: 0710 train_loss= 0.40500 train_acc= 0.81859 val_roc= 0.69843 val_ap= 0.74637 time= 0.30685\n",
            "Epoch: 0711 train_loss= 0.40499 train_acc= 0.81920 val_roc= 0.69826 val_ap= 0.74623 time= 0.29418\n",
            "Epoch: 0712 train_loss= 0.40497 train_acc= 0.81978 val_roc= 0.69807 val_ap= 0.74613 time= 0.29890\n",
            "Epoch: 0713 train_loss= 0.40496 train_acc= 0.82036 val_roc= 0.69781 val_ap= 0.74597 time= 0.30296\n",
            "Epoch: 0714 train_loss= 0.40495 train_acc= 0.82095 val_roc= 0.69760 val_ap= 0.74579 time= 0.31102\n",
            "Epoch: 0715 train_loss= 0.40494 train_acc= 0.82154 val_roc= 0.69734 val_ap= 0.74562 time= 0.30214\n",
            "Epoch: 0716 train_loss= 0.40493 train_acc= 0.82215 val_roc= 0.69704 val_ap= 0.74537 time= 0.29675\n",
            "Epoch: 0717 train_loss= 0.40491 train_acc= 0.82276 val_roc= 0.69674 val_ap= 0.74514 time= 0.32896\n",
            "Epoch: 0718 train_loss= 0.40490 train_acc= 0.82337 val_roc= 0.69664 val_ap= 0.74507 time= 0.30929\n",
            "Epoch: 0719 train_loss= 0.40489 train_acc= 0.82401 val_roc= 0.69645 val_ap= 0.74493 time= 0.29762\n",
            "Epoch: 0720 train_loss= 0.40488 train_acc= 0.82465 val_roc= 0.69629 val_ap= 0.74479 time= 0.30294\n",
            "Epoch: 0721 train_loss= 0.40487 train_acc= 0.82524 val_roc= 0.69617 val_ap= 0.74466 time= 0.29361\n",
            "Epoch: 0722 train_loss= 0.40486 train_acc= 0.82583 val_roc= 0.69605 val_ap= 0.74457 time= 0.29733\n",
            "Epoch: 0723 train_loss= 0.40485 train_acc= 0.82643 val_roc= 0.69583 val_ap= 0.74441 time= 0.29889\n",
            "Epoch: 0724 train_loss= 0.40483 train_acc= 0.82701 val_roc= 0.69572 val_ap= 0.74433 time= 0.30409\n",
            "Epoch: 0725 train_loss= 0.40482 train_acc= 0.82758 val_roc= 0.69546 val_ap= 0.74410 time= 0.29575\n",
            "Epoch: 0726 train_loss= 0.40481 train_acc= 0.82811 val_roc= 0.69521 val_ap= 0.74394 time= 0.29979\n",
            "Epoch: 0727 train_loss= 0.40480 train_acc= 0.82867 val_roc= 0.69506 val_ap= 0.74379 time= 0.31897\n",
            "Epoch: 0728 train_loss= 0.40479 train_acc= 0.82920 val_roc= 0.69487 val_ap= 0.74366 time= 0.29739\n",
            "Epoch: 0729 train_loss= 0.40478 train_acc= 0.82975 val_roc= 0.69467 val_ap= 0.74349 time= 0.31659\n",
            "Epoch: 0730 train_loss= 0.40477 train_acc= 0.83031 val_roc= 0.69444 val_ap= 0.74331 time= 0.29960\n",
            "Epoch: 0731 train_loss= 0.40476 train_acc= 0.83086 val_roc= 0.69436 val_ap= 0.74321 time= 0.29588\n",
            "Epoch: 0732 train_loss= 0.40475 train_acc= 0.83143 val_roc= 0.69413 val_ap= 0.74301 time= 0.29794\n",
            "Epoch: 0733 train_loss= 0.40474 train_acc= 0.83195 val_roc= 0.69398 val_ap= 0.74293 time= 0.30835\n",
            "Epoch: 0734 train_loss= 0.40473 train_acc= 0.83247 val_roc= 0.69390 val_ap= 0.74287 time= 0.29663\n",
            "Epoch: 0735 train_loss= 0.40472 train_acc= 0.83299 val_roc= 0.69371 val_ap= 0.74275 time= 0.30179\n",
            "Epoch: 0736 train_loss= 0.40471 train_acc= 0.83350 val_roc= 0.69350 val_ap= 0.74262 time= 0.29559\n",
            "Epoch: 0737 train_loss= 0.40470 train_acc= 0.83403 val_roc= 0.69340 val_ap= 0.74256 time= 0.31836\n",
            "Epoch: 0738 train_loss= 0.40469 train_acc= 0.83456 val_roc= 0.69325 val_ap= 0.74244 time= 0.30503\n",
            "Epoch: 0739 train_loss= 0.40468 train_acc= 0.83507 val_roc= 0.69311 val_ap= 0.74236 time= 0.31673\n",
            "Epoch: 0740 train_loss= 0.40467 train_acc= 0.83562 val_roc= 0.69291 val_ap= 0.74224 time= 0.32520\n",
            "Epoch: 0741 train_loss= 0.40466 train_acc= 0.83613 val_roc= 0.69278 val_ap= 0.74211 time= 0.32560\n",
            "Epoch: 0742 train_loss= 0.40465 train_acc= 0.83662 val_roc= 0.69249 val_ap= 0.74191 time= 0.30606\n",
            "Epoch: 0743 train_loss= 0.40464 train_acc= 0.83711 val_roc= 0.69238 val_ap= 0.74186 time= 0.30437\n",
            "Epoch: 0744 train_loss= 0.40463 train_acc= 0.83764 val_roc= 0.69222 val_ap= 0.74178 time= 0.29457\n",
            "Epoch: 0745 train_loss= 0.40462 train_acc= 0.83812 val_roc= 0.69210 val_ap= 0.74173 time= 0.30151\n",
            "Epoch: 0746 train_loss= 0.40461 train_acc= 0.83863 val_roc= 0.69201 val_ap= 0.74169 time= 0.31103\n",
            "Epoch: 0747 train_loss= 0.40461 train_acc= 0.83914 val_roc= 0.69190 val_ap= 0.74161 time= 0.31964\n",
            "Epoch: 0748 train_loss= 0.40460 train_acc= 0.83964 val_roc= 0.69175 val_ap= 0.74150 time= 0.31558\n",
            "Epoch: 0749 train_loss= 0.40459 train_acc= 0.84015 val_roc= 0.69163 val_ap= 0.74140 time= 0.29776\n",
            "Epoch: 0750 train_loss= 0.40458 train_acc= 0.84064 val_roc= 0.69146 val_ap= 0.74130 time= 0.31017\n",
            "Epoch: 0751 train_loss= 0.40457 train_acc= 0.84115 val_roc= 0.69129 val_ap= 0.74120 time= 0.29721\n",
            "Epoch: 0752 train_loss= 0.40456 train_acc= 0.84165 val_roc= 0.69112 val_ap= 0.74110 time= 0.29816\n",
            "Epoch: 0753 train_loss= 0.40455 train_acc= 0.84213 val_roc= 0.69100 val_ap= 0.74095 time= 0.32444\n",
            "Epoch: 0754 train_loss= 0.40454 train_acc= 0.84261 val_roc= 0.69093 val_ap= 0.74087 time= 0.29524\n",
            "Epoch: 0755 train_loss= 0.40453 train_acc= 0.84308 val_roc= 0.69080 val_ap= 0.74075 time= 0.29955\n",
            "Epoch: 0756 train_loss= 0.40452 train_acc= 0.84356 val_roc= 0.69055 val_ap= 0.74064 time= 0.30367\n",
            "Epoch: 0757 train_loss= 0.40452 train_acc= 0.84408 val_roc= 0.69041 val_ap= 0.74050 time= 0.30008\n",
            "Epoch: 0758 train_loss= 0.40451 train_acc= 0.84458 val_roc= 0.69018 val_ap= 0.74035 time= 0.29811\n",
            "Epoch: 0759 train_loss= 0.40450 train_acc= 0.84507 val_roc= 0.69001 val_ap= 0.74025 time= 0.30574\n",
            "Epoch: 0760 train_loss= 0.40449 train_acc= 0.84558 val_roc= 0.68997 val_ap= 0.74022 time= 0.30046\n",
            "Epoch: 0761 train_loss= 0.40448 train_acc= 0.84604 val_roc= 0.68989 val_ap= 0.74016 time= 0.29557\n",
            "Epoch: 0762 train_loss= 0.40447 train_acc= 0.84651 val_roc= 0.68985 val_ap= 0.74012 time= 0.30151\n",
            "Epoch: 0763 train_loss= 0.40447 train_acc= 0.84699 val_roc= 0.68979 val_ap= 0.74006 time= 0.32067\n",
            "Epoch: 0764 train_loss= 0.40446 train_acc= 0.84747 val_roc= 0.68961 val_ap= 0.73993 time= 0.29642\n",
            "Epoch: 0765 train_loss= 0.40445 train_acc= 0.84793 val_roc= 0.68952 val_ap= 0.73990 time= 0.30293\n",
            "Epoch: 0766 train_loss= 0.40444 train_acc= 0.84837 val_roc= 0.68939 val_ap= 0.73983 time= 0.29826\n",
            "Epoch: 0767 train_loss= 0.40443 train_acc= 0.84885 val_roc= 0.68916 val_ap= 0.73970 time= 0.29878\n",
            "Epoch: 0768 train_loss= 0.40443 train_acc= 0.84931 val_roc= 0.68889 val_ap= 0.73957 time= 0.29360\n",
            "Epoch: 0769 train_loss= 0.40442 train_acc= 0.84972 val_roc= 0.68878 val_ap= 0.73950 time= 0.31642\n",
            "Epoch: 0770 train_loss= 0.40441 train_acc= 0.85018 val_roc= 0.68873 val_ap= 0.73946 time= 0.32693\n",
            "Epoch: 0771 train_loss= 0.40440 train_acc= 0.85063 val_roc= 0.68854 val_ap= 0.73930 time= 0.31764\n",
            "Epoch: 0772 train_loss= 0.40439 train_acc= 0.85107 val_roc= 0.68832 val_ap= 0.73919 time= 0.30228\n",
            "Epoch: 0773 train_loss= 0.40438 train_acc= 0.85149 val_roc= 0.68821 val_ap= 0.73895 time= 0.30397\n",
            "Epoch: 0774 train_loss= 0.40438 train_acc= 0.85193 val_roc= 0.68811 val_ap= 0.73892 time= 0.30131\n",
            "Epoch: 0775 train_loss= 0.40437 train_acc= 0.85235 val_roc= 0.68789 val_ap= 0.73884 time= 0.30065\n",
            "Epoch: 0776 train_loss= 0.40436 train_acc= 0.85279 val_roc= 0.68771 val_ap= 0.73878 time= 0.31374\n",
            "Epoch: 0777 train_loss= 0.40435 train_acc= 0.85324 val_roc= 0.68743 val_ap= 0.73860 time= 0.31412\n",
            "Epoch: 0778 train_loss= 0.40434 train_acc= 0.85368 val_roc= 0.68727 val_ap= 0.73855 time= 0.30955\n",
            "Epoch: 0779 train_loss= 0.40434 train_acc= 0.85409 val_roc= 0.68702 val_ap= 0.73845 time= 0.30626\n",
            "Epoch: 0780 train_loss= 0.40433 train_acc= 0.85448 val_roc= 0.68676 val_ap= 0.73829 time= 0.29985\n",
            "Epoch: 0781 train_loss= 0.40432 train_acc= 0.85486 val_roc= 0.68650 val_ap= 0.73816 time= 0.30869\n",
            "Epoch: 0782 train_loss= 0.40431 train_acc= 0.85526 val_roc= 0.68629 val_ap= 0.73801 time= 0.30086\n",
            "Epoch: 0783 train_loss= 0.40431 train_acc= 0.85568 val_roc= 0.68614 val_ap= 0.73791 time= 0.30394\n",
            "Epoch: 0784 train_loss= 0.40430 train_acc= 0.85606 val_roc= 0.68594 val_ap= 0.73780 time= 0.31280\n",
            "Epoch: 0785 train_loss= 0.40429 train_acc= 0.85644 val_roc= 0.68569 val_ap= 0.73764 time= 0.29576\n",
            "Epoch: 0786 train_loss= 0.40428 train_acc= 0.85682 val_roc= 0.68548 val_ap= 0.73754 time= 0.30380\n",
            "Epoch: 0787 train_loss= 0.40427 train_acc= 0.85719 val_roc= 0.68532 val_ap= 0.73746 time= 0.29873\n",
            "Epoch: 0788 train_loss= 0.40427 train_acc= 0.85754 val_roc= 0.68527 val_ap= 0.73744 time= 0.29848\n",
            "Epoch: 0789 train_loss= 0.40426 train_acc= 0.85789 val_roc= 0.68514 val_ap= 0.73739 time= 0.30789\n",
            "Epoch: 0790 train_loss= 0.40425 train_acc= 0.85824 val_roc= 0.68496 val_ap= 0.73733 time= 0.29474\n",
            "Epoch: 0791 train_loss= 0.40424 train_acc= 0.85860 val_roc= 0.68475 val_ap= 0.73721 time= 0.29711\n",
            "Epoch: 0792 train_loss= 0.40424 train_acc= 0.85895 val_roc= 0.68454 val_ap= 0.73707 time= 0.30069\n",
            "Epoch: 0793 train_loss= 0.40423 train_acc= 0.85929 val_roc= 0.68433 val_ap= 0.73692 time= 0.30417\n",
            "Epoch: 0794 train_loss= 0.40422 train_acc= 0.85963 val_roc= 0.68400 val_ap= 0.73670 time= 0.29614\n",
            "Epoch: 0795 train_loss= 0.40421 train_acc= 0.85997 val_roc= 0.68385 val_ap= 0.73669 time= 0.29953\n",
            "Epoch: 0796 train_loss= 0.40421 train_acc= 0.86029 val_roc= 0.68379 val_ap= 0.73661 time= 0.30786\n",
            "Epoch: 0797 train_loss= 0.40420 train_acc= 0.86064 val_roc= 0.68366 val_ap= 0.73654 time= 0.29802\n",
            "Epoch: 0798 train_loss= 0.40419 train_acc= 0.86098 val_roc= 0.68342 val_ap= 0.73643 time= 0.29695\n",
            "Epoch: 0799 train_loss= 0.40419 train_acc= 0.86129 val_roc= 0.68319 val_ap= 0.73629 time= 0.30284\n",
            "Epoch: 0800 train_loss= 0.40418 train_acc= 0.86162 val_roc= 0.68285 val_ap= 0.73609 time= 0.29903\n",
            "Epoch: 0801 train_loss= 0.40417 train_acc= 0.86193 val_roc= 0.68265 val_ap= 0.73593 time= 0.29773\n",
            "Epoch: 0802 train_loss= 0.40416 train_acc= 0.86225 val_roc= 0.68240 val_ap= 0.73582 time= 0.31634\n",
            "Epoch: 0803 train_loss= 0.40416 train_acc= 0.86258 val_roc= 0.68216 val_ap= 0.73561 time= 0.32183\n",
            "Epoch: 0804 train_loss= 0.40415 train_acc= 0.86289 val_roc= 0.68195 val_ap= 0.73549 time= 0.30054\n",
            "Epoch: 0805 train_loss= 0.40414 train_acc= 0.86323 val_roc= 0.68171 val_ap= 0.73539 time= 0.30027\n",
            "Epoch: 0806 train_loss= 0.40414 train_acc= 0.86357 val_roc= 0.68156 val_ap= 0.73533 time= 0.30063\n",
            "Epoch: 0807 train_loss= 0.40413 train_acc= 0.86391 val_roc= 0.68130 val_ap= 0.73521 time= 0.29694\n",
            "Epoch: 0808 train_loss= 0.40412 train_acc= 0.86423 val_roc= 0.68116 val_ap= 0.73511 time= 0.30471\n",
            "Epoch: 0809 train_loss= 0.40412 train_acc= 0.86453 val_roc= 0.68090 val_ap= 0.73495 time= 0.32742\n",
            "Epoch: 0810 train_loss= 0.40411 train_acc= 0.86483 val_roc= 0.68069 val_ap= 0.73485 time= 0.32365\n",
            "Epoch: 0811 train_loss= 0.40410 train_acc= 0.86513 val_roc= 0.68038 val_ap= 0.73471 time= 0.29772\n",
            "Epoch: 0812 train_loss= 0.40410 train_acc= 0.86543 val_roc= 0.68009 val_ap= 0.73458 time= 0.29433\n",
            "Epoch: 0813 train_loss= 0.40409 train_acc= 0.86572 val_roc= 0.67995 val_ap= 0.73446 time= 0.30344\n",
            "Epoch: 0814 train_loss= 0.40408 train_acc= 0.86603 val_roc= 0.67967 val_ap= 0.73429 time= 0.29779\n",
            "Epoch: 0815 train_loss= 0.40408 train_acc= 0.86632 val_roc= 0.67935 val_ap= 0.73414 time= 0.32022\n",
            "Epoch: 0816 train_loss= 0.40407 train_acc= 0.86662 val_roc= 0.67906 val_ap= 0.73400 time= 0.33497\n",
            "Epoch: 0817 train_loss= 0.40406 train_acc= 0.86691 val_roc= 0.67890 val_ap= 0.73397 time= 0.31740\n",
            "Epoch: 0818 train_loss= 0.40406 train_acc= 0.86721 val_roc= 0.67859 val_ap= 0.73377 time= 0.29852\n",
            "Epoch: 0819 train_loss= 0.40405 train_acc= 0.86751 val_roc= 0.67839 val_ap= 0.73366 time= 0.30108\n",
            "Epoch: 0820 train_loss= 0.40404 train_acc= 0.86781 val_roc= 0.67812 val_ap= 0.73350 time= 0.32497\n",
            "Epoch: 0821 train_loss= 0.40404 train_acc= 0.86809 val_roc= 0.67788 val_ap= 0.73340 time= 0.30327\n",
            "Epoch: 0822 train_loss= 0.40403 train_acc= 0.86838 val_roc= 0.67761 val_ap= 0.73324 time= 0.31948\n",
            "Epoch: 0823 train_loss= 0.40402 train_acc= 0.86866 val_roc= 0.67739 val_ap= 0.73317 time= 0.31428\n",
            "Epoch: 0824 train_loss= 0.40402 train_acc= 0.86896 val_roc= 0.67712 val_ap= 0.73303 time= 0.31244\n",
            "Epoch: 0825 train_loss= 0.40401 train_acc= 0.86923 val_roc= 0.67694 val_ap= 0.73295 time= 0.30267\n",
            "Epoch: 0826 train_loss= 0.40401 train_acc= 0.86947 val_roc= 0.67682 val_ap= 0.73288 time= 0.30998\n",
            "Epoch: 0827 train_loss= 0.40400 train_acc= 0.86974 val_roc= 0.67670 val_ap= 0.73289 time= 0.31455\n",
            "Epoch: 0828 train_loss= 0.40399 train_acc= 0.87001 val_roc= 0.67647 val_ap= 0.73278 time= 0.31042\n",
            "Epoch: 0829 train_loss= 0.40399 train_acc= 0.87026 val_roc= 0.67630 val_ap= 0.73267 time= 0.30996\n",
            "Epoch: 0830 train_loss= 0.40398 train_acc= 0.87053 val_roc= 0.67598 val_ap= 0.73250 time= 0.29813\n",
            "Epoch: 0831 train_loss= 0.40398 train_acc= 0.87081 val_roc= 0.67580 val_ap= 0.73243 time= 0.29993\n",
            "Epoch: 0832 train_loss= 0.40397 train_acc= 0.87107 val_roc= 0.67564 val_ap= 0.73238 time= 0.30308\n",
            "Epoch: 0833 train_loss= 0.40396 train_acc= 0.87132 val_roc= 0.67545 val_ap= 0.73227 time= 0.29725\n",
            "Epoch: 0834 train_loss= 0.40396 train_acc= 0.87157 val_roc= 0.67523 val_ap= 0.73213 time= 0.30660\n",
            "Epoch: 0835 train_loss= 0.40395 train_acc= 0.87182 val_roc= 0.67506 val_ap= 0.73206 time= 0.29899\n",
            "Epoch: 0836 train_loss= 0.40395 train_acc= 0.87205 val_roc= 0.67486 val_ap= 0.73197 time= 0.32725\n",
            "Epoch: 0837 train_loss= 0.40394 train_acc= 0.87230 val_roc= 0.67459 val_ap= 0.73181 time= 0.31297\n",
            "Epoch: 0838 train_loss= 0.40394 train_acc= 0.87254 val_roc= 0.67437 val_ap= 0.73172 time= 0.29770\n",
            "Epoch: 0839 train_loss= 0.40393 train_acc= 0.87281 val_roc= 0.67416 val_ap= 0.73163 time= 0.30603\n",
            "Epoch: 0840 train_loss= 0.40392 train_acc= 0.87303 val_roc= 0.67396 val_ap= 0.73155 time= 0.30841\n",
            "Epoch: 0841 train_loss= 0.40392 train_acc= 0.87327 val_roc= 0.67383 val_ap= 0.73146 time= 0.29664\n",
            "Epoch: 0842 train_loss= 0.40391 train_acc= 0.87351 val_roc= 0.67364 val_ap= 0.73135 time= 0.29914\n",
            "Epoch: 0843 train_loss= 0.40391 train_acc= 0.87375 val_roc= 0.67340 val_ap= 0.73125 time= 0.31130\n",
            "Epoch: 0844 train_loss= 0.40390 train_acc= 0.87398 val_roc= 0.67330 val_ap= 0.73123 time= 0.29750\n",
            "Epoch: 0845 train_loss= 0.40390 train_acc= 0.87422 val_roc= 0.67320 val_ap= 0.73122 time= 0.30292\n",
            "Epoch: 0846 train_loss= 0.40389 train_acc= 0.87447 val_roc= 0.67303 val_ap= 0.73100 time= 0.29999\n",
            "Epoch: 0847 train_loss= 0.40389 train_acc= 0.87468 val_roc= 0.67289 val_ap= 0.73094 time= 0.30322\n",
            "Epoch: 0848 train_loss= 0.40388 train_acc= 0.87489 val_roc= 0.67286 val_ap= 0.73089 time= 0.30242\n",
            "Epoch: 0849 train_loss= 0.40388 train_acc= 0.87512 val_roc= 0.67272 val_ap= 0.73075 time= 0.30634\n",
            "Epoch: 0850 train_loss= 0.40387 train_acc= 0.87534 val_roc= 0.67263 val_ap= 0.73075 time= 0.30446\n",
            "Epoch: 0851 train_loss= 0.40387 train_acc= 0.87558 val_roc= 0.67251 val_ap= 0.73063 time= 0.31799\n",
            "Epoch: 0852 train_loss= 0.40386 train_acc= 0.87581 val_roc= 0.67235 val_ap= 0.73055 time= 0.31300\n",
            "Epoch: 0853 train_loss= 0.40386 train_acc= 0.87604 val_roc= 0.67219 val_ap= 0.73044 time= 0.32132\n",
            "Epoch: 0854 train_loss= 0.40385 train_acc= 0.87628 val_roc= 0.67197 val_ap= 0.73032 time= 0.31267\n",
            "Epoch: 0855 train_loss= 0.40385 train_acc= 0.87650 val_roc= 0.67193 val_ap= 0.73029 time= 0.30982\n",
            "Epoch: 0856 train_loss= 0.40385 train_acc= 0.87673 val_roc= 0.67178 val_ap= 0.73020 time= 0.29938\n",
            "Epoch: 0857 train_loss= 0.40384 train_acc= 0.87696 val_roc= 0.67171 val_ap= 0.73014 time= 0.32857\n",
            "Epoch: 0858 train_loss= 0.40384 train_acc= 0.87720 val_roc= 0.67155 val_ap= 0.73002 time= 0.32797\n",
            "Epoch: 0859 train_loss= 0.40383 train_acc= 0.87745 val_roc= 0.67139 val_ap= 0.72992 time= 0.31577\n",
            "Epoch: 0860 train_loss= 0.40383 train_acc= 0.87767 val_roc= 0.67119 val_ap= 0.72981 time= 0.30145\n",
            "Epoch: 0861 train_loss= 0.40382 train_acc= 0.87788 val_roc= 0.67105 val_ap= 0.72970 time= 0.30132\n",
            "Epoch: 0862 train_loss= 0.40382 train_acc= 0.87811 val_roc= 0.67100 val_ap= 0.72964 time= 0.30485\n",
            "Epoch: 0863 train_loss= 0.40381 train_acc= 0.87832 val_roc= 0.67081 val_ap= 0.72953 time= 0.30524\n",
            "Epoch: 0864 train_loss= 0.40381 train_acc= 0.87854 val_roc= 0.67060 val_ap= 0.72942 time= 0.32031\n",
            "Epoch: 0865 train_loss= 0.40380 train_acc= 0.87876 val_roc= 0.67053 val_ap= 0.72940 time= 0.32415\n",
            "Epoch: 0866 train_loss= 0.40380 train_acc= 0.87899 val_roc= 0.67030 val_ap= 0.72926 time= 0.30653\n",
            "Epoch: 0867 train_loss= 0.40379 train_acc= 0.87919 val_roc= 0.67025 val_ap= 0.72924 time= 0.30134\n",
            "Epoch: 0868 train_loss= 0.40379 train_acc= 0.87941 val_roc= 0.67007 val_ap= 0.72916 time= 0.30125\n",
            "Epoch: 0869 train_loss= 0.40378 train_acc= 0.87961 val_roc= 0.66989 val_ap= 0.72906 time= 0.30157\n",
            "Epoch: 0870 train_loss= 0.40378 train_acc= 0.87983 val_roc= 0.66965 val_ap= 0.72892 time= 0.29671\n",
            "Epoch: 0871 train_loss= 0.40378 train_acc= 0.88005 val_roc= 0.66948 val_ap= 0.72885 time= 0.29916\n",
            "Epoch: 0872 train_loss= 0.40377 train_acc= 0.88029 val_roc= 0.66932 val_ap= 0.72877 time= 0.30600\n",
            "Epoch: 0873 train_loss= 0.40377 train_acc= 0.88052 val_roc= 0.66925 val_ap= 0.72878 time= 0.29833\n",
            "Epoch: 0874 train_loss= 0.40376 train_acc= 0.88072 val_roc= 0.66900 val_ap= 0.72862 time= 0.30206\n",
            "Epoch: 0875 train_loss= 0.40376 train_acc= 0.88094 val_roc= 0.66894 val_ap= 0.72860 time= 0.30739\n",
            "Epoch: 0876 train_loss= 0.40375 train_acc= 0.88116 val_roc= 0.66872 val_ap= 0.72848 time= 0.29671\n",
            "Epoch: 0877 train_loss= 0.40375 train_acc= 0.88137 val_roc= 0.66860 val_ap= 0.72840 time= 0.30173\n",
            "Epoch: 0878 train_loss= 0.40375 train_acc= 0.88159 val_roc= 0.66848 val_ap= 0.72831 time= 0.30224\n",
            "Epoch: 0879 train_loss= 0.40374 train_acc= 0.88180 val_roc= 0.66835 val_ap= 0.72828 time= 0.30086\n",
            "Epoch: 0880 train_loss= 0.40374 train_acc= 0.88199 val_roc= 0.66824 val_ap= 0.72833 time= 0.29860\n",
            "Epoch: 0881 train_loss= 0.40373 train_acc= 0.88220 val_roc= 0.66810 val_ap= 0.72820 time= 0.29790\n",
            "Epoch: 0882 train_loss= 0.40373 train_acc= 0.88239 val_roc= 0.66801 val_ap= 0.72817 time= 0.30359\n",
            "Epoch: 0883 train_loss= 0.40373 train_acc= 0.88257 val_roc= 0.66782 val_ap= 0.72808 time= 0.30691\n",
            "Epoch: 0884 train_loss= 0.40372 train_acc= 0.88276 val_roc= 0.66773 val_ap= 0.72804 time= 0.29488\n",
            "Epoch: 0885 train_loss= 0.40372 train_acc= 0.88296 val_roc= 0.66767 val_ap= 0.72799 time= 0.30272\n",
            "Epoch: 0886 train_loss= 0.40371 train_acc= 0.88315 val_roc= 0.66761 val_ap= 0.72795 time= 0.29650\n",
            "Epoch: 0887 train_loss= 0.40371 train_acc= 0.88335 val_roc= 0.66749 val_ap= 0.72787 time= 0.30087\n",
            "Epoch: 0888 train_loss= 0.40371 train_acc= 0.88355 val_roc= 0.66744 val_ap= 0.72778 time= 0.30165\n",
            "Epoch: 0889 train_loss= 0.40370 train_acc= 0.88374 val_roc= 0.66733 val_ap= 0.72770 time= 0.30115\n",
            "Epoch: 0890 train_loss= 0.40370 train_acc= 0.88392 val_roc= 0.66721 val_ap= 0.72763 time= 0.29631\n",
            "Epoch: 0891 train_loss= 0.40370 train_acc= 0.88412 val_roc= 0.66709 val_ap= 0.72755 time= 0.30022\n",
            "Epoch: 0892 train_loss= 0.40369 train_acc= 0.88430 val_roc= 0.66705 val_ap= 0.72748 time= 0.30305\n",
            "Epoch: 0893 train_loss= 0.40369 train_acc= 0.88450 val_roc= 0.66695 val_ap= 0.72740 time= 0.29930\n",
            "Epoch: 0894 train_loss= 0.40368 train_acc= 0.88468 val_roc= 0.66685 val_ap= 0.72733 time= 0.31694\n",
            "Epoch: 0895 train_loss= 0.40368 train_acc= 0.88487 val_roc= 0.66682 val_ap= 0.72731 time= 0.30599\n",
            "Epoch: 0896 train_loss= 0.40368 train_acc= 0.88504 val_roc= 0.66676 val_ap= 0.72728 time= 0.30181\n",
            "Epoch: 0897 train_loss= 0.40367 train_acc= 0.88521 val_roc= 0.66676 val_ap= 0.72729 time= 0.29779\n",
            "Epoch: 0898 train_loss= 0.40367 train_acc= 0.88537 val_roc= 0.66668 val_ap= 0.72727 time= 0.30355\n",
            "Epoch: 0899 train_loss= 0.40367 train_acc= 0.88556 val_roc= 0.66665 val_ap= 0.72726 time= 0.30758\n",
            "Epoch: 0900 train_loss= 0.40366 train_acc= 0.88572 val_roc= 0.66655 val_ap= 0.72722 time= 0.29827\n",
            "Epoch: 0901 train_loss= 0.40366 train_acc= 0.88591 val_roc= 0.66646 val_ap= 0.72713 time= 0.30068\n",
            "Epoch: 0902 train_loss= 0.40365 train_acc= 0.88607 val_roc= 0.66640 val_ap= 0.72710 time= 0.31047\n",
            "Epoch: 0903 train_loss= 0.40365 train_acc= 0.88624 val_roc= 0.66629 val_ap= 0.72702 time= 0.30307\n",
            "Epoch: 0904 train_loss= 0.40365 train_acc= 0.88640 val_roc= 0.66622 val_ap= 0.72697 time= 0.29764\n",
            "Epoch: 0905 train_loss= 0.40364 train_acc= 0.88658 val_roc= 0.66612 val_ap= 0.72686 time= 0.30388\n",
            "Epoch: 0906 train_loss= 0.40364 train_acc= 0.88674 val_roc= 0.66608 val_ap= 0.72683 time= 0.30159\n",
            "Epoch: 0907 train_loss= 0.40364 train_acc= 0.88690 val_roc= 0.66598 val_ap= 0.72677 time= 0.29681\n",
            "Epoch: 0908 train_loss= 0.40363 train_acc= 0.88705 val_roc= 0.66592 val_ap= 0.72679 time= 0.30530\n",
            "Epoch: 0909 train_loss= 0.40363 train_acc= 0.88720 val_roc= 0.66595 val_ap= 0.72678 time= 0.30021\n",
            "Epoch: 0910 train_loss= 0.40363 train_acc= 0.88737 val_roc= 0.66587 val_ap= 0.72668 time= 0.29734\n",
            "Epoch: 0911 train_loss= 0.40362 train_acc= 0.88756 val_roc= 0.66580 val_ap= 0.72663 time= 0.29672\n",
            "Epoch: 0912 train_loss= 0.40362 train_acc= 0.88771 val_roc= 0.66579 val_ap= 0.72664 time= 0.30871\n",
            "Epoch: 0913 train_loss= 0.40362 train_acc= 0.88787 val_roc= 0.66573 val_ap= 0.72660 time= 0.29614\n",
            "Epoch: 0914 train_loss= 0.40362 train_acc= 0.88803 val_roc= 0.66579 val_ap= 0.72666 time= 0.29826\n",
            "Epoch: 0915 train_loss= 0.40361 train_acc= 0.88818 val_roc= 0.66573 val_ap= 0.72661 time= 0.30166\n",
            "Epoch: 0916 train_loss= 0.40361 train_acc= 0.88833 val_roc= 0.66555 val_ap= 0.72646 time= 0.30962\n",
            "Epoch: 0917 train_loss= 0.40361 train_acc= 0.88849 val_roc= 0.66550 val_ap= 0.72639 time= 0.31418\n",
            "Epoch: 0918 train_loss= 0.40360 train_acc= 0.88866 val_roc= 0.66541 val_ap= 0.72626 time= 0.30497\n",
            "Epoch: 0919 train_loss= 0.40360 train_acc= 0.88881 val_roc= 0.66536 val_ap= 0.72620 time= 0.30892\n",
            "Epoch: 0920 train_loss= 0.40360 train_acc= 0.88896 val_roc= 0.66530 val_ap= 0.72613 time= 0.29799\n",
            "Epoch: 0921 train_loss= 0.40360 train_acc= 0.88912 val_roc= 0.66529 val_ap= 0.72613 time= 0.30302\n",
            "Epoch: 0922 train_loss= 0.40359 train_acc= 0.88928 val_roc= 0.66525 val_ap= 0.72610 time= 0.30405\n",
            "Epoch: 0923 train_loss= 0.40359 train_acc= 0.88945 val_roc= 0.66526 val_ap= 0.72610 time= 0.29751\n",
            "Epoch: 0924 train_loss= 0.40359 train_acc= 0.88961 val_roc= 0.66520 val_ap= 0.72605 time= 0.29981\n",
            "Epoch: 0925 train_loss= 0.40358 train_acc= 0.88976 val_roc= 0.66513 val_ap= 0.72600 time= 0.30275\n",
            "Epoch: 0926 train_loss= 0.40358 train_acc= 0.88991 val_roc= 0.66518 val_ap= 0.72592 time= 0.29817\n",
            "Epoch: 0927 train_loss= 0.40358 train_acc= 0.89005 val_roc= 0.66522 val_ap= 0.72593 time= 0.29983\n",
            "Epoch: 0928 train_loss= 0.40357 train_acc= 0.89021 val_roc= 0.66509 val_ap= 0.72582 time= 0.30531\n",
            "Epoch: 0929 train_loss= 0.40357 train_acc= 0.89036 val_roc= 0.66506 val_ap= 0.72584 time= 0.30453\n",
            "Epoch: 0930 train_loss= 0.40357 train_acc= 0.89052 val_roc= 0.66500 val_ap= 0.72577 time= 0.32297\n",
            "Epoch: 0931 train_loss= 0.40357 train_acc= 0.89065 val_roc= 0.66489 val_ap= 0.72568 time= 0.32413\n",
            "Epoch: 0932 train_loss= 0.40356 train_acc= 0.89079 val_roc= 0.66485 val_ap= 0.72560 time= 0.30620\n",
            "Epoch: 0933 train_loss= 0.40356 train_acc= 0.89092 val_roc= 0.66485 val_ap= 0.72561 time= 0.29986\n",
            "Epoch: 0934 train_loss= 0.40356 train_acc= 0.89106 val_roc= 0.66479 val_ap= 0.72555 time= 0.30006\n",
            "Epoch: 0935 train_loss= 0.40356 train_acc= 0.89120 val_roc= 0.66476 val_ap= 0.72557 time= 0.33007\n",
            "Epoch: 0936 train_loss= 0.40355 train_acc= 0.89134 val_roc= 0.66473 val_ap= 0.72555 time= 0.29782\n",
            "Epoch: 0937 train_loss= 0.40355 train_acc= 0.89147 val_roc= 0.66475 val_ap= 0.72556 time= 0.29775\n",
            "Epoch: 0938 train_loss= 0.40355 train_acc= 0.89161 val_roc= 0.66467 val_ap= 0.72550 time= 0.30306\n",
            "Epoch: 0939 train_loss= 0.40355 train_acc= 0.89173 val_roc= 0.66458 val_ap= 0.72545 time= 0.30227\n",
            "Epoch: 0940 train_loss= 0.40354 train_acc= 0.89186 val_roc= 0.66447 val_ap= 0.72538 time= 0.29606\n",
            "Epoch: 0941 train_loss= 0.40354 train_acc= 0.89199 val_roc= 0.66439 val_ap= 0.72531 time= 0.30266\n",
            "Epoch: 0942 train_loss= 0.40354 train_acc= 0.89212 val_roc= 0.66427 val_ap= 0.72524 time= 0.30333\n",
            "Epoch: 0943 train_loss= 0.40354 train_acc= 0.89227 val_roc= 0.66422 val_ap= 0.72521 time= 0.29731\n",
            "Epoch: 0944 train_loss= 0.40353 train_acc= 0.89239 val_roc= 0.66410 val_ap= 0.72523 time= 0.30065\n",
            "Epoch: 0945 train_loss= 0.40353 train_acc= 0.89253 val_roc= 0.66401 val_ap= 0.72517 time= 0.31101\n",
            "Epoch: 0946 train_loss= 0.40353 train_acc= 0.89266 val_roc= 0.66393 val_ap= 0.72511 time= 0.30093\n",
            "Epoch: 0947 train_loss= 0.40353 train_acc= 0.89279 val_roc= 0.66381 val_ap= 0.72504 time= 0.31284\n",
            "Epoch: 0948 train_loss= 0.40352 train_acc= 0.89291 val_roc= 0.66369 val_ap= 0.72499 time= 0.31549\n",
            "Epoch: 0949 train_loss= 0.40352 train_acc= 0.89302 val_roc= 0.66364 val_ap= 0.72495 time= 0.29750\n",
            "Epoch: 0950 train_loss= 0.40352 train_acc= 0.89314 val_roc= 0.66349 val_ap= 0.72484 time= 0.30044\n",
            "Epoch: 0951 train_loss= 0.40352 train_acc= 0.89325 val_roc= 0.66328 val_ap= 0.72471 time= 0.30152\n",
            "Epoch: 0952 train_loss= 0.40351 train_acc= 0.89337 val_roc= 0.66310 val_ap= 0.72460 time= 0.31842\n",
            "Epoch: 0953 train_loss= 0.40351 train_acc= 0.89348 val_roc= 0.66303 val_ap= 0.72456 time= 0.29648\n",
            "Epoch: 0954 train_loss= 0.40351 train_acc= 0.89360 val_roc= 0.66299 val_ap= 0.72453 time= 0.29944\n",
            "Epoch: 0955 train_loss= 0.40351 train_acc= 0.89371 val_roc= 0.66290 val_ap= 0.72447 time= 0.31038\n",
            "Epoch: 0956 train_loss= 0.40350 train_acc= 0.89383 val_roc= 0.66282 val_ap= 0.72446 time= 0.30468\n",
            "Epoch: 0957 train_loss= 0.40350 train_acc= 0.89395 val_roc= 0.66267 val_ap= 0.72435 time= 0.31973\n",
            "Epoch: 0958 train_loss= 0.40350 train_acc= 0.89407 val_roc= 0.66255 val_ap= 0.72426 time= 0.31702\n",
            "Epoch: 0959 train_loss= 0.40350 train_acc= 0.89417 val_roc= 0.66251 val_ap= 0.72425 time= 0.29902\n",
            "Epoch: 0960 train_loss= 0.40349 train_acc= 0.89427 val_roc= 0.66237 val_ap= 0.72418 time= 0.31011\n",
            "Epoch: 0961 train_loss= 0.40349 train_acc= 0.89436 val_roc= 0.66222 val_ap= 0.72410 time= 0.29909\n",
            "Epoch: 0962 train_loss= 0.40349 train_acc= 0.89447 val_roc= 0.66218 val_ap= 0.72407 time= 0.32811\n",
            "Epoch: 0963 train_loss= 0.40349 train_acc= 0.89456 val_roc= 0.66215 val_ap= 0.72407 time= 0.29695\n",
            "Epoch: 0964 train_loss= 0.40348 train_acc= 0.89467 val_roc= 0.66213 val_ap= 0.72405 time= 0.31741\n",
            "Epoch: 0965 train_loss= 0.40348 train_acc= 0.89476 val_roc= 0.66206 val_ap= 0.72401 time= 0.30974\n",
            "Epoch: 0966 train_loss= 0.40348 train_acc= 0.89487 val_roc= 0.66199 val_ap= 0.72397 time= 0.29596\n",
            "Epoch: 0967 train_loss= 0.40348 train_acc= 0.89496 val_roc= 0.66194 val_ap= 0.72393 time= 0.30101\n",
            "Epoch: 0968 train_loss= 0.40347 train_acc= 0.89507 val_roc= 0.66188 val_ap= 0.72389 time= 0.30252\n",
            "Epoch: 0969 train_loss= 0.40347 train_acc= 0.89517 val_roc= 0.66177 val_ap= 0.72381 time= 0.31913\n",
            "Epoch: 0970 train_loss= 0.40347 train_acc= 0.89528 val_roc= 0.66171 val_ap= 0.72378 time= 0.31394\n",
            "Epoch: 0971 train_loss= 0.40347 train_acc= 0.89539 val_roc= 0.66166 val_ap= 0.72374 time= 0.31529\n",
            "Epoch: 0972 train_loss= 0.40347 train_acc= 0.89549 val_roc= 0.66156 val_ap= 0.72370 time= 0.29781\n",
            "Epoch: 0973 train_loss= 0.40346 train_acc= 0.89557 val_roc= 0.66155 val_ap= 0.72372 time= 0.29681\n",
            "Epoch: 0974 train_loss= 0.40346 train_acc= 0.89567 val_roc= 0.66146 val_ap= 0.72361 time= 0.30706\n",
            "Epoch: 0975 train_loss= 0.40346 train_acc= 0.89577 val_roc= 0.66136 val_ap= 0.72354 time= 0.31807\n",
            "Epoch: 0976 train_loss= 0.40346 train_acc= 0.89586 val_roc= 0.66130 val_ap= 0.72351 time= 0.30043\n",
            "Epoch: 0977 train_loss= 0.40345 train_acc= 0.89595 val_roc= 0.66121 val_ap= 0.72345 time= 0.31532\n",
            "Epoch: 0978 train_loss= 0.40345 train_acc= 0.89604 val_roc= 0.66115 val_ap= 0.72335 time= 0.32184\n",
            "Epoch: 0979 train_loss= 0.40345 train_acc= 0.89614 val_roc= 0.66102 val_ap= 0.72322 time= 0.30021\n",
            "Epoch: 0980 train_loss= 0.40345 train_acc= 0.89622 val_roc= 0.66090 val_ap= 0.72311 time= 0.31474\n",
            "Epoch: 0981 train_loss= 0.40344 train_acc= 0.89631 val_roc= 0.66078 val_ap= 0.72303 time= 0.31318\n",
            "Epoch: 0982 train_loss= 0.40344 train_acc= 0.89640 val_roc= 0.66060 val_ap= 0.72294 time= 0.30992\n",
            "Epoch: 0983 train_loss= 0.40344 train_acc= 0.89650 val_roc= 0.66047 val_ap= 0.72287 time= 0.29683\n",
            "Epoch: 0984 train_loss= 0.40344 train_acc= 0.89659 val_roc= 0.66029 val_ap= 0.72277 time= 0.32734\n",
            "Epoch: 0985 train_loss= 0.40343 train_acc= 0.89668 val_roc= 0.66022 val_ap= 0.72274 time= 0.31041\n",
            "Epoch: 0986 train_loss= 0.40343 train_acc= 0.89679 val_roc= 0.66014 val_ap= 0.72268 time= 0.30592\n",
            "Epoch: 0987 train_loss= 0.40343 train_acc= 0.89689 val_roc= 0.65997 val_ap= 0.72259 time= 0.30562\n",
            "Epoch: 0988 train_loss= 0.40343 train_acc= 0.89698 val_roc= 0.65987 val_ap= 0.72252 time= 0.32861\n",
            "Epoch: 0989 train_loss= 0.40343 train_acc= 0.89707 val_roc= 0.65975 val_ap= 0.72247 time= 0.31404\n",
            "Epoch: 0990 train_loss= 0.40342 train_acc= 0.89716 val_roc= 0.65965 val_ap= 0.72243 time= 0.31064\n",
            "Epoch: 0991 train_loss= 0.40342 train_acc= 0.89725 val_roc= 0.65957 val_ap= 0.72240 time= 0.32299\n",
            "Epoch: 0992 train_loss= 0.40342 train_acc= 0.89733 val_roc= 0.65935 val_ap= 0.72231 time= 0.29667\n",
            "Epoch: 0993 train_loss= 0.40342 train_acc= 0.89744 val_roc= 0.65928 val_ap= 0.72228 time= 0.30206\n",
            "Epoch: 0994 train_loss= 0.40341 train_acc= 0.89751 val_roc= 0.65911 val_ap= 0.72214 time= 0.30196\n",
            "Epoch: 0995 train_loss= 0.40341 train_acc= 0.89758 val_roc= 0.65904 val_ap= 0.72208 time= 0.29543\n",
            "Epoch: 0996 train_loss= 0.40341 train_acc= 0.89766 val_roc= 0.65888 val_ap= 0.72199 time= 0.29510\n",
            "Epoch: 0997 train_loss= 0.40341 train_acc= 0.89773 val_roc= 0.65887 val_ap= 0.72198 time= 0.30847\n",
            "Epoch: 0998 train_loss= 0.40340 train_acc= 0.89780 val_roc= 0.65880 val_ap= 0.72193 time= 0.30228\n",
            "Epoch: 0999 train_loss= 0.40340 train_acc= 0.89787 val_roc= 0.65870 val_ap= 0.72181 time= 0.29570\n",
            "Epoch: 1000 train_loss= 0.40340 train_acc= 0.89794 val_roc= 0.65854 val_ap= 0.72171 time= 0.31533\n",
            "Epoch: 1001 train_loss= 0.40340 train_acc= 0.89799 val_roc= 0.65842 val_ap= 0.72167 time= 0.30868\n",
            "Epoch: 1002 train_loss= 0.40340 train_acc= 0.89802 val_roc= 0.65831 val_ap= 0.72161 time= 0.30967\n",
            "Epoch: 1003 train_loss= 0.40339 train_acc= 0.89806 val_roc= 0.65829 val_ap= 0.72160 time= 0.30496\n",
            "Epoch: 1004 train_loss= 0.40339 train_acc= 0.89811 val_roc= 0.65820 val_ap= 0.72156 time= 0.32466\n",
            "Epoch: 1005 train_loss= 0.40339 train_acc= 0.89816 val_roc= 0.65819 val_ap= 0.72154 time= 0.31012\n",
            "Epoch: 1006 train_loss= 0.40339 train_acc= 0.89823 val_roc= 0.65809 val_ap= 0.72147 time= 0.30649\n",
            "Epoch: 1007 train_loss= 0.40339 train_acc= 0.89830 val_roc= 0.65803 val_ap= 0.72145 time= 0.30123\n",
            "Epoch: 1008 train_loss= 0.40338 train_acc= 0.89835 val_roc= 0.65796 val_ap= 0.72144 time= 0.29942\n",
            "Epoch: 1009 train_loss= 0.40338 train_acc= 0.89841 val_roc= 0.65789 val_ap= 0.72139 time= 0.29680\n",
            "Epoch: 1010 train_loss= 0.40338 train_acc= 0.89848 val_roc= 0.65780 val_ap= 0.72134 time= 0.30411\n",
            "Epoch: 1011 train_loss= 0.40338 train_acc= 0.89854 val_roc= 0.65774 val_ap= 0.72131 time= 0.32244\n",
            "Epoch: 1012 train_loss= 0.40338 train_acc= 0.89859 val_roc= 0.65768 val_ap= 0.72121 time= 0.29565\n",
            "Epoch: 1013 train_loss= 0.40337 train_acc= 0.89865 val_roc= 0.65761 val_ap= 0.72117 time= 0.30360\n",
            "Epoch: 1014 train_loss= 0.40337 train_acc= 0.89871 val_roc= 0.65754 val_ap= 0.72115 time= 0.32688\n",
            "Epoch: 1015 train_loss= 0.40337 train_acc= 0.89877 val_roc= 0.65743 val_ap= 0.72110 time= 0.31008\n",
            "Epoch: 1016 train_loss= 0.40337 train_acc= 0.89882 val_roc= 0.65740 val_ap= 0.72108 time= 0.30252\n",
            "Epoch: 1017 train_loss= 0.40336 train_acc= 0.89887 val_roc= 0.65727 val_ap= 0.72104 time= 0.33008\n",
            "Epoch: 1018 train_loss= 0.40336 train_acc= 0.89892 val_roc= 0.65719 val_ap= 0.72100 time= 0.32271\n",
            "Epoch: 1019 train_loss= 0.40336 train_acc= 0.89897 val_roc= 0.65708 val_ap= 0.72092 time= 0.29991\n",
            "Epoch: 1020 train_loss= 0.40336 train_acc= 0.89902 val_roc= 0.65691 val_ap= 0.72084 time= 0.32343\n",
            "Epoch: 1021 train_loss= 0.40336 train_acc= 0.89908 val_roc= 0.65682 val_ap= 0.72081 time= 0.32014\n",
            "Epoch: 1022 train_loss= 0.40335 train_acc= 0.89913 val_roc= 0.65675 val_ap= 0.72078 time= 0.31889\n",
            "Epoch: 1023 train_loss= 0.40335 train_acc= 0.89918 val_roc= 0.65673 val_ap= 0.72075 time= 0.31790\n",
            "Epoch: 1024 train_loss= 0.40335 train_acc= 0.89924 val_roc= 0.65672 val_ap= 0.72074 time= 0.32918\n",
            "Epoch: 1025 train_loss= 0.40335 train_acc= 0.89930 val_roc= 0.65660 val_ap= 0.72069 time= 0.31537\n",
            "Epoch: 1026 train_loss= 0.40335 train_acc= 0.89935 val_roc= 0.65652 val_ap= 0.72065 time= 0.31207\n",
            "Epoch: 1027 train_loss= 0.40334 train_acc= 0.89940 val_roc= 0.65645 val_ap= 0.72060 time= 0.33173\n",
            "Epoch: 1028 train_loss= 0.40334 train_acc= 0.89945 val_roc= 0.65640 val_ap= 0.72061 time= 0.31081\n",
            "Epoch: 1029 train_loss= 0.40334 train_acc= 0.89950 val_roc= 0.65634 val_ap= 0.72057 time= 0.30707\n",
            "Epoch: 1030 train_loss= 0.40334 train_acc= 0.89956 val_roc= 0.65629 val_ap= 0.72054 time= 0.32954\n",
            "Epoch: 1031 train_loss= 0.40334 train_acc= 0.89961 val_roc= 0.65624 val_ap= 0.72052 time= 0.32263\n",
            "Epoch: 1032 train_loss= 0.40333 train_acc= 0.89965 val_roc= 0.65618 val_ap= 0.72049 time= 0.31821\n",
            "Epoch: 1033 train_loss= 0.40333 train_acc= 0.89970 val_roc= 0.65616 val_ap= 0.72046 time= 0.31513\n",
            "Epoch: 1034 train_loss= 0.40333 train_acc= 0.89974 val_roc= 0.65605 val_ap= 0.72038 time= 0.32548\n",
            "Epoch: 1035 train_loss= 0.40333 train_acc= 0.89979 val_roc= 0.65597 val_ap= 0.72034 time= 0.31025\n",
            "Epoch: 1036 train_loss= 0.40332 train_acc= 0.89983 val_roc= 0.65593 val_ap= 0.72033 time= 0.30439\n",
            "Epoch: 1037 train_loss= 0.40332 train_acc= 0.89988 val_roc= 0.65588 val_ap= 0.72028 time= 0.29821\n",
            "Epoch: 1038 train_loss= 0.40332 train_acc= 0.89993 val_roc= 0.65578 val_ap= 0.72020 time= 0.29920\n",
            "Epoch: 1039 train_loss= 0.40332 train_acc= 0.89997 val_roc= 0.65575 val_ap= 0.72022 time= 0.32001\n",
            "Epoch: 1040 train_loss= 0.40331 train_acc= 0.90000 val_roc= 0.65568 val_ap= 0.72019 time= 0.31911\n",
            "Epoch: 1041 train_loss= 0.40331 train_acc= 0.90004 val_roc= 0.65563 val_ap= 0.72014 time= 0.30714\n",
            "Epoch: 1042 train_loss= 0.40331 train_acc= 0.90008 val_roc= 0.65552 val_ap= 0.72004 time= 0.31841\n",
            "Epoch: 1043 train_loss= 0.40331 train_acc= 0.90012 val_roc= 0.65554 val_ap= 0.72004 time= 0.32154\n",
            "Epoch: 1044 train_loss= 0.40331 train_acc= 0.90016 val_roc= 0.65541 val_ap= 0.71998 time= 0.30000\n",
            "Epoch: 1045 train_loss= 0.40330 train_acc= 0.90020 val_roc= 0.65534 val_ap= 0.71995 time= 0.31870\n",
            "Epoch: 1046 train_loss= 0.40330 train_acc= 0.90025 val_roc= 0.65521 val_ap= 0.71986 time= 0.32096\n",
            "Epoch: 1047 train_loss= 0.40330 train_acc= 0.90030 val_roc= 0.65518 val_ap= 0.71982 time= 0.29955\n",
            "Epoch: 1048 train_loss= 0.40330 train_acc= 0.90034 val_roc= 0.65517 val_ap= 0.71983 time= 0.31408\n",
            "Epoch: 1049 train_loss= 0.40329 train_acc= 0.90038 val_roc= 0.65498 val_ap= 0.71970 time= 0.32258\n",
            "Epoch: 1050 train_loss= 0.40329 train_acc= 0.90043 val_roc= 0.65495 val_ap= 0.71968 time= 0.31993\n",
            "Epoch: 1051 train_loss= 0.40329 train_acc= 0.90048 val_roc= 0.65489 val_ap= 0.71968 time= 0.32353\n",
            "Epoch: 1052 train_loss= 0.40329 train_acc= 0.90052 val_roc= 0.65476 val_ap= 0.71962 time= 0.32605\n",
            "Epoch: 1053 train_loss= 0.40328 train_acc= 0.90057 val_roc= 0.65469 val_ap= 0.71957 time= 0.31325\n",
            "Epoch: 1054 train_loss= 0.40328 train_acc= 0.90060 val_roc= 0.65460 val_ap= 0.71952 time= 0.30858\n",
            "Epoch: 1055 train_loss= 0.40328 train_acc= 0.90065 val_roc= 0.65456 val_ap= 0.71948 time= 0.31863\n",
            "Epoch: 1056 train_loss= 0.40328 train_acc= 0.90069 val_roc= 0.65452 val_ap= 0.71945 time= 0.31616\n",
            "Epoch: 1057 train_loss= 0.40328 train_acc= 0.90073 val_roc= 0.65451 val_ap= 0.71943 time= 0.29591\n",
            "Epoch: 1058 train_loss= 0.40327 train_acc= 0.90077 val_roc= 0.65441 val_ap= 0.71936 time= 0.31773\n",
            "Epoch: 1059 train_loss= 0.40327 train_acc= 0.90080 val_roc= 0.65437 val_ap= 0.71932 time= 0.32669\n",
            "Epoch: 1060 train_loss= 0.40327 train_acc= 0.90083 val_roc= 0.65430 val_ap= 0.71930 time= 0.31516\n",
            "Epoch: 1061 train_loss= 0.40327 train_acc= 0.90085 val_roc= 0.65419 val_ap= 0.71922 time= 0.31765\n",
            "Epoch: 1062 train_loss= 0.40326 train_acc= 0.90087 val_roc= 0.65409 val_ap= 0.71913 time= 0.31780\n",
            "Epoch: 1063 train_loss= 0.40326 train_acc= 0.90089 val_roc= 0.65400 val_ap= 0.71912 time= 0.31706\n",
            "Epoch: 1064 train_loss= 0.40326 train_acc= 0.90092 val_roc= 0.65398 val_ap= 0.71909 time= 0.32044\n",
            "Epoch: 1065 train_loss= 0.40326 train_acc= 0.90095 val_roc= 0.65393 val_ap= 0.71905 time= 0.32155\n",
            "Epoch: 1066 train_loss= 0.40325 train_acc= 0.90098 val_roc= 0.65391 val_ap= 0.71903 time= 0.29635\n",
            "Epoch: 1067 train_loss= 0.40325 train_acc= 0.90101 val_roc= 0.65384 val_ap= 0.71899 time= 0.30247\n",
            "Epoch: 1068 train_loss= 0.40325 train_acc= 0.90103 val_roc= 0.65386 val_ap= 0.71894 time= 0.33635\n",
            "Epoch: 1069 train_loss= 0.40325 train_acc= 0.90107 val_roc= 0.65378 val_ap= 0.71885 time= 0.31189\n",
            "Epoch: 1070 train_loss= 0.40324 train_acc= 0.90109 val_roc= 0.65373 val_ap= 0.71878 time= 0.29463\n",
            "Epoch: 1071 train_loss= 0.40324 train_acc= 0.90112 val_roc= 0.65373 val_ap= 0.71876 time= 0.30100\n",
            "Epoch: 1072 train_loss= 0.40324 train_acc= 0.90114 val_roc= 0.65371 val_ap= 0.71870 time= 0.30694\n",
            "Epoch: 1073 train_loss= 0.40324 train_acc= 0.90116 val_roc= 0.65370 val_ap= 0.71874 time= 0.30220\n",
            "Epoch: 1074 train_loss= 0.40323 train_acc= 0.90118 val_roc= 0.65369 val_ap= 0.71871 time= 0.29570\n",
            "Epoch: 1075 train_loss= 0.40323 train_acc= 0.90121 val_roc= 0.65359 val_ap= 0.71866 time= 0.31684\n",
            "Epoch: 1076 train_loss= 0.40323 train_acc= 0.90123 val_roc= 0.65351 val_ap= 0.71865 time= 0.30413\n",
            "Epoch: 1077 train_loss= 0.40323 train_acc= 0.90127 val_roc= 0.65347 val_ap= 0.71861 time= 0.29544\n",
            "Epoch: 1078 train_loss= 0.40323 train_acc= 0.90132 val_roc= 0.65346 val_ap= 0.71859 time= 0.30635\n",
            "Epoch: 1079 train_loss= 0.40322 train_acc= 0.90137 val_roc= 0.65338 val_ap= 0.71850 time= 0.29587\n",
            "Epoch: 1080 train_loss= 0.40322 train_acc= 0.90142 val_roc= 0.65332 val_ap= 0.71844 time= 0.29800\n",
            "Epoch: 1081 train_loss= 0.40322 train_acc= 0.90145 val_roc= 0.65330 val_ap= 0.71843 time= 0.29790\n",
            "Epoch: 1082 train_loss= 0.40322 train_acc= 0.90146 val_roc= 0.65323 val_ap= 0.71835 time= 0.30195\n",
            "Epoch: 1083 train_loss= 0.40322 train_acc= 0.90149 val_roc= 0.65318 val_ap= 0.71836 time= 0.30021\n",
            "Epoch: 1084 train_loss= 0.40321 train_acc= 0.90152 val_roc= 0.65308 val_ap= 0.71827 time= 0.29649\n",
            "Epoch: 1085 train_loss= 0.40321 train_acc= 0.90156 val_roc= 0.65299 val_ap= 0.71823 time= 0.30314\n",
            "Epoch: 1086 train_loss= 0.40321 train_acc= 0.90159 val_roc= 0.65290 val_ap= 0.71816 time= 0.30295\n",
            "Epoch: 1087 train_loss= 0.40321 train_acc= 0.90162 val_roc= 0.65283 val_ap= 0.71812 time= 0.29701\n",
            "Epoch: 1088 train_loss= 0.40321 train_acc= 0.90165 val_roc= 0.65271 val_ap= 0.71807 time= 0.30462\n",
            "Epoch: 1089 train_loss= 0.40320 train_acc= 0.90167 val_roc= 0.65269 val_ap= 0.71805 time= 0.30656\n",
            "Epoch: 1090 train_loss= 0.40320 train_acc= 0.90170 val_roc= 0.65266 val_ap= 0.71802 time= 0.29678\n",
            "Epoch: 1091 train_loss= 0.40320 train_acc= 0.90171 val_roc= 0.65259 val_ap= 0.71793 time= 0.29730\n",
            "Epoch: 1092 train_loss= 0.40320 train_acc= 0.90173 val_roc= 0.65256 val_ap= 0.71802 time= 0.30459\n",
            "Epoch: 1093 train_loss= 0.40320 train_acc= 0.90173 val_roc= 0.65247 val_ap= 0.71795 time= 0.30015\n",
            "Epoch: 1094 train_loss= 0.40320 train_acc= 0.90174 val_roc= 0.65235 val_ap= 0.71787 time= 0.29415\n",
            "Epoch: 1095 train_loss= 0.40319 train_acc= 0.90175 val_roc= 0.65228 val_ap= 0.71780 time= 0.30499\n",
            "Epoch: 1096 train_loss= 0.40319 train_acc= 0.90177 val_roc= 0.65221 val_ap= 0.71777 time= 0.29802\n",
            "Epoch: 1097 train_loss= 0.40319 train_acc= 0.90179 val_roc= 0.65209 val_ap= 0.71767 time= 0.30090\n",
            "Epoch: 1098 train_loss= 0.40319 train_acc= 0.90181 val_roc= 0.65204 val_ap= 0.71764 time= 0.29489\n",
            "Epoch: 1099 train_loss= 0.40319 train_acc= 0.90182 val_roc= 0.65197 val_ap= 0.71756 time= 0.30782\n",
            "Epoch: 1100 train_loss= 0.40319 train_acc= 0.90184 val_roc= 0.65191 val_ap= 0.71752 time= 0.29553\n",
            "Epoch: 1101 train_loss= 0.40318 train_acc= 0.90186 val_roc= 0.65192 val_ap= 0.71753 time= 0.29646\n",
            "Epoch: 1102 train_loss= 0.40318 train_acc= 0.90187 val_roc= 0.65186 val_ap= 0.71747 time= 0.30535\n",
            "Epoch: 1103 train_loss= 0.40318 train_acc= 0.90188 val_roc= 0.65180 val_ap= 0.71744 time= 0.29842\n",
            "Epoch: 1104 train_loss= 0.40318 train_acc= 0.90190 val_roc= 0.65178 val_ap= 0.71741 time= 0.29666\n",
            "Epoch: 1105 train_loss= 0.40318 train_acc= 0.90191 val_roc= 0.65171 val_ap= 0.71737 time= 0.30248\n",
            "Epoch: 1106 train_loss= 0.40318 train_acc= 0.90192 val_roc= 0.65167 val_ap= 0.71737 time= 0.29627\n",
            "Epoch: 1107 train_loss= 0.40317 train_acc= 0.90193 val_roc= 0.65160 val_ap= 0.71731 time= 0.30187\n",
            "Epoch: 1108 train_loss= 0.40317 train_acc= 0.90196 val_roc= 0.65151 val_ap= 0.71722 time= 0.29652\n",
            "Epoch: 1109 train_loss= 0.40317 train_acc= 0.90198 val_roc= 0.65147 val_ap= 0.71719 time= 0.30506\n",
            "Epoch: 1110 train_loss= 0.40317 train_acc= 0.90199 val_roc= 0.65138 val_ap= 0.71711 time= 0.29430\n",
            "Epoch: 1111 train_loss= 0.40317 train_acc= 0.90199 val_roc= 0.65130 val_ap= 0.71708 time= 0.30796\n",
            "Epoch: 1112 train_loss= 0.40317 train_acc= 0.90200 val_roc= 0.65122 val_ap= 0.71701 time= 0.30049\n",
            "Epoch: 1113 train_loss= 0.40316 train_acc= 0.90201 val_roc= 0.65119 val_ap= 0.71697 time= 0.29775\n",
            "Epoch: 1114 train_loss= 0.40316 train_acc= 0.90203 val_roc= 0.65111 val_ap= 0.71690 time= 0.29487\n",
            "Epoch: 1115 train_loss= 0.40316 train_acc= 0.90205 val_roc= 0.65106 val_ap= 0.71685 time= 0.30353\n",
            "Epoch: 1116 train_loss= 0.40316 train_acc= 0.90206 val_roc= 0.65101 val_ap= 0.71678 time= 0.30307\n",
            "Epoch: 1117 train_loss= 0.40316 train_acc= 0.90208 val_roc= 0.65094 val_ap= 0.71673 time= 0.29870\n",
            "Epoch: 1118 train_loss= 0.40316 train_acc= 0.90209 val_roc= 0.65087 val_ap= 0.71669 time= 0.29605\n",
            "Epoch: 1119 train_loss= 0.40316 train_acc= 0.90212 val_roc= 0.65088 val_ap= 0.71668 time= 0.30847\n",
            "Epoch: 1120 train_loss= 0.40316 train_acc= 0.90216 val_roc= 0.65081 val_ap= 0.71665 time= 0.29532\n",
            "Epoch: 1121 train_loss= 0.40315 train_acc= 0.90218 val_roc= 0.65075 val_ap= 0.71662 time= 0.29526\n",
            "Epoch: 1122 train_loss= 0.40315 train_acc= 0.90221 val_roc= 0.65075 val_ap= 0.71660 time= 0.29995\n",
            "Epoch: 1123 train_loss= 0.40315 train_acc= 0.90223 val_roc= 0.65068 val_ap= 0.71658 time= 0.29971\n",
            "Epoch: 1124 train_loss= 0.40315 train_acc= 0.90225 val_roc= 0.65064 val_ap= 0.71650 time= 0.29738\n",
            "Epoch: 1125 train_loss= 0.40315 train_acc= 0.90229 val_roc= 0.65054 val_ap= 0.71644 time= 0.30107\n",
            "Epoch: 1126 train_loss= 0.40315 train_acc= 0.90231 val_roc= 0.65047 val_ap= 0.71640 time= 0.30556\n",
            "Epoch: 1127 train_loss= 0.40315 train_acc= 0.90233 val_roc= 0.65047 val_ap= 0.71640 time= 0.31524\n",
            "Epoch: 1128 train_loss= 0.40315 train_acc= 0.90235 val_roc= 0.65042 val_ap= 0.71641 time= 0.29730\n",
            "Epoch: 1129 train_loss= 0.40314 train_acc= 0.90236 val_roc= 0.65036 val_ap= 0.71639 time= 0.31583\n",
            "Epoch: 1130 train_loss= 0.40314 train_acc= 0.90237 val_roc= 0.65035 val_ap= 0.71637 time= 0.30326\n",
            "Epoch: 1131 train_loss= 0.40314 train_acc= 0.90239 val_roc= 0.65027 val_ap= 0.71631 time= 0.31217\n",
            "Epoch: 1132 train_loss= 0.40314 train_acc= 0.90242 val_roc= 0.65019 val_ap= 0.71625 time= 0.30866\n",
            "Epoch: 1133 train_loss= 0.40314 train_acc= 0.90245 val_roc= 0.65017 val_ap= 0.71620 time= 0.29869\n",
            "Epoch: 1134 train_loss= 0.40314 train_acc= 0.90247 val_roc= 0.65007 val_ap= 0.71616 time= 0.29605\n",
            "Epoch: 1135 train_loss= 0.40314 train_acc= 0.90249 val_roc= 0.65003 val_ap= 0.71613 time= 0.30449\n",
            "Epoch: 1136 train_loss= 0.40314 train_acc= 0.90251 val_roc= 0.64999 val_ap= 0.71608 time= 0.29715\n",
            "Epoch: 1137 train_loss= 0.40313 train_acc= 0.90254 val_roc= 0.65001 val_ap= 0.71610 time= 0.29888\n",
            "Epoch: 1138 train_loss= 0.40313 train_acc= 0.90256 val_roc= 0.65003 val_ap= 0.71609 time= 0.30189\n",
            "Epoch: 1139 train_loss= 0.40313 train_acc= 0.90259 val_roc= 0.64995 val_ap= 0.71604 time= 0.30573\n",
            "Epoch: 1140 train_loss= 0.40313 train_acc= 0.90262 val_roc= 0.64996 val_ap= 0.71604 time= 0.29802\n",
            "Epoch: 1141 train_loss= 0.40313 train_acc= 0.90266 val_roc= 0.64993 val_ap= 0.71602 time= 0.30094\n",
            "Epoch: 1142 train_loss= 0.40313 train_acc= 0.90269 val_roc= 0.64991 val_ap= 0.71599 time= 0.30280\n",
            "Epoch: 1143 train_loss= 0.40313 train_acc= 0.90270 val_roc= 0.64985 val_ap= 0.71594 time= 0.30779\n",
            "Epoch: 1144 train_loss= 0.40313 train_acc= 0.90273 val_roc= 0.64976 val_ap= 0.71587 time= 0.29666\n",
            "Epoch: 1145 train_loss= 0.40312 train_acc= 0.90275 val_roc= 0.64973 val_ap= 0.71584 time= 0.30342\n",
            "Epoch: 1146 train_loss= 0.40312 train_acc= 0.90277 val_roc= 0.64967 val_ap= 0.71581 time= 0.30167\n",
            "Epoch: 1147 train_loss= 0.40312 train_acc= 0.90280 val_roc= 0.64957 val_ap= 0.71575 time= 0.29842\n",
            "Epoch: 1148 train_loss= 0.40312 train_acc= 0.90284 val_roc= 0.64950 val_ap= 0.71568 time= 0.29686\n",
            "Epoch: 1149 train_loss= 0.40312 train_acc= 0.90287 val_roc= 0.64942 val_ap= 0.71563 time= 0.30842\n",
            "Epoch: 1150 train_loss= 0.40312 train_acc= 0.90290 val_roc= 0.64936 val_ap= 0.71558 time= 0.29581\n",
            "Epoch: 1151 train_loss= 0.40312 train_acc= 0.90291 val_roc= 0.64927 val_ap= 0.71550 time= 0.29581\n",
            "Epoch: 1152 train_loss= 0.40312 train_acc= 0.90293 val_roc= 0.64926 val_ap= 0.71548 time= 0.30132\n",
            "Epoch: 1153 train_loss= 0.40311 train_acc= 0.90296 val_roc= 0.64920 val_ap= 0.71543 time= 0.29805\n",
            "Epoch: 1154 train_loss= 0.40311 train_acc= 0.90298 val_roc= 0.64913 val_ap= 0.71540 time= 0.29820\n",
            "Epoch: 1155 train_loss= 0.40311 train_acc= 0.90300 val_roc= 0.64904 val_ap= 0.71537 time= 0.29717\n",
            "Epoch: 1156 train_loss= 0.40311 train_acc= 0.90303 val_roc= 0.64901 val_ap= 0.71534 time= 0.32339\n",
            "Epoch: 1157 train_loss= 0.40311 train_acc= 0.90305 val_roc= 0.64900 val_ap= 0.71535 time= 0.32298\n",
            "Epoch: 1158 train_loss= 0.40311 train_acc= 0.90308 val_roc= 0.64895 val_ap= 0.71527 time= 0.29619\n",
            "Epoch: 1159 train_loss= 0.40311 train_acc= 0.90311 val_roc= 0.64889 val_ap= 0.71524 time= 0.32187\n",
            "Epoch: 1160 train_loss= 0.40311 train_acc= 0.90313 val_roc= 0.64881 val_ap= 0.71516 time= 0.30067\n",
            "Epoch: 1161 train_loss= 0.40311 train_acc= 0.90315 val_roc= 0.64879 val_ap= 0.71515 time= 0.30104\n",
            "Epoch: 1162 train_loss= 0.40310 train_acc= 0.90317 val_roc= 0.64875 val_ap= 0.71513 time= 0.31197\n",
            "Epoch: 1163 train_loss= 0.40310 train_acc= 0.90319 val_roc= 0.64869 val_ap= 0.71509 time= 0.29731\n",
            "Epoch: 1164 train_loss= 0.40310 train_acc= 0.90321 val_roc= 0.64866 val_ap= 0.71504 time= 0.30007\n",
            "Epoch: 1165 train_loss= 0.40310 train_acc= 0.90324 val_roc= 0.64863 val_ap= 0.71505 time= 0.30227\n",
            "Epoch: 1166 train_loss= 0.40310 train_acc= 0.90326 val_roc= 0.64859 val_ap= 0.71500 time= 0.29586\n",
            "Epoch: 1167 train_loss= 0.40310 train_acc= 0.90329 val_roc= 0.64856 val_ap= 0.71499 time= 0.29847\n",
            "Epoch: 1168 train_loss= 0.40310 train_acc= 0.90333 val_roc= 0.64849 val_ap= 0.71492 time= 0.29964\n",
            "Epoch: 1169 train_loss= 0.40310 train_acc= 0.90337 val_roc= 0.64840 val_ap= 0.71485 time= 0.30375\n",
            "Epoch: 1170 train_loss= 0.40309 train_acc= 0.90339 val_roc= 0.64830 val_ap= 0.71481 time= 0.30173\n",
            "Epoch: 1171 train_loss= 0.40309 train_acc= 0.90341 val_roc= 0.64824 val_ap= 0.71475 time= 0.29749\n",
            "Epoch: 1172 train_loss= 0.40309 train_acc= 0.90343 val_roc= 0.64818 val_ap= 0.71471 time= 0.30740\n",
            "Epoch: 1173 train_loss= 0.40309 train_acc= 0.90344 val_roc= 0.64812 val_ap= 0.71465 time= 0.29509\n",
            "Epoch: 1174 train_loss= 0.40309 train_acc= 0.90346 val_roc= 0.64811 val_ap= 0.71462 time= 0.29429\n",
            "Epoch: 1175 train_loss= 0.40309 train_acc= 0.90347 val_roc= 0.64808 val_ap= 0.71459 time= 0.29563\n",
            "Epoch: 1176 train_loss= 0.40309 train_acc= 0.90349 val_roc= 0.64797 val_ap= 0.71452 time= 0.31460\n",
            "Epoch: 1177 train_loss= 0.40309 train_acc= 0.90351 val_roc= 0.64787 val_ap= 0.71446 time= 0.31418\n",
            "Epoch: 1178 train_loss= 0.40308 train_acc= 0.90353 val_roc= 0.64781 val_ap= 0.71445 time= 0.29411\n",
            "Epoch: 1179 train_loss= 0.40308 train_acc= 0.90355 val_roc= 0.64770 val_ap= 0.71439 time= 0.30538\n",
            "Epoch: 1180 train_loss= 0.40308 train_acc= 0.90357 val_roc= 0.64763 val_ap= 0.71433 time= 0.29992\n",
            "Epoch: 1181 train_loss= 0.40308 train_acc= 0.90359 val_roc= 0.64756 val_ap= 0.71422 time= 0.29950\n",
            "Epoch: 1182 train_loss= 0.40308 train_acc= 0.90360 val_roc= 0.64746 val_ap= 0.71409 time= 0.30535\n",
            "Epoch: 1183 train_loss= 0.40308 train_acc= 0.90363 val_roc= 0.64740 val_ap= 0.71405 time= 0.31161\n",
            "Epoch: 1184 train_loss= 0.40308 train_acc= 0.90364 val_roc= 0.64733 val_ap= 0.71403 time= 0.29558\n",
            "Epoch: 1185 train_loss= 0.40308 train_acc= 0.90365 val_roc= 0.64729 val_ap= 0.71398 time= 0.30173\n",
            "Epoch: 1186 train_loss= 0.40307 train_acc= 0.90366 val_roc= 0.64713 val_ap= 0.71385 time= 0.30442\n",
            "Epoch: 1187 train_loss= 0.40307 train_acc= 0.90367 val_roc= 0.64701 val_ap= 0.71376 time= 0.31121\n",
            "Epoch: 1188 train_loss= 0.40307 train_acc= 0.90368 val_roc= 0.64690 val_ap= 0.71368 time= 0.29709\n",
            "Epoch: 1189 train_loss= 0.40307 train_acc= 0.90369 val_roc= 0.64682 val_ap= 0.71360 time= 0.31588\n",
            "Epoch: 1190 train_loss= 0.40307 train_acc= 0.90370 val_roc= 0.64673 val_ap= 0.71351 time= 0.31916\n",
            "Epoch: 1191 train_loss= 0.40307 train_acc= 0.90371 val_roc= 0.64658 val_ap= 0.71338 time= 0.32436\n",
            "Epoch: 1192 train_loss= 0.40307 train_acc= 0.90371 val_roc= 0.64644 val_ap= 0.71330 time= 0.31632\n",
            "Epoch: 1193 train_loss= 0.40306 train_acc= 0.90372 val_roc= 0.64634 val_ap= 0.71324 time= 0.30111\n",
            "Epoch: 1194 train_loss= 0.40306 train_acc= 0.90373 val_roc= 0.64618 val_ap= 0.71313 time= 0.29727\n",
            "Epoch: 1195 train_loss= 0.40306 train_acc= 0.90373 val_roc= 0.64608 val_ap= 0.71305 time= 0.30536\n",
            "Epoch: 1196 train_loss= 0.40306 train_acc= 0.90374 val_roc= 0.64592 val_ap= 0.71294 time= 0.31529\n",
            "Epoch: 1197 train_loss= 0.40306 train_acc= 0.90376 val_roc= 0.64586 val_ap= 0.71291 time= 0.29734\n",
            "Epoch: 1198 train_loss= 0.40306 train_acc= 0.90377 val_roc= 0.64576 val_ap= 0.71283 time= 0.30136\n",
            "Epoch: 1199 train_loss= 0.40306 train_acc= 0.90378 val_roc= 0.64561 val_ap= 0.71274 time= 0.31796\n",
            "Epoch: 1200 train_loss= 0.40305 train_acc= 0.90380 val_roc= 0.64544 val_ap= 0.71261 time= 0.29532\n",
            "Epoch: 1201 train_loss= 0.40305 train_acc= 0.90382 val_roc= 0.64532 val_ap= 0.71250 time= 0.29812\n",
            "Epoch: 1202 train_loss= 0.40305 train_acc= 0.90383 val_roc= 0.64515 val_ap= 0.71234 time= 0.31304\n",
            "Epoch: 1203 train_loss= 0.40305 train_acc= 0.90385 val_roc= 0.64507 val_ap= 0.71229 time= 0.32040\n",
            "Epoch: 1204 train_loss= 0.40305 train_acc= 0.90387 val_roc= 0.64492 val_ap= 0.71217 time= 0.31167\n",
            "Epoch: 1205 train_loss= 0.40305 train_acc= 0.90387 val_roc= 0.64480 val_ap= 0.71206 time= 0.29842\n",
            "Epoch: 1206 train_loss= 0.40304 train_acc= 0.90389 val_roc= 0.64468 val_ap= 0.71197 time= 0.30915\n",
            "Epoch: 1207 train_loss= 0.40304 train_acc= 0.90390 val_roc= 0.64459 val_ap= 0.71190 time= 0.29835\n",
            "Epoch: 1208 train_loss= 0.40304 train_acc= 0.90391 val_roc= 0.64441 val_ap= 0.71176 time= 0.29475\n",
            "Epoch: 1209 train_loss= 0.40304 train_acc= 0.90393 val_roc= 0.64430 val_ap= 0.71168 time= 0.30470\n",
            "Epoch: 1210 train_loss= 0.40304 train_acc= 0.90393 val_roc= 0.64419 val_ap= 0.71153 time= 0.31264\n",
            "Epoch: 1211 train_loss= 0.40304 train_acc= 0.90394 val_roc= 0.64414 val_ap= 0.71147 time= 0.29855\n",
            "Epoch: 1212 train_loss= 0.40304 train_acc= 0.90398 val_roc= 0.64403 val_ap= 0.71140 time= 0.30843\n",
            "Epoch: 1213 train_loss= 0.40304 train_acc= 0.90401 val_roc= 0.64391 val_ap= 0.71132 time= 0.30696\n",
            "Epoch: 1214 train_loss= 0.40304 train_acc= 0.90406 val_roc= 0.64383 val_ap= 0.71128 time= 0.29864\n",
            "Epoch: 1215 train_loss= 0.40303 train_acc= 0.90412 val_roc= 0.64378 val_ap= 0.71125 time= 0.30545\n",
            "Epoch: 1216 train_loss= 0.40303 train_acc= 0.90414 val_roc= 0.64371 val_ap= 0.71120 time= 0.29615\n",
            "Epoch: 1217 train_loss= 0.40303 train_acc= 0.90416 val_roc= 0.64365 val_ap= 0.71113 time= 0.29949\n",
            "Epoch: 1218 train_loss= 0.40303 train_acc= 0.90418 val_roc= 0.64359 val_ap= 0.71110 time= 0.29721\n",
            "Epoch: 1219 train_loss= 0.40303 train_acc= 0.90420 val_roc= 0.64354 val_ap= 0.71106 time= 0.30430\n",
            "Epoch: 1220 train_loss= 0.40303 train_acc= 0.90422 val_roc= 0.64351 val_ap= 0.71100 time= 0.29856\n",
            "Epoch: 1221 train_loss= 0.40303 train_acc= 0.90424 val_roc= 0.64345 val_ap= 0.71096 time= 0.30380\n",
            "Epoch: 1222 train_loss= 0.40303 train_acc= 0.90425 val_roc= 0.64336 val_ap= 0.71093 time= 0.30309\n",
            "Epoch: 1223 train_loss= 0.40303 train_acc= 0.90427 val_roc= 0.64326 val_ap= 0.71086 time= 0.30299\n",
            "Epoch: 1224 train_loss= 0.40303 train_acc= 0.90428 val_roc= 0.64315 val_ap= 0.71082 time= 0.29962\n",
            "Epoch: 1225 train_loss= 0.40303 train_acc= 0.90430 val_roc= 0.64312 val_ap= 0.71081 time= 0.30110\n",
            "Epoch: 1226 train_loss= 0.40303 train_acc= 0.90431 val_roc= 0.64298 val_ap= 0.71073 time= 0.29626\n",
            "Epoch: 1227 train_loss= 0.40303 train_acc= 0.90433 val_roc= 0.64289 val_ap= 0.71063 time= 0.31144\n",
            "Epoch: 1228 train_loss= 0.40303 train_acc= 0.90434 val_roc= 0.64281 val_ap= 0.71058 time= 0.29837\n",
            "Epoch: 1229 train_loss= 0.40302 train_acc= 0.90435 val_roc= 0.64281 val_ap= 0.71059 time= 0.31073\n",
            "Epoch: 1230 train_loss= 0.40302 train_acc= 0.90436 val_roc= 0.64271 val_ap= 0.71052 time= 0.30011\n",
            "Epoch: 1231 train_loss= 0.40302 train_acc= 0.90437 val_roc= 0.64259 val_ap= 0.71044 time= 0.29723\n",
            "Epoch: 1232 train_loss= 0.40302 train_acc= 0.90438 val_roc= 0.64255 val_ap= 0.71040 time= 0.30657\n",
            "Epoch: 1233 train_loss= 0.40302 train_acc= 0.90440 val_roc= 0.64244 val_ap= 0.71035 time= 0.29566\n",
            "Epoch: 1234 train_loss= 0.40302 train_acc= 0.90442 val_roc= 0.64239 val_ap= 0.71033 time= 0.29807\n",
            "Epoch: 1235 train_loss= 0.40302 train_acc= 0.90444 val_roc= 0.64230 val_ap= 0.71026 time= 0.30674\n",
            "Epoch: 1236 train_loss= 0.40302 train_acc= 0.90447 val_roc= 0.64215 val_ap= 0.71021 time= 0.29749\n",
            "Epoch: 1237 train_loss= 0.40302 train_acc= 0.90449 val_roc= 0.64207 val_ap= 0.71015 time= 0.30328\n",
            "Epoch: 1238 train_loss= 0.40302 train_acc= 0.90451 val_roc= 0.64202 val_ap= 0.71009 time= 0.29812\n",
            "Epoch: 1239 train_loss= 0.40302 train_acc= 0.90452 val_roc= 0.64196 val_ap= 0.71005 time= 0.30683\n",
            "Epoch: 1240 train_loss= 0.40302 train_acc= 0.90454 val_roc= 0.64189 val_ap= 0.71000 time= 0.29753\n",
            "Epoch: 1241 train_loss= 0.40302 train_acc= 0.90456 val_roc= 0.64179 val_ap= 0.70994 time= 0.31248\n",
            "Epoch: 1242 train_loss= 0.40302 train_acc= 0.90456 val_roc= 0.64173 val_ap= 0.70993 time= 0.30350\n",
            "Epoch: 1243 train_loss= 0.40302 train_acc= 0.90458 val_roc= 0.64167 val_ap= 0.70989 time= 0.29872\n",
            "Epoch: 1244 train_loss= 0.40301 train_acc= 0.90460 val_roc= 0.64163 val_ap= 0.70987 time= 0.30301\n",
            "Epoch: 1245 train_loss= 0.40301 train_acc= 0.90461 val_roc= 0.64154 val_ap= 0.70983 time= 0.30370\n",
            "Epoch: 1246 train_loss= 0.40301 train_acc= 0.90463 val_roc= 0.64150 val_ap= 0.70984 time= 0.29576\n",
            "Epoch: 1247 train_loss= 0.40301 train_acc= 0.90464 val_roc= 0.64149 val_ap= 0.70983 time= 0.30233\n",
            "Epoch: 1248 train_loss= 0.40301 train_acc= 0.90466 val_roc= 0.64142 val_ap= 0.70978 time= 0.30419\n",
            "Epoch: 1249 train_loss= 0.40301 train_acc= 0.90468 val_roc= 0.64138 val_ap= 0.70977 time= 0.30837\n",
            "Epoch: 1250 train_loss= 0.40301 train_acc= 0.90470 val_roc= 0.64130 val_ap= 0.70972 time= 0.29948\n",
            "Epoch: 1251 train_loss= 0.40301 train_acc= 0.90475 val_roc= 0.64121 val_ap= 0.70963 time= 0.30432\n",
            "Epoch: 1252 train_loss= 0.40301 train_acc= 0.90476 val_roc= 0.64110 val_ap= 0.70955 time= 0.30103\n",
            "Epoch: 1253 train_loss= 0.40301 train_acc= 0.90479 val_roc= 0.64106 val_ap= 0.70952 time= 0.29974\n",
            "Epoch: 1254 train_loss= 0.40301 train_acc= 0.90482 val_roc= 0.64091 val_ap= 0.70942 time= 0.29628\n",
            "Epoch: 1255 train_loss= 0.40301 train_acc= 0.90483 val_roc= 0.64083 val_ap= 0.70935 time= 0.31330\n",
            "Epoch: 1256 train_loss= 0.40301 train_acc= 0.90485 val_roc= 0.64074 val_ap= 0.70931 time= 0.29330\n",
            "Epoch: 1257 train_loss= 0.40301 train_acc= 0.90486 val_roc= 0.64067 val_ap= 0.70927 time= 0.30077\n",
            "Epoch: 1258 train_loss= 0.40301 train_acc= 0.90487 val_roc= 0.64060 val_ap= 0.70924 time= 0.30079\n",
            "Epoch: 1259 train_loss= 0.40300 train_acc= 0.90489 val_roc= 0.64058 val_ap= 0.70922 time= 0.32314\n",
            "Epoch: 1260 train_loss= 0.40300 train_acc= 0.90491 val_roc= 0.64048 val_ap= 0.70916 time= 0.30115\n",
            "Epoch: 1261 train_loss= 0.40300 train_acc= 0.90492 val_roc= 0.64043 val_ap= 0.70914 time= 0.30140\n",
            "Epoch: 1262 train_loss= 0.40300 train_acc= 0.90493 val_roc= 0.64037 val_ap= 0.70910 time= 0.31823\n",
            "Epoch: 1263 train_loss= 0.40300 train_acc= 0.90495 val_roc= 0.64018 val_ap= 0.70898 time= 0.30120\n",
            "Epoch: 1264 train_loss= 0.40300 train_acc= 0.90496 val_roc= 0.64013 val_ap= 0.70896 time= 0.31740\n",
            "Epoch: 1265 train_loss= 0.40300 train_acc= 0.90497 val_roc= 0.64008 val_ap= 0.70893 time= 0.30220\n",
            "Epoch: 1266 train_loss= 0.40300 train_acc= 0.90498 val_roc= 0.64002 val_ap= 0.70890 time= 0.29797\n",
            "Epoch: 1267 train_loss= 0.40300 train_acc= 0.90500 val_roc= 0.63990 val_ap= 0.70884 time= 0.29780\n",
            "Epoch: 1268 train_loss= 0.40300 train_acc= 0.90501 val_roc= 0.63983 val_ap= 0.70879 time= 0.32693\n",
            "Epoch: 1269 train_loss= 0.40300 train_acc= 0.90501 val_roc= 0.63977 val_ap= 0.70876 time= 0.32487\n",
            "Epoch: 1270 train_loss= 0.40300 train_acc= 0.90502 val_roc= 0.63972 val_ap= 0.70873 time= 0.31695\n",
            "Epoch: 1271 train_loss= 0.40300 train_acc= 0.90503 val_roc= 0.63970 val_ap= 0.70874 time= 0.29865\n",
            "Epoch: 1272 train_loss= 0.40300 train_acc= 0.90504 val_roc= 0.63963 val_ap= 0.70869 time= 0.30356\n",
            "Epoch: 1273 train_loss= 0.40300 train_acc= 0.90506 val_roc= 0.63956 val_ap= 0.70867 time= 0.30452\n",
            "Epoch: 1274 train_loss= 0.40300 train_acc= 0.90508 val_roc= 0.63953 val_ap= 0.70866 time= 0.30566\n",
            "Epoch: 1275 train_loss= 0.40299 train_acc= 0.90509 val_roc= 0.63946 val_ap= 0.70864 time= 0.32033\n",
            "Epoch: 1276 train_loss= 0.40299 train_acc= 0.90510 val_roc= 0.63944 val_ap= 0.70865 time= 0.29892\n",
            "Epoch: 1277 train_loss= 0.40299 train_acc= 0.90512 val_roc= 0.63933 val_ap= 0.70858 time= 0.29658\n",
            "Epoch: 1278 train_loss= 0.40299 train_acc= 0.90513 val_roc= 0.63926 val_ap= 0.70851 time= 0.30280\n",
            "Epoch: 1279 train_loss= 0.40299 train_acc= 0.90514 val_roc= 0.63920 val_ap= 0.70847 time= 0.30019\n",
            "Epoch: 1280 train_loss= 0.40299 train_acc= 0.90516 val_roc= 0.63909 val_ap= 0.70841 time= 0.30346\n",
            "Epoch: 1281 train_loss= 0.40299 train_acc= 0.90517 val_roc= 0.63902 val_ap= 0.70839 time= 0.31242\n",
            "Epoch: 1282 train_loss= 0.40299 train_acc= 0.90518 val_roc= 0.63900 val_ap= 0.70837 time= 0.33067\n",
            "Epoch: 1283 train_loss= 0.40299 train_acc= 0.90519 val_roc= 0.63895 val_ap= 0.70835 time= 0.31133\n",
            "Epoch: 1284 train_loss= 0.40299 train_acc= 0.90520 val_roc= 0.63890 val_ap= 0.70833 time= 0.31291\n",
            "Epoch: 1285 train_loss= 0.40299 train_acc= 0.90522 val_roc= 0.63885 val_ap= 0.70830 time= 0.30283\n",
            "Epoch: 1286 train_loss= 0.40299 train_acc= 0.90523 val_roc= 0.63880 val_ap= 0.70823 time= 0.29603\n",
            "Epoch: 1287 train_loss= 0.40299 train_acc= 0.90525 val_roc= 0.63871 val_ap= 0.70820 time= 0.31570\n",
            "Epoch: 1288 train_loss= 0.40299 train_acc= 0.90527 val_roc= 0.63870 val_ap= 0.70820 time= 0.32392\n",
            "Epoch: 1289 train_loss= 0.40299 train_acc= 0.90529 val_roc= 0.63867 val_ap= 0.70819 time= 0.29956\n",
            "Epoch: 1290 train_loss= 0.40299 train_acc= 0.90530 val_roc= 0.63860 val_ap= 0.70814 time= 0.31861\n",
            "Epoch: 1291 train_loss= 0.40298 train_acc= 0.90531 val_roc= 0.63856 val_ap= 0.70812 time= 0.32812\n",
            "Epoch: 1292 train_loss= 0.40298 train_acc= 0.90532 val_roc= 0.63853 val_ap= 0.70809 time= 0.31847\n",
            "Epoch: 1293 train_loss= 0.40298 train_acc= 0.90533 val_roc= 0.63843 val_ap= 0.70803 time= 0.30910\n",
            "Epoch: 1294 train_loss= 0.40298 train_acc= 0.90534 val_roc= 0.63838 val_ap= 0.70800 time= 0.30411\n",
            "Epoch: 1295 train_loss= 0.40298 train_acc= 0.90535 val_roc= 0.63832 val_ap= 0.70794 time= 0.30502\n",
            "Epoch: 1296 train_loss= 0.40298 train_acc= 0.90535 val_roc= 0.63829 val_ap= 0.70792 time= 0.30074\n",
            "Epoch: 1297 train_loss= 0.40298 train_acc= 0.90536 val_roc= 0.63830 val_ap= 0.70792 time= 0.32027\n",
            "Epoch: 1298 train_loss= 0.40298 train_acc= 0.90538 val_roc= 0.63829 val_ap= 0.70787 time= 0.30949\n",
            "Epoch: 1299 train_loss= 0.40298 train_acc= 0.90539 val_roc= 0.63827 val_ap= 0.70786 time= 0.29826\n",
            "Epoch: 1300 train_loss= 0.40298 train_acc= 0.90540 val_roc= 0.63822 val_ap= 0.70783 time= 0.31824\n",
            "Epoch: 1301 train_loss= 0.40298 train_acc= 0.90542 val_roc= 0.63819 val_ap= 0.70781 time= 0.33168\n",
            "Epoch: 1302 train_loss= 0.40298 train_acc= 0.90543 val_roc= 0.63816 val_ap= 0.70777 time= 0.31040\n",
            "Epoch: 1303 train_loss= 0.40298 train_acc= 0.90545 val_roc= 0.63807 val_ap= 0.70771 time= 0.31142\n",
            "Epoch: 1304 train_loss= 0.40298 train_acc= 0.90546 val_roc= 0.63803 val_ap= 0.70770 time= 0.33325\n",
            "Epoch: 1305 train_loss= 0.40298 train_acc= 0.90547 val_roc= 0.63805 val_ap= 0.70771 time= 0.31109\n",
            "Epoch: 1306 train_loss= 0.40298 train_acc= 0.90548 val_roc= 0.63798 val_ap= 0.70766 time= 0.29500\n",
            "Epoch: 1307 train_loss= 0.40298 train_acc= 0.90550 val_roc= 0.63793 val_ap= 0.70756 time= 0.30317\n",
            "Epoch: 1308 train_loss= 0.40298 train_acc= 0.90551 val_roc= 0.63791 val_ap= 0.70755 time= 0.30294\n",
            "Epoch: 1309 train_loss= 0.40297 train_acc= 0.90552 val_roc= 0.63786 val_ap= 0.70756 time= 0.31342\n",
            "Epoch: 1310 train_loss= 0.40297 train_acc= 0.90553 val_roc= 0.63784 val_ap= 0.70755 time= 0.29592\n",
            "Epoch: 1311 train_loss= 0.40297 train_acc= 0.90556 val_roc= 0.63779 val_ap= 0.70751 time= 0.30404\n",
            "Epoch: 1312 train_loss= 0.40297 train_acc= 0.90558 val_roc= 0.63771 val_ap= 0.70747 time= 0.30203\n",
            "Epoch: 1313 train_loss= 0.40297 train_acc= 0.90559 val_roc= 0.63763 val_ap= 0.70743 time= 0.32119\n",
            "Epoch: 1314 train_loss= 0.40297 train_acc= 0.90561 val_roc= 0.63755 val_ap= 0.70742 time= 0.32375\n",
            "Epoch: 1315 train_loss= 0.40297 train_acc= 0.90563 val_roc= 0.63752 val_ap= 0.70741 time= 0.32291\n",
            "Epoch: 1316 train_loss= 0.40297 train_acc= 0.90564 val_roc= 0.63747 val_ap= 0.70738 time= 0.29427\n",
            "Epoch: 1317 train_loss= 0.40297 train_acc= 0.90566 val_roc= 0.63739 val_ap= 0.70733 time= 0.30659\n",
            "Epoch: 1318 train_loss= 0.40297 train_acc= 0.90568 val_roc= 0.63736 val_ap= 0.70731 time= 0.29560\n",
            "Epoch: 1319 train_loss= 0.40297 train_acc= 0.90569 val_roc= 0.63733 val_ap= 0.70729 time= 0.31046\n",
            "Epoch: 1320 train_loss= 0.40297 train_acc= 0.90572 val_roc= 0.63728 val_ap= 0.70726 time= 0.31914\n",
            "Epoch: 1321 train_loss= 0.40297 train_acc= 0.90573 val_roc= 0.63716 val_ap= 0.70720 time= 0.32538\n",
            "Epoch: 1322 train_loss= 0.40297 train_acc= 0.90574 val_roc= 0.63707 val_ap= 0.70713 time= 0.32279\n",
            "Epoch: 1323 train_loss= 0.40297 train_acc= 0.90577 val_roc= 0.63701 val_ap= 0.70713 time= 0.29652\n",
            "Epoch: 1324 train_loss= 0.40297 train_acc= 0.90579 val_roc= 0.63696 val_ap= 0.70712 time= 0.30221\n",
            "Epoch: 1325 train_loss= 0.40297 train_acc= 0.90581 val_roc= 0.63689 val_ap= 0.70709 time= 0.29855\n",
            "Epoch: 1326 train_loss= 0.40297 train_acc= 0.90582 val_roc= 0.63682 val_ap= 0.70705 time= 0.33063\n",
            "Epoch: 1327 train_loss= 0.40297 train_acc= 0.90584 val_roc= 0.63677 val_ap= 0.70701 time= 0.31775\n",
            "Epoch: 1328 train_loss= 0.40296 train_acc= 0.90586 val_roc= 0.63673 val_ap= 0.70699 time= 0.29561\n",
            "Epoch: 1329 train_loss= 0.40296 train_acc= 0.90588 val_roc= 0.63669 val_ap= 0.70697 time= 0.29975\n",
            "Epoch: 1330 train_loss= 0.40296 train_acc= 0.90589 val_roc= 0.63667 val_ap= 0.70695 time= 0.30155\n",
            "Epoch: 1331 train_loss= 0.40296 train_acc= 0.90590 val_roc= 0.63663 val_ap= 0.70694 time= 0.30162\n",
            "Epoch: 1332 train_loss= 0.40296 train_acc= 0.90592 val_roc= 0.63664 val_ap= 0.70695 time= 0.31700\n",
            "Epoch: 1333 train_loss= 0.40296 train_acc= 0.90593 val_roc= 0.63664 val_ap= 0.70695 time= 0.32312\n",
            "Epoch: 1334 train_loss= 0.40296 train_acc= 0.90595 val_roc= 0.63658 val_ap= 0.70691 time= 0.32994\n",
            "Epoch: 1335 train_loss= 0.40296 train_acc= 0.90597 val_roc= 0.63651 val_ap= 0.70677 time= 0.30327\n",
            "Epoch: 1336 train_loss= 0.40296 train_acc= 0.90598 val_roc= 0.63644 val_ap= 0.70674 time= 0.31395\n",
            "Epoch: 1337 train_loss= 0.40296 train_acc= 0.90599 val_roc= 0.63636 val_ap= 0.70669 time= 0.32615\n",
            "Epoch: 1338 train_loss= 0.40296 train_acc= 0.90600 val_roc= 0.63633 val_ap= 0.70666 time= 0.31128\n",
            "Epoch: 1339 train_loss= 0.40296 train_acc= 0.90601 val_roc= 0.63626 val_ap= 0.70664 time= 0.30030\n",
            "Epoch: 1340 train_loss= 0.40296 train_acc= 0.90602 val_roc= 0.63623 val_ap= 0.70662 time= 0.31914\n",
            "Epoch: 1341 train_loss= 0.40296 train_acc= 0.90603 val_roc= 0.63617 val_ap= 0.70659 time= 0.30373\n",
            "Epoch: 1342 train_loss= 0.40296 train_acc= 0.90603 val_roc= 0.63609 val_ap= 0.70655 time= 0.32013\n",
            "Epoch: 1343 train_loss= 0.40296 train_acc= 0.90605 val_roc= 0.63604 val_ap= 0.70651 time= 0.31852\n",
            "Epoch: 1344 train_loss= 0.40296 train_acc= 0.90605 val_roc= 0.63600 val_ap= 0.70649 time= 0.30023\n",
            "Epoch: 1345 train_loss= 0.40296 train_acc= 0.90606 val_roc= 0.63595 val_ap= 0.70647 time= 0.29947\n",
            "Epoch: 1346 train_loss= 0.40296 train_acc= 0.90607 val_roc= 0.63593 val_ap= 0.70647 time= 0.29905\n",
            "Epoch: 1347 train_loss= 0.40296 train_acc= 0.90608 val_roc= 0.63590 val_ap= 0.70645 time= 0.30262\n",
            "Epoch: 1348 train_loss= 0.40295 train_acc= 0.90609 val_roc= 0.63587 val_ap= 0.70644 time= 0.31764\n",
            "Epoch: 1349 train_loss= 0.40295 train_acc= 0.90610 val_roc= 0.63583 val_ap= 0.70639 time= 0.31284\n",
            "Epoch: 1350 train_loss= 0.40295 train_acc= 0.90611 val_roc= 0.63577 val_ap= 0.70634 time= 0.30993\n",
            "Epoch: 1351 train_loss= 0.40295 train_acc= 0.90612 val_roc= 0.63572 val_ap= 0.70632 time= 0.30046\n",
            "Epoch: 1352 train_loss= 0.40295 train_acc= 0.90613 val_roc= 0.63571 val_ap= 0.70631 time= 0.32134\n",
            "Epoch: 1353 train_loss= 0.40295 train_acc= 0.90614 val_roc= 0.63565 val_ap= 0.70626 time= 0.32319\n",
            "Epoch: 1354 train_loss= 0.40295 train_acc= 0.90615 val_roc= 0.63558 val_ap= 0.70622 time= 0.30744\n",
            "Epoch: 1355 train_loss= 0.40295 train_acc= 0.90617 val_roc= 0.63552 val_ap= 0.70618 time= 0.30053\n",
            "Epoch: 1356 train_loss= 0.40295 train_acc= 0.90618 val_roc= 0.63543 val_ap= 0.70612 time= 0.30671\n",
            "Epoch: 1357 train_loss= 0.40295 train_acc= 0.90620 val_roc= 0.63536 val_ap= 0.70608 time= 0.29960\n",
            "Epoch: 1358 train_loss= 0.40295 train_acc= 0.90621 val_roc= 0.63530 val_ap= 0.70604 time= 0.29470\n",
            "Epoch: 1359 train_loss= 0.40295 train_acc= 0.90622 val_roc= 0.63529 val_ap= 0.70604 time= 0.29841\n",
            "Epoch: 1360 train_loss= 0.40295 train_acc= 0.90624 val_roc= 0.63526 val_ap= 0.70603 time= 0.30091\n",
            "Epoch: 1361 train_loss= 0.40295 train_acc= 0.90625 val_roc= 0.63527 val_ap= 0.70604 time= 0.29725\n",
            "Epoch: 1362 train_loss= 0.40295 train_acc= 0.90626 val_roc= 0.63526 val_ap= 0.70602 time= 0.32473\n",
            "Epoch: 1363 train_loss= 0.40295 train_acc= 0.90627 val_roc= 0.63519 val_ap= 0.70598 time= 0.30254\n",
            "Epoch: 1364 train_loss= 0.40295 train_acc= 0.90628 val_roc= 0.63514 val_ap= 0.70595 time= 0.30990\n",
            "Epoch: 1365 train_loss= 0.40294 train_acc= 0.90629 val_roc= 0.63510 val_ap= 0.70591 time= 0.32010\n",
            "Epoch: 1366 train_loss= 0.40294 train_acc= 0.90631 val_roc= 0.63504 val_ap= 0.70585 time= 0.32610\n",
            "Epoch: 1367 train_loss= 0.40294 train_acc= 0.90632 val_roc= 0.63505 val_ap= 0.70586 time= 0.30709\n",
            "Epoch: 1368 train_loss= 0.40294 train_acc= 0.90634 val_roc= 0.63498 val_ap= 0.70583 time= 0.29459\n",
            "Epoch: 1369 train_loss= 0.40294 train_acc= 0.90634 val_roc= 0.63494 val_ap= 0.70578 time= 0.30010\n",
            "Epoch: 1370 train_loss= 0.40294 train_acc= 0.90633 val_roc= 0.63495 val_ap= 0.70579 time= 0.29987\n",
            "Epoch: 1371 train_loss= 0.40294 train_acc= 0.90635 val_roc= 0.63492 val_ap= 0.70574 time= 0.29512\n",
            "Epoch: 1372 train_loss= 0.40294 train_acc= 0.90636 val_roc= 0.63491 val_ap= 0.70572 time= 0.29929\n",
            "Epoch: 1373 train_loss= 0.40294 train_acc= 0.90638 val_roc= 0.63481 val_ap= 0.70566 time= 0.31143\n",
            "Epoch: 1374 train_loss= 0.40294 train_acc= 0.90640 val_roc= 0.63475 val_ap= 0.70562 time= 0.29759\n",
            "Epoch: 1375 train_loss= 0.40294 train_acc= 0.90641 val_roc= 0.63470 val_ap= 0.70559 time= 0.29551\n",
            "Epoch: 1376 train_loss= 0.40294 train_acc= 0.90642 val_roc= 0.63466 val_ap= 0.70555 time= 0.30284\n",
            "Epoch: 1377 train_loss= 0.40294 train_acc= 0.90643 val_roc= 0.63467 val_ap= 0.70555 time= 0.30317\n",
            "Epoch: 1378 train_loss= 0.40294 train_acc= 0.90644 val_roc= 0.63460 val_ap= 0.70551 time= 0.29577\n",
            "Epoch: 1379 train_loss= 0.40294 train_acc= 0.90645 val_roc= 0.63455 val_ap= 0.70549 time= 0.29823\n",
            "Epoch: 1380 train_loss= 0.40294 train_acc= 0.90646 val_roc= 0.63449 val_ap= 0.70547 time= 0.31409\n",
            "Epoch: 1381 train_loss= 0.40294 train_acc= 0.90647 val_roc= 0.63451 val_ap= 0.70548 time= 0.30009\n",
            "Epoch: 1382 train_loss= 0.40293 train_acc= 0.90648 val_roc= 0.63450 val_ap= 0.70548 time= 0.30013\n",
            "Epoch: 1383 train_loss= 0.40293 train_acc= 0.90648 val_roc= 0.63448 val_ap= 0.70548 time= 0.30429\n",
            "Epoch: 1384 train_loss= 0.40293 train_acc= 0.90649 val_roc= 0.63450 val_ap= 0.70551 time= 0.29924\n",
            "Epoch: 1385 train_loss= 0.40293 train_acc= 0.90650 val_roc= 0.63446 val_ap= 0.70548 time= 0.30165\n",
            "Epoch: 1386 train_loss= 0.40293 train_acc= 0.90650 val_roc= 0.63447 val_ap= 0.70548 time= 0.30590\n",
            "Epoch: 1387 train_loss= 0.40293 train_acc= 0.90651 val_roc= 0.63445 val_ap= 0.70546 time= 0.30201\n",
            "Epoch: 1388 train_loss= 0.40293 train_acc= 0.90652 val_roc= 0.63450 val_ap= 0.70548 time= 0.29940\n",
            "Epoch: 1389 train_loss= 0.40293 train_acc= 0.90652 val_roc= 0.63444 val_ap= 0.70544 time= 0.30087\n",
            "Epoch: 1390 train_loss= 0.40293 train_acc= 0.90653 val_roc= 0.63446 val_ap= 0.70542 time= 0.30963\n",
            "Epoch: 1391 train_loss= 0.40293 train_acc= 0.90653 val_roc= 0.63448 val_ap= 0.70543 time= 0.29895\n",
            "Epoch: 1392 train_loss= 0.40293 train_acc= 0.90654 val_roc= 0.63442 val_ap= 0.70540 time= 0.29940\n",
            "Epoch: 1393 train_loss= 0.40293 train_acc= 0.90654 val_roc= 0.63443 val_ap= 0.70538 time= 0.30527\n",
            "Epoch: 1394 train_loss= 0.40293 train_acc= 0.90655 val_roc= 0.63444 val_ap= 0.70538 time= 0.30755\n",
            "Epoch: 1395 train_loss= 0.40293 train_acc= 0.90654 val_roc= 0.63445 val_ap= 0.70538 time= 0.30215\n",
            "Epoch: 1396 train_loss= 0.40293 train_acc= 0.90655 val_roc= 0.63445 val_ap= 0.70537 time= 0.30397\n",
            "Epoch: 1397 train_loss= 0.40293 train_acc= 0.90655 val_roc= 0.63446 val_ap= 0.70534 time= 0.29805\n",
            "Epoch: 1398 train_loss= 0.40292 train_acc= 0.90656 val_roc= 0.63443 val_ap= 0.70532 time= 0.32027\n",
            "Epoch: 1399 train_loss= 0.40292 train_acc= 0.90657 val_roc= 0.63435 val_ap= 0.70530 time= 0.31507\n",
            "Epoch: 1400 train_loss= 0.40292 train_acc= 0.90658 val_roc= 0.63433 val_ap= 0.70528 time= 0.31507\n",
            "Epoch: 1401 train_loss= 0.40292 train_acc= 0.90659 val_roc= 0.63430 val_ap= 0.70526 time= 0.29398\n",
            "Epoch: 1402 train_loss= 0.40292 train_acc= 0.90660 val_roc= 0.63431 val_ap= 0.70526 time= 0.29498\n",
            "Epoch: 1403 train_loss= 0.40292 train_acc= 0.90661 val_roc= 0.63430 val_ap= 0.70526 time= 0.29855\n",
            "Epoch: 1404 train_loss= 0.40292 train_acc= 0.90662 val_roc= 0.63428 val_ap= 0.70523 time= 0.29524\n",
            "Epoch: 1405 train_loss= 0.40292 train_acc= 0.90663 val_roc= 0.63426 val_ap= 0.70520 time= 0.29725\n",
            "Epoch: 1406 train_loss= 0.40292 train_acc= 0.90664 val_roc= 0.63430 val_ap= 0.70518 time= 0.30940\n",
            "Epoch: 1407 train_loss= 0.40292 train_acc= 0.90664 val_roc= 0.63429 val_ap= 0.70515 time= 0.29939\n",
            "Epoch: 1408 train_loss= 0.40292 train_acc= 0.90664 val_roc= 0.63428 val_ap= 0.70516 time= 0.29571\n",
            "Epoch: 1409 train_loss= 0.40292 train_acc= 0.90665 val_roc= 0.63430 val_ap= 0.70516 time= 0.29616\n",
            "Epoch: 1410 train_loss= 0.40292 train_acc= 0.90666 val_roc= 0.63428 val_ap= 0.70513 time= 0.30012\n",
            "Epoch: 1411 train_loss= 0.40292 train_acc= 0.90667 val_roc= 0.63425 val_ap= 0.70509 time= 0.30125\n",
            "Epoch: 1412 train_loss= 0.40292 train_acc= 0.90668 val_roc= 0.63425 val_ap= 0.70509 time= 0.29961\n",
            "Epoch: 1413 train_loss= 0.40292 train_acc= 0.90669 val_roc= 0.63420 val_ap= 0.70507 time= 0.30381\n",
            "Epoch: 1414 train_loss= 0.40292 train_acc= 0.90670 val_roc= 0.63422 val_ap= 0.70509 time= 0.29277\n",
            "Epoch: 1415 train_loss= 0.40291 train_acc= 0.90670 val_roc= 0.63418 val_ap= 0.70506 time= 0.29602\n",
            "Epoch: 1416 train_loss= 0.40291 train_acc= 0.90671 val_roc= 0.63418 val_ap= 0.70504 time= 0.30418\n",
            "Epoch: 1417 train_loss= 0.40291 train_acc= 0.90671 val_roc= 0.63419 val_ap= 0.70506 time= 0.32569\n",
            "Epoch: 1418 train_loss= 0.40291 train_acc= 0.90671 val_roc= 0.63418 val_ap= 0.70505 time= 0.30863\n",
            "Epoch: 1419 train_loss= 0.40291 train_acc= 0.90672 val_roc= 0.63419 val_ap= 0.70505 time= 0.29537\n",
            "Epoch: 1420 train_loss= 0.40291 train_acc= 0.90673 val_roc= 0.63417 val_ap= 0.70505 time= 0.31018\n",
            "Epoch: 1421 train_loss= 0.40291 train_acc= 0.90673 val_roc= 0.63416 val_ap= 0.70504 time= 0.29652\n",
            "Epoch: 1422 train_loss= 0.40291 train_acc= 0.90673 val_roc= 0.63412 val_ap= 0.70501 time= 0.29536\n",
            "Epoch: 1423 train_loss= 0.40291 train_acc= 0.90674 val_roc= 0.63414 val_ap= 0.70502 time= 0.29889\n",
            "Epoch: 1424 train_loss= 0.40291 train_acc= 0.90674 val_roc= 0.63411 val_ap= 0.70500 time= 0.29869\n",
            "Epoch: 1425 train_loss= 0.40291 train_acc= 0.90674 val_roc= 0.63410 val_ap= 0.70499 time= 0.31354\n",
            "Epoch: 1426 train_loss= 0.40291 train_acc= 0.90674 val_roc= 0.63405 val_ap= 0.70498 time= 0.29486\n",
            "Epoch: 1427 train_loss= 0.40291 train_acc= 0.90675 val_roc= 0.63405 val_ap= 0.70498 time= 0.30310\n",
            "Epoch: 1428 train_loss= 0.40291 train_acc= 0.90675 val_roc= 0.63406 val_ap= 0.70499 time= 0.29438\n",
            "Epoch: 1429 train_loss= 0.40291 train_acc= 0.90676 val_roc= 0.63402 val_ap= 0.70496 time= 0.29548\n",
            "Epoch: 1430 train_loss= 0.40291 train_acc= 0.90677 val_roc= 0.63405 val_ap= 0.70498 time= 0.31676\n",
            "Epoch: 1431 train_loss= 0.40290 train_acc= 0.90678 val_roc= 0.63403 val_ap= 0.70497 time= 0.32294\n",
            "Epoch: 1432 train_loss= 0.40290 train_acc= 0.90678 val_roc= 0.63398 val_ap= 0.70492 time= 0.31377\n",
            "Epoch: 1433 train_loss= 0.40290 train_acc= 0.90679 val_roc= 0.63396 val_ap= 0.70491 time= 0.30229\n",
            "Epoch: 1434 train_loss= 0.40290 train_acc= 0.90679 val_roc= 0.63396 val_ap= 0.70488 time= 0.29715\n",
            "Epoch: 1435 train_loss= 0.40290 train_acc= 0.90680 val_roc= 0.63386 val_ap= 0.70482 time= 0.29613\n",
            "Epoch: 1436 train_loss= 0.40290 train_acc= 0.90680 val_roc= 0.63383 val_ap= 0.70481 time= 0.29643\n",
            "Epoch: 1437 train_loss= 0.40290 train_acc= 0.90681 val_roc= 0.63382 val_ap= 0.70480 time= 0.30755\n",
            "Epoch: 1438 train_loss= 0.40290 train_acc= 0.90682 val_roc= 0.63380 val_ap= 0.70480 time= 0.29453\n",
            "Epoch: 1439 train_loss= 0.40290 train_acc= 0.90683 val_roc= 0.63377 val_ap= 0.70478 time= 0.29541\n",
            "Epoch: 1440 train_loss= 0.40290 train_acc= 0.90684 val_roc= 0.63375 val_ap= 0.70477 time= 0.30968\n",
            "Epoch: 1441 train_loss= 0.40290 train_acc= 0.90686 val_roc= 0.63371 val_ap= 0.70474 time= 0.29665\n",
            "Epoch: 1442 train_loss= 0.40290 train_acc= 0.90686 val_roc= 0.63370 val_ap= 0.70471 time= 0.29724\n",
            "Epoch: 1443 train_loss= 0.40290 train_acc= 0.90687 val_roc= 0.63369 val_ap= 0.70469 time= 0.30023\n",
            "Epoch: 1444 train_loss= 0.40290 train_acc= 0.90687 val_roc= 0.63365 val_ap= 0.70466 time= 0.29665\n",
            "Epoch: 1445 train_loss= 0.40290 train_acc= 0.90689 val_roc= 0.63364 val_ap= 0.70466 time= 0.30105\n",
            "Epoch: 1446 train_loss= 0.40290 train_acc= 0.90689 val_roc= 0.63363 val_ap= 0.70466 time= 0.29439\n",
            "Epoch: 1447 train_loss= 0.40290 train_acc= 0.90690 val_roc= 0.63364 val_ap= 0.70468 time= 0.30528\n",
            "Epoch: 1448 train_loss= 0.40289 train_acc= 0.90690 val_roc= 0.63361 val_ap= 0.70466 time= 0.29610\n",
            "Epoch: 1449 train_loss= 0.40289 train_acc= 0.90691 val_roc= 0.63356 val_ap= 0.70462 time= 0.30064\n",
            "Epoch: 1450 train_loss= 0.40289 train_acc= 0.90692 val_roc= 0.63352 val_ap= 0.70459 time= 0.30111\n",
            "Epoch: 1451 train_loss= 0.40289 train_acc= 0.90692 val_roc= 0.63351 val_ap= 0.70457 time= 0.29919\n",
            "Epoch: 1452 train_loss= 0.40289 train_acc= 0.90693 val_roc= 0.63347 val_ap= 0.70454 time= 0.31645\n",
            "Epoch: 1453 train_loss= 0.40289 train_acc= 0.90694 val_roc= 0.63349 val_ap= 0.70454 time= 0.31177\n",
            "Epoch: 1454 train_loss= 0.40289 train_acc= 0.90694 val_roc= 0.63346 val_ap= 0.70451 time= 0.29908\n",
            "Epoch: 1455 train_loss= 0.40289 train_acc= 0.90695 val_roc= 0.63341 val_ap= 0.70447 time= 0.29659\n",
            "Epoch: 1456 train_loss= 0.40289 train_acc= 0.90696 val_roc= 0.63337 val_ap= 0.70448 time= 0.29460\n",
            "Epoch: 1457 train_loss= 0.40289 train_acc= 0.90697 val_roc= 0.63334 val_ap= 0.70446 time= 0.30662\n",
            "Epoch: 1458 train_loss= 0.40289 train_acc= 0.90697 val_roc= 0.63338 val_ap= 0.70448 time= 0.29593\n",
            "Epoch: 1459 train_loss= 0.40289 train_acc= 0.90698 val_roc= 0.63330 val_ap= 0.70445 time= 0.29563\n",
            "Epoch: 1460 train_loss= 0.40289 train_acc= 0.90699 val_roc= 0.63328 val_ap= 0.70443 time= 0.30622\n",
            "Epoch: 1461 train_loss= 0.40289 train_acc= 0.90700 val_roc= 0.63325 val_ap= 0.70442 time= 0.29532\n",
            "Epoch: 1462 train_loss= 0.40289 train_acc= 0.90700 val_roc= 0.63323 val_ap= 0.70441 time= 0.29456\n",
            "Epoch: 1463 train_loss= 0.40289 train_acc= 0.90701 val_roc= 0.63319 val_ap= 0.70438 time= 0.31652\n",
            "Epoch: 1464 train_loss= 0.40289 train_acc= 0.90702 val_roc= 0.63316 val_ap= 0.70434 time= 0.32689\n",
            "Epoch: 1465 train_loss= 0.40289 train_acc= 0.90702 val_roc= 0.63308 val_ap= 0.70428 time= 0.29573\n",
            "Epoch: 1466 train_loss= 0.40289 train_acc= 0.90703 val_roc= 0.63310 val_ap= 0.70427 time= 0.29970\n",
            "Epoch: 1467 train_loss= 0.40289 train_acc= 0.90703 val_roc= 0.63310 val_ap= 0.70429 time= 0.30416\n",
            "Epoch: 1468 train_loss= 0.40289 train_acc= 0.90704 val_roc= 0.63306 val_ap= 0.70426 time= 0.30486\n",
            "Epoch: 1469 train_loss= 0.40289 train_acc= 0.90704 val_roc= 0.63301 val_ap= 0.70417 time= 0.29767\n",
            "Epoch: 1470 train_loss= 0.40288 train_acc= 0.90705 val_roc= 0.63302 val_ap= 0.70418 time= 0.30095\n",
            "Epoch: 1471 train_loss= 0.40288 train_acc= 0.90706 val_roc= 0.63303 val_ap= 0.70419 time= 0.29920\n",
            "Epoch: 1472 train_loss= 0.40288 train_acc= 0.90707 val_roc= 0.63301 val_ap= 0.70416 time= 0.30230\n",
            "Epoch: 1473 train_loss= 0.40288 train_acc= 0.90708 val_roc= 0.63302 val_ap= 0.70416 time= 0.30588\n",
            "Epoch: 1474 train_loss= 0.40288 train_acc= 0.90709 val_roc= 0.63303 val_ap= 0.70417 time= 0.29382\n",
            "Epoch: 1475 train_loss= 0.40288 train_acc= 0.90712 val_roc= 0.63298 val_ap= 0.70414 time= 0.29949\n",
            "Epoch: 1476 train_loss= 0.40288 train_acc= 0.90713 val_roc= 0.63291 val_ap= 0.70408 time= 0.31067\n",
            "Epoch: 1477 train_loss= 0.40288 train_acc= 0.90713 val_roc= 0.63292 val_ap= 0.70409 time= 0.31367\n",
            "Epoch: 1478 train_loss= 0.40288 train_acc= 0.90714 val_roc= 0.63288 val_ap= 0.70406 time= 0.30642\n",
            "Epoch: 1479 train_loss= 0.40288 train_acc= 0.90715 val_roc= 0.63287 val_ap= 0.70406 time= 0.29688\n",
            "Epoch: 1480 train_loss= 0.40288 train_acc= 0.90716 val_roc= 0.63285 val_ap= 0.70406 time= 0.30614\n",
            "Epoch: 1481 train_loss= 0.40288 train_acc= 0.90717 val_roc= 0.63288 val_ap= 0.70410 time= 0.30019\n",
            "Epoch: 1482 train_loss= 0.40288 train_acc= 0.90717 val_roc= 0.63286 val_ap= 0.70408 time= 0.30175\n",
            "Epoch: 1483 train_loss= 0.40288 train_acc= 0.90718 val_roc= 0.63287 val_ap= 0.70408 time= 0.32588\n",
            "Epoch: 1484 train_loss= 0.40288 train_acc= 0.90719 val_roc= 0.63284 val_ap= 0.70407 time= 0.31514\n",
            "Epoch: 1485 train_loss= 0.40288 train_acc= 0.90720 val_roc= 0.63282 val_ap= 0.70404 time= 0.30656\n",
            "Epoch: 1486 train_loss= 0.40288 train_acc= 0.90721 val_roc= 0.63286 val_ap= 0.70407 time= 0.29959\n",
            "Epoch: 1487 train_loss= 0.40288 train_acc= 0.90721 val_roc= 0.63283 val_ap= 0.70406 time= 0.32813\n",
            "Epoch: 1488 train_loss= 0.40288 train_acc= 0.90722 val_roc= 0.63281 val_ap= 0.70402 time= 0.31462\n",
            "Epoch: 1489 train_loss= 0.40288 train_acc= 0.90723 val_roc= 0.63275 val_ap= 0.70399 time= 0.29611\n",
            "Epoch: 1490 train_loss= 0.40288 train_acc= 0.90724 val_roc= 0.63279 val_ap= 0.70401 time= 0.30471\n",
            "Epoch: 1491 train_loss= 0.40288 train_acc= 0.90725 val_roc= 0.63281 val_ap= 0.70404 time= 0.30117\n",
            "Epoch: 1492 train_loss= 0.40287 train_acc= 0.90727 val_roc= 0.63280 val_ap= 0.70404 time= 0.29469\n",
            "Epoch: 1493 train_loss= 0.40287 train_acc= 0.90728 val_roc= 0.63278 val_ap= 0.70402 time= 0.30063\n",
            "Epoch: 1494 train_loss= 0.40287 train_acc= 0.90729 val_roc= 0.63275 val_ap= 0.70400 time= 0.29811\n",
            "Epoch: 1495 train_loss= 0.40287 train_acc= 0.90730 val_roc= 0.63272 val_ap= 0.70398 time= 0.29633\n",
            "Epoch: 1496 train_loss= 0.40287 train_acc= 0.90730 val_roc= 0.63272 val_ap= 0.70397 time= 0.29470\n",
            "Epoch: 1497 train_loss= 0.40287 train_acc= 0.90730 val_roc= 0.63269 val_ap= 0.70395 time= 0.32520\n",
            "Epoch: 1498 train_loss= 0.40287 train_acc= 0.90730 val_roc= 0.63267 val_ap= 0.70394 time= 0.29570\n",
            "Epoch: 1499 train_loss= 0.40287 train_acc= 0.90730 val_roc= 0.63265 val_ap= 0.70391 time= 0.30983\n",
            "Epoch: 1500 train_loss= 0.40287 train_acc= 0.90732 val_roc= 0.63262 val_ap= 0.70387 time= 0.31754\n",
            "End of training! test_roc= 0.65075 test_ap= 0.72299\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}